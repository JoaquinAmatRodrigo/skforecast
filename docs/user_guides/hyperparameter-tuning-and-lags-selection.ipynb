{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8bfe72e",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning and lags selection\n",
    "\n",
    "Skforecast library combines several model tuning strategies with [backtesting](https://joaquinamatrodrigo.github.io/skforecast/latest/user_guides/backtesting.html) to identify the combination of lags and hyperparameters that achieve the best prediction performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc006084",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "902da042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "# ==============================================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from skforecast.ForecasterAutoreg import ForecasterAutoreg\n",
    "from skforecast.model_selection import grid_search_forecaster\n",
    "from skforecast.model_selection import  random_search_forecaster\n",
    "from skforecast.model_selection import  bayesian_search_forecaster\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc809ed",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb76f40b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dates      : 1991-07-01 00:00:00 --- 2001-01-01 00:00:00  (n=115)\n",
      "Validation dates : 2001-02-01 00:00:00 --- 2006-01-01 00:00:00  (n=60)\n",
      "Test dates       : 2006-02-01 00:00:00 --- 2008-06-01 00:00:00  (n=29)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 900x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Download data\n",
    "# ==============================================================================\n",
    "url = ('https://raw.githubusercontent.com/JoaquinAmatRodrigo/skforecast/master/data/h2o.csv')\n",
    "data = pd.read_csv(url, sep=',', header=0, names=['y', 'datetime'])\n",
    "\n",
    "# Data preprocessing\n",
    "# ==============================================================================\n",
    "data['datetime'] = pd.to_datetime(data['datetime'], format='%Y/%m/%d')\n",
    "data = data.set_index('datetime')\n",
    "data = data.asfreq('MS')\n",
    "data = data[['y']]\n",
    "data = data.sort_index()\n",
    "\n",
    "# Train-val-test dates\n",
    "# ==============================================================================\n",
    "end_train = '2001-01-01 23:59:00'\n",
    "end_val = '2006-01-01 23:59:00'\n",
    "\n",
    "print(f\"Train dates      : {data.index.min()} --- {data.loc[:end_train].index.max()}  (n={len(data.loc[:end_train])})\")\n",
    "print(f\"Validation dates : {data.loc[end_train:].index.min()} --- {data.loc[:end_val].index.max()}  (n={len(data.loc[end_train:end_val])})\")\n",
    "print(f\"Test dates       : {data.loc[end_val:].index.min()} --- {data.index.max()}  (n={len(data.loc[end_val:])})\")\n",
    "\n",
    "# Plot\n",
    "# ==============================================================================\n",
    "fig, ax=plt.subplots(figsize=(9, 4))\n",
    "data.loc[:end_train].plot(ax=ax, label='train')\n",
    "data.loc[end_train:end_val].plot(ax=ax, label='validation')\n",
    "data.loc[end_val:].plot(ax=ax, label='test')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f347f80",
   "metadata": {},
   "source": [
    "## Grid search\n",
    "\n",
    "Grid search requires two grids, one with the different lag configurations (`lags_grid`) and the other with the list of hyperparameters to be tested (`param_grid`). The process comprises the following steps:\n",
    "\n",
    "1. `grid_search_forecaster` creates a copy of the forecaster object and replaces the `lags` argument with the first option appearing in `lags_grid`.\n",
    "\n",
    "2. The function validates all combinations of hyperparameters presented in `param_grid` by [backtesting](https://joaquinamatrodrigo.github.io/skforecast/latest/user_guides/backtesting.html).\n",
    "\n",
    "3. The function repeats these two steps until it runs through all the possibilities (lags + hyperparameters).\n",
    "\n",
    "4. If `return_best = True`, the original forecaster is trained with the best lags and hyperparameters configuration found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10187b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of models compared: 18.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|| 3/3 [00:07<00:00,  2.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [ 1  2  3  4  5  6  7  8  9 10] \n",
      "  Parameters: {'max_depth': 5, 'n_estimators': 50}\n",
      "  Backtesting metric: 0.03344857370906804\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Grid search hyperparameter and lags\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterAutoreg(\n",
    "                 regressor = RandomForestRegressor(random_state=123),\n",
    "                 lags      = 10 # Placeholder, the value will be overwritten\n",
    "             )\n",
    "\n",
    "# Lags used as predictors\n",
    "lags_grid = [3, 10, [1, 2, 3, 20]]\n",
    "\n",
    "# Regressor hyperparameters\n",
    "param_grid = {'n_estimators': [50, 100],\n",
    "              'max_depth': [5, 10, 15]}\n",
    "\n",
    "results_grid = grid_search_forecaster(\n",
    "                   forecaster         = forecaster,\n",
    "                   y                  = data.loc[:end_val, 'y'],\n",
    "                   param_grid         = param_grid,\n",
    "                   lags_grid          = lags_grid,\n",
    "                   steps              = 12,\n",
    "                   refit              = True,\n",
    "                   metric             = 'mean_squared_error',\n",
    "                   initial_train_size = len(data.loc[:end_train]),\n",
    "                   fixed_train_size   = False,\n",
    "                   return_best        = True,\n",
    "                   verbose            = False\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97a049cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lags</th>\n",
       "      <th>params</th>\n",
       "      <th>mean_squared_error</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>n_estimators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 50}</td>\n",
       "      <td>0.033449</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 50}</td>\n",
       "      <td>0.039221</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]</td>\n",
       "      <td>{'max_depth': 15, 'n_estimators': 100}</td>\n",
       "      <td>0.039266</td>\n",
       "      <td>15</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 100}</td>\n",
       "      <td>0.039526</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 100}</td>\n",
       "      <td>0.040241</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]</td>\n",
       "      <td>{'max_depth': 15, 'n_estimators': 50}</td>\n",
       "      <td>0.040765</td>\n",
       "      <td>15</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[1, 2, 3, 20]</td>\n",
       "      <td>{'max_depth': 15, 'n_estimators': 100}</td>\n",
       "      <td>0.043909</td>\n",
       "      <td>15</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[1, 2, 3, 20]</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 100}</td>\n",
       "      <td>0.044992</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[1, 2, 3, 20]</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 50}</td>\n",
       "      <td>0.046224</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 50}</td>\n",
       "      <td>0.048666</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[1, 2, 3, 20]</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 100}</td>\n",
       "      <td>0.048991</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[1, 2, 3, 20]</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 50}</td>\n",
       "      <td>0.050193</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'max_depth': 15, 'n_estimators': 100}</td>\n",
       "      <td>0.050556</td>\n",
       "      <td>15</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[1, 2, 3, 20]</td>\n",
       "      <td>{'max_depth': 15, 'n_estimators': 50}</td>\n",
       "      <td>0.051217</td>\n",
       "      <td>15</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 100}</td>\n",
       "      <td>0.053123</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'max_depth': 15, 'n_estimators': 50}</td>\n",
       "      <td>0.060260</td>\n",
       "      <td>15</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 50}</td>\n",
       "      <td>0.060951</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 100}</td>\n",
       "      <td>0.067334</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               lags                                  params  \\\n",
       "6   [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]    {'max_depth': 5, 'n_estimators': 50}   \n",
       "8   [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]   {'max_depth': 10, 'n_estimators': 50}   \n",
       "11  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]  {'max_depth': 15, 'n_estimators': 100}   \n",
       "7   [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]   {'max_depth': 5, 'n_estimators': 100}   \n",
       "9   [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]  {'max_depth': 10, 'n_estimators': 100}   \n",
       "10  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]   {'max_depth': 15, 'n_estimators': 50}   \n",
       "17                    [1, 2, 3, 20]  {'max_depth': 15, 'n_estimators': 100}   \n",
       "13                    [1, 2, 3, 20]   {'max_depth': 5, 'n_estimators': 100}   \n",
       "12                    [1, 2, 3, 20]    {'max_depth': 5, 'n_estimators': 50}   \n",
       "0                         [1, 2, 3]    {'max_depth': 5, 'n_estimators': 50}   \n",
       "15                    [1, 2, 3, 20]  {'max_depth': 10, 'n_estimators': 100}   \n",
       "14                    [1, 2, 3, 20]   {'max_depth': 10, 'n_estimators': 50}   \n",
       "5                         [1, 2, 3]  {'max_depth': 15, 'n_estimators': 100}   \n",
       "16                    [1, 2, 3, 20]   {'max_depth': 15, 'n_estimators': 50}   \n",
       "1                         [1, 2, 3]   {'max_depth': 5, 'n_estimators': 100}   \n",
       "4                         [1, 2, 3]   {'max_depth': 15, 'n_estimators': 50}   \n",
       "2                         [1, 2, 3]   {'max_depth': 10, 'n_estimators': 50}   \n",
       "3                         [1, 2, 3]  {'max_depth': 10, 'n_estimators': 100}   \n",
       "\n",
       "    mean_squared_error  max_depth  n_estimators  \n",
       "6             0.033449          5            50  \n",
       "8             0.039221         10            50  \n",
       "11            0.039266         15           100  \n",
       "7             0.039526          5           100  \n",
       "9             0.040241         10           100  \n",
       "10            0.040765         15            50  \n",
       "17            0.043909         15           100  \n",
       "13            0.044992          5           100  \n",
       "12            0.046224          5            50  \n",
       "0             0.048666          5            50  \n",
       "15            0.048991         10           100  \n",
       "14            0.050193         10            50  \n",
       "5             0.050556         15           100  \n",
       "16            0.051217         15            50  \n",
       "1             0.053123          5           100  \n",
       "4             0.060260         15            50  \n",
       "2             0.060951         10            50  \n",
       "3             0.067334         10           100  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a718228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "================= \n",
       "ForecasterAutoreg \n",
       "================= \n",
       "Regressor: RandomForestRegressor(max_depth=5, n_estimators=50, random_state=123) \n",
       "Lags: [ 1  2  3  4  5  6  7  8  9 10] \n",
       "Transformer for y: None \n",
       "Transformer for exog: None \n",
       "Window size: 10 \n",
       "Weight function included: False \n",
       "Exogenous included: False \n",
       "Type of exogenous variable: None \n",
       "Exogenous variables names: None \n",
       "Training range: [Timestamp('1991-07-01 00:00:00'), Timestamp('2006-01-01 00:00:00')] \n",
       "Training index type: DatetimeIndex \n",
       "Training index frequency: MS \n",
       "Regressor parameters: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': 5, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 50, 'n_jobs': None, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False} \n",
       "Creation date: 2023-03-08 15:18:11 \n",
       "Last fit date: 2023-03-08 15:18:19 \n",
       "Skforecast version: 0.7.0 \n",
       "Python version: 3.9.13 \n",
       "Forecaster id: None "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecaster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab71330",
   "metadata": {},
   "source": [
    "## Random search\n",
    "\n",
    "Randomized search on hyperparameters. In contrast to `grid_search_forecaster`, not all parameter values are tried out, but rather a fixed number of parameter settings is sampled from the specified possibilities. The number of parameter settings that are tried is given by `n_iter`.\n",
    "\n",
    "It is important to note that random sampling is only applied to the model hyperparameters, but not to the lags. All lags specified by the user are evaluated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "395d1e1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of models compared: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|| 2/2 [00:04<00:00,  2.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [1 2 3 4 5] \n",
      "  Parameters: {'n_estimators': 77, 'max_depth': 17}\n",
      "  Backtesting metric: 0.03147248676391345\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lags</th>\n",
       "      <th>params</th>\n",
       "      <th>mean_squared_error</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_depth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 77, 'max_depth': 17}</td>\n",
       "      <td>0.031472</td>\n",
       "      <td>77</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 66, 'max_depth': 24}</td>\n",
       "      <td>0.033616</td>\n",
       "      <td>66</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 96, 'max_depth': 19}</td>\n",
       "      <td>0.033761</td>\n",
       "      <td>96</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 52, 'max_depth': 17}</td>\n",
       "      <td>0.040640</td>\n",
       "      <td>52</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 94, 'max_depth': 28}</td>\n",
       "      <td>0.044071</td>\n",
       "      <td>94</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'n_estimators': 94, 'max_depth': 28}</td>\n",
       "      <td>0.048469</td>\n",
       "      <td>94</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'n_estimators': 96, 'max_depth': 19}</td>\n",
       "      <td>0.049969</td>\n",
       "      <td>96</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'n_estimators': 66, 'max_depth': 24}</td>\n",
       "      <td>0.060074</td>\n",
       "      <td>66</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'n_estimators': 77, 'max_depth': 17}</td>\n",
       "      <td>0.060801</td>\n",
       "      <td>77</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'n_estimators': 52, 'max_depth': 17}</td>\n",
       "      <td>0.067000</td>\n",
       "      <td>52</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              lags                                 params  mean_squared_error  \\\n",
       "9  [1, 2, 3, 4, 5]  {'n_estimators': 77, 'max_depth': 17}            0.031472   \n",
       "7  [1, 2, 3, 4, 5]  {'n_estimators': 66, 'max_depth': 24}            0.033616   \n",
       "5  [1, 2, 3, 4, 5]  {'n_estimators': 96, 'max_depth': 19}            0.033761   \n",
       "6  [1, 2, 3, 4, 5]  {'n_estimators': 52, 'max_depth': 17}            0.040640   \n",
       "8  [1, 2, 3, 4, 5]  {'n_estimators': 94, 'max_depth': 28}            0.044071   \n",
       "3        [1, 2, 3]  {'n_estimators': 94, 'max_depth': 28}            0.048469   \n",
       "0        [1, 2, 3]  {'n_estimators': 96, 'max_depth': 19}            0.049969   \n",
       "2        [1, 2, 3]  {'n_estimators': 66, 'max_depth': 24}            0.060074   \n",
       "4        [1, 2, 3]  {'n_estimators': 77, 'max_depth': 17}            0.060801   \n",
       "1        [1, 2, 3]  {'n_estimators': 52, 'max_depth': 17}            0.067000   \n",
       "\n",
       "   n_estimators  max_depth  \n",
       "9            77         17  \n",
       "7            66         24  \n",
       "5            96         19  \n",
       "6            52         17  \n",
       "8            94         28  \n",
       "3            94         28  \n",
       "0            96         19  \n",
       "2            66         24  \n",
       "4            77         17  \n",
       "1            52         17  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random search hyperparameter and lags\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterAutoreg(\n",
    "                 regressor = RandomForestRegressor(random_state=123),\n",
    "                 lags      = 10 # Placeholder, the value will be overwritten\n",
    "             )\n",
    "\n",
    "# Lags used as predictors\n",
    "lags_grid = [3, 5]\n",
    "\n",
    "# Regressor hyperparameters\n",
    "param_distributions = {'n_estimators': np.arange(start=10, stop=100, step=1, dtype=int),\n",
    "                       'max_depth': np.arange(start=5, stop=30, step=1, dtype=int)}\n",
    "\n",
    "results = random_search_forecaster(\n",
    "              forecaster           = forecaster,\n",
    "              y                    = data.loc[:end_val, 'y'],\n",
    "              steps                = 12,\n",
    "              lags_grid            = lags_grid,\n",
    "              param_distributions  = param_distributions,\n",
    "              n_iter               = 5,\n",
    "              metric               = 'mean_squared_error',\n",
    "              refit                = True,\n",
    "              initial_train_size   = len(data.loc[:end_train]),\n",
    "              fixed_train_size     = False,\n",
    "              return_best          = True,\n",
    "              random_state         = 123,\n",
    "              verbose              = False\n",
    "          )\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df764b2d",
   "metadata": {},
   "source": [
    "## Bayesian search\n",
    "\n",
    "Grid and random search generate good results, especially when the search range is narrowed down. But they share a common flaw, neither of them takes into account the results obtained so far, which prevents them from focusing the search on the regions of greatest interest while avoiding unnecessary ones.\n",
    "\n",
    "An alternative is to search for hyperparameters using Bayesian optimization methods. In general terms, Bayesian hyperparameter optimization consists of creating a probabilistic model in which the objective function is the model validation metric (RMSE, AUC, accuracy...). With this strategy, the search is redirected at each iteration to the regions of greatest interest. The ultimate goal is to reduce the number of hyperparameter combinations with which the model is evaluated, choosing only the best candidates. This means that the advantage over the other mentioned strategies is maximized when the search space is very large or the model evaluation is very slow.\n",
    "\n",
    "It is important to note that Bayesian search is only applied to the hyperparameters of the model, but not to the lags. All lags specified by the user are evaluated.\n",
    "\n",
    "Skforecast includes two bayesian optimization engines: [Scikit-Optimize](https://scikit-optimize.github.io/stable/) and [Optuna](https://optuna.org/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6354c505",
   "metadata": {},
   "source": [
    "### Optuna\n",
    "\n",
    "Bayesian optimization using Optuna performs optimization with its [Study object](https://optuna.readthedocs.io/en/stable/reference/generated/optuna.study.Study.html#optuna.study.Study). This experiment minimizes  the metric generated by [backtesting](https://joaquinamatrodrigo.github.io/skforecast/latest/user_guides/backtesting.html). \n",
    "\n",
    "Additional parameters can be included when `bayesian_search_forecaster` calls [create_study](https://optuna.readthedocs.io/en/stable/reference/generated/optuna.study.create_study.html) and [optimize method](https://optuna.readthedocs.io/en/stable/reference/generated/optuna.study.Study.html#optuna.study.Study.optimize) using the `kwargs_create_study` and `kwargs_study_optimize` arguments respectively as `{'parameter_name': parameter_value}`.\n",
    "\n",
    "To use this engine, `search_space` argument must be a `function` as shown below. Optuna uses the [Trial object](https://optuna.readthedocs.io/en/stable/reference/generated/optuna.trial.Trial.html#optuna.trial.Trial) to generate each search space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c762a37c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of models compared: 20,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|| 2/2 [00:01<00:00,  1.08it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lags</th>\n",
       "      <th>params</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>max_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'n_estimators': 12, 'min_samples_leaf': 1.258...</td>\n",
       "      <td>0.217299</td>\n",
       "      <td>12</td>\n",
       "      <td>1.258033</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'n_estimators': 13, 'min_samples_leaf': 2.283...</td>\n",
       "      <td>0.217401</td>\n",
       "      <td>13</td>\n",
       "      <td>2.283083</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'n_estimators': 14, 'min_samples_leaf': 3.218...</td>\n",
       "      <td>0.217481</td>\n",
       "      <td>14</td>\n",
       "      <td>3.218291</td>\n",
       "      <td>log2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'n_estimators': 14, 'min_samples_leaf': 1.907...</td>\n",
       "      <td>0.217481</td>\n",
       "      <td>14</td>\n",
       "      <td>1.907712</td>\n",
       "      <td>log2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'n_estimators': 14, 'min_samples_leaf': 1.081...</td>\n",
       "      <td>0.217481</td>\n",
       "      <td>14</td>\n",
       "      <td>1.081208</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'n_estimators': 17, 'min_samples_leaf': 1.525...</td>\n",
       "      <td>0.217677</td>\n",
       "      <td>17</td>\n",
       "      <td>1.525829</td>\n",
       "      <td>log2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'n_estimators': 17, 'min_samples_leaf': 1.454...</td>\n",
       "      <td>0.217677</td>\n",
       "      <td>17</td>\n",
       "      <td>1.454068</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'n_estimators': 17, 'min_samples_leaf': 1.739...</td>\n",
       "      <td>0.217677</td>\n",
       "      <td>17</td>\n",
       "      <td>1.739441</td>\n",
       "      <td>log2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'n_estimators': 15, 'min_samples_leaf': 1.670...</td>\n",
       "      <td>0.218018</td>\n",
       "      <td>15</td>\n",
       "      <td>1.670328</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'n_estimators': 16, 'min_samples_leaf': 3.038...</td>\n",
       "      <td>0.218105</td>\n",
       "      <td>16</td>\n",
       "      <td>3.038426</td>\n",
       "      <td>log2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 17, 'min_samples_leaf': 1.454...</td>\n",
       "      <td>0.219529</td>\n",
       "      <td>17</td>\n",
       "      <td>1.454068</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 17, 'min_samples_leaf': 1.739...</td>\n",
       "      <td>0.219529</td>\n",
       "      <td>17</td>\n",
       "      <td>1.739441</td>\n",
       "      <td>log2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 17, 'min_samples_leaf': 1.525...</td>\n",
       "      <td>0.219529</td>\n",
       "      <td>17</td>\n",
       "      <td>1.525829</td>\n",
       "      <td>log2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 16, 'min_samples_leaf': 3.038...</td>\n",
       "      <td>0.219800</td>\n",
       "      <td>16</td>\n",
       "      <td>3.038426</td>\n",
       "      <td>log2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 13, 'min_samples_leaf': 2.283...</td>\n",
       "      <td>0.220040</td>\n",
       "      <td>13</td>\n",
       "      <td>2.283083</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 15, 'min_samples_leaf': 1.670...</td>\n",
       "      <td>0.220173</td>\n",
       "      <td>15</td>\n",
       "      <td>1.670328</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 14, 'min_samples_leaf': 1.907...</td>\n",
       "      <td>0.220478</td>\n",
       "      <td>14</td>\n",
       "      <td>1.907712</td>\n",
       "      <td>log2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 14, 'min_samples_leaf': 1.081...</td>\n",
       "      <td>0.220478</td>\n",
       "      <td>14</td>\n",
       "      <td>1.081208</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 14, 'min_samples_leaf': 3.218...</td>\n",
       "      <td>0.220478</td>\n",
       "      <td>14</td>\n",
       "      <td>3.218291</td>\n",
       "      <td>log2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 12, 'min_samples_leaf': 1.258...</td>\n",
       "      <td>0.220546</td>\n",
       "      <td>12</td>\n",
       "      <td>1.258033</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               lags                                             params  \\\n",
       "4         [1, 2, 3]  {'n_estimators': 12, 'min_samples_leaf': 1.258...   \n",
       "7         [1, 2, 3]  {'n_estimators': 13, 'min_samples_leaf': 2.283...   \n",
       "9         [1, 2, 3]  {'n_estimators': 14, 'min_samples_leaf': 3.218...   \n",
       "8         [1, 2, 3]  {'n_estimators': 14, 'min_samples_leaf': 1.907...   \n",
       "3         [1, 2, 3]  {'n_estimators': 14, 'min_samples_leaf': 1.081...   \n",
       "6         [1, 2, 3]  {'n_estimators': 17, 'min_samples_leaf': 1.525...   \n",
       "0         [1, 2, 3]  {'n_estimators': 17, 'min_samples_leaf': 1.454...   \n",
       "1         [1, 2, 3]  {'n_estimators': 17, 'min_samples_leaf': 1.739...   \n",
       "2         [1, 2, 3]  {'n_estimators': 15, 'min_samples_leaf': 1.670...   \n",
       "5         [1, 2, 3]  {'n_estimators': 16, 'min_samples_leaf': 3.038...   \n",
       "10  [1, 2, 3, 4, 5]  {'n_estimators': 17, 'min_samples_leaf': 1.454...   \n",
       "11  [1, 2, 3, 4, 5]  {'n_estimators': 17, 'min_samples_leaf': 1.739...   \n",
       "16  [1, 2, 3, 4, 5]  {'n_estimators': 17, 'min_samples_leaf': 1.525...   \n",
       "15  [1, 2, 3, 4, 5]  {'n_estimators': 16, 'min_samples_leaf': 3.038...   \n",
       "17  [1, 2, 3, 4, 5]  {'n_estimators': 13, 'min_samples_leaf': 2.283...   \n",
       "12  [1, 2, 3, 4, 5]  {'n_estimators': 15, 'min_samples_leaf': 1.670...   \n",
       "18  [1, 2, 3, 4, 5]  {'n_estimators': 14, 'min_samples_leaf': 1.907...   \n",
       "13  [1, 2, 3, 4, 5]  {'n_estimators': 14, 'min_samples_leaf': 1.081...   \n",
       "19  [1, 2, 3, 4, 5]  {'n_estimators': 14, 'min_samples_leaf': 3.218...   \n",
       "14  [1, 2, 3, 4, 5]  {'n_estimators': 12, 'min_samples_leaf': 1.258...   \n",
       "\n",
       "    mean_absolute_error  n_estimators  min_samples_leaf max_features  \n",
       "4              0.217299            12          1.258033         sqrt  \n",
       "7              0.217401            13          2.283083         sqrt  \n",
       "9              0.217481            14          3.218291         log2  \n",
       "8              0.217481            14          1.907712         log2  \n",
       "3              0.217481            14          1.081208         sqrt  \n",
       "6              0.217677            17          1.525829         log2  \n",
       "0              0.217677            17          1.454068         sqrt  \n",
       "1              0.217677            17          1.739441         log2  \n",
       "2              0.218018            15          1.670328         sqrt  \n",
       "5              0.218105            16          3.038426         log2  \n",
       "10             0.219529            17          1.454068         sqrt  \n",
       "11             0.219529            17          1.739441         log2  \n",
       "16             0.219529            17          1.525829         log2  \n",
       "15             0.219800            16          3.038426         log2  \n",
       "17             0.220040            13          2.283083         sqrt  \n",
       "12             0.220173            15          1.670328         sqrt  \n",
       "18             0.220478            14          1.907712         log2  \n",
       "13             0.220478            14          1.081208         sqrt  \n",
       "19             0.220478            14          3.218291         log2  \n",
       "14             0.220546            12          1.258033         sqrt  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bayesian search hyperparameter and lags with Optuna\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterAutoreg(\n",
    "                 regressor = RandomForestRegressor(random_state=123),\n",
    "                 lags      = 10 # Placeholder, the value will be overwritten\n",
    "             )\n",
    "\n",
    "# Lags used as predictors\n",
    "lags_grid = [3, 5]\n",
    "\n",
    "# Regressor hyperparameters search space\n",
    "def search_space(trial):\n",
    "    search_space  = {'n_estimators'     : trial.suggest_int('n_estimators', 10, 20),\n",
    "                     'min_samples_leaf' : trial.suggest_float('min_samples_leaf', 1., 3.7, log=True),\n",
    "                     'max_features'     : trial.suggest_categorical('max_features', ['log2', 'sqrt'])\n",
    "                    } \n",
    "    return search_space\n",
    "\n",
    "results, frozen_trial = bayesian_search_forecaster(\n",
    "                            forecaster            = forecaster,\n",
    "                            y                     = data.loc[:end_val, 'y'],\n",
    "                            lags_grid             = lags_grid,\n",
    "                            search_space          = search_space,\n",
    "                            steps                 = 12,\n",
    "                            metric                = 'mean_absolute_error',\n",
    "                            refit                 = True,\n",
    "                            initial_train_size    = len(data.loc[:end_train]),\n",
    "                            fixed_train_size      = True,\n",
    "                            n_trials              = 10,\n",
    "                            random_state          = 123,\n",
    "                            return_best           = False,\n",
    "                            verbose               = False,\n",
    "                            engine                = 'optuna',\n",
    "                            kwargs_create_study   = {},\n",
    "                            kwargs_study_optimize = {}\n",
    "                        )\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a970a3",
   "metadata": {},
   "source": [
    "`frozen_trial` contains the trial of the optimization of the [Study class](https://optuna.readthedocs.io/en/stable/reference/generated/optuna.study.Study.html#optuna.study.Study) for the best iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "400b4ab4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FrozenTrial(number=4, values=[0.21729924404290674], datetime_start=datetime.datetime(2023, 3, 8, 15, 18, 24, 84513), datetime_complete=datetime.datetime(2023, 3, 8, 15, 18, 24, 164882), params={'n_estimators': 12, 'min_samples_leaf': 1.2580328751834622, 'max_features': 'sqrt'}, distributions={'n_estimators': IntDistribution(high=20, log=False, low=10, step=1), 'min_samples_leaf': FloatDistribution(high=3.7, log=True, low=1.0, step=None), 'max_features': CategoricalDistribution(choices=('log2', 'sqrt'))}, user_attrs={}, system_attrs={}, intermediate_values={}, trial_id=4, state=TrialState.COMPLETE, value=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frozen_trial"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "268feae8",
   "metadata": {},
   "source": [
    "### Scikit-optimize\n",
    "\n",
    "Bayesian optimization with Skopt performs optimization with Gaussian processes. This is done with the function [gp_minimize](https://scikit-optimize.github.io/stable/modules/generated/skopt.gp_minimize.html#skopt.gp_minimize) where the objective value to be minimized is calculated by [backtesting](https://joaquinamatrodrigo.github.io/skforecast/latest/user_guides/backtesting.html)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f130b400",
   "metadata": {},
   "source": [
    "<script src=\"https://kit.fontawesome.com/d20edc211b.js\" crossorigin=\"anonymous\"></script>\n",
    "\n",
    "<div class=\"admonition note\" name=\"html-admonition\" style=\"background: rgba(255,145,0,.1); padding-top: 0px; padding-bottom: 6px; border-radius: 8px; border-left: 8px solid #ff9100;\">\n",
    "\n",
    "<p class=\"title\">\n",
    "    <i class=\"fa-triangle-exclamation fa\" style=\"font-size: 18px; color:#ff9100;\"></i>\n",
    "    <b> &nbsp Warning</b>\n",
    "</p>\n",
    "\n",
    "This engine is deprecated since skforecast 0.7.0 in favor of optuna engine. To continue using it, install skforecast 0.6.0.\n",
    "<br><br>\n",
    "User guide: https://joaquinamatrodrigo.github.io/skforecast/0.6.0/user_guides/hyperparameter-tuning-and-lags-selection.html#scikit-optimize\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8279bda4",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning with custom metric\n",
    "\n",
    "Besides the frequently used metrics: `mean_squared_error`, `mean_absolute_error`, and `mean_absolute_percentage_error`, it is possible to use any custom function as long as:\n",
    "\n",
    "+ It includes the arguments:\n",
    "\n",
    "    + `y_true`: true values of the series.\n",
    "\n",
    "    + `y_pred`: predicted values.\n",
    "\n",
    "+ It returns a numeric value (`float` or `int`).\n",
    "\n",
    "It allows to evaluate of the predictive capability of the model in a wide range of scenarios, for example:\n",
    "\n",
    "+ Consider only certain months, days, hours...\n",
    "\n",
    "+ Consider only dates that are holidays.\n",
    "\n",
    "+ Consider only the last step of the predicted horizon.\n",
    "\n",
    "The following example using `grid_search_forecaster` shows how to forecast a 12-month horizon but considering only the last 3 months of each year to calculate the interest metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "251660d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of models compared: 18.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|| 3/3 [00:08<00:00,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [1 2 3] \n",
      "  Parameters: {'max_depth': 5, 'n_estimators': 50}\n",
      "  Backtesting metric: 0.04867459231626605\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lags</th>\n",
       "      <th>params</th>\n",
       "      <th>custom_metric</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>n_estimators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 50}</td>\n",
       "      <td>0.048675</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[1, 2, 3, 20]</td>\n",
       "      <td>{'max_depth': 15, 'n_estimators': 100}</td>\n",
       "      <td>0.052172</td>\n",
       "      <td>15</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'max_depth': 15, 'n_estimators': 100}</td>\n",
       "      <td>0.055920</td>\n",
       "      <td>15</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[1, 2, 3, 20]</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 50}</td>\n",
       "      <td>0.056981</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 50}</td>\n",
       "      <td>0.057507</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[1, 2, 3, 20]</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 50}</td>\n",
       "      <td>0.058631</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 50}</td>\n",
       "      <td>0.060032</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'max_depth': 15, 'n_estimators': 50}</td>\n",
       "      <td>0.063681</td>\n",
       "      <td>15</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[1, 2, 3, 20]</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 100}</td>\n",
       "      <td>0.064490</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[1, 2, 3, 20]</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 100}</td>\n",
       "      <td>0.066499</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 100}</td>\n",
       "      <td>0.066522</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 50}</td>\n",
       "      <td>0.066599</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 100}</td>\n",
       "      <td>0.069684</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[1, 2, 3, 20]</td>\n",
       "      <td>{'max_depth': 15, 'n_estimators': 50}</td>\n",
       "      <td>0.070077</td>\n",
       "      <td>15</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 100}</td>\n",
       "      <td>0.071078</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]</td>\n",
       "      <td>{'max_depth': 15, 'n_estimators': 100}</td>\n",
       "      <td>0.072183</td>\n",
       "      <td>15</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]</td>\n",
       "      <td>{'max_depth': 15, 'n_estimators': 50}</td>\n",
       "      <td>0.085193</td>\n",
       "      <td>15</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 100}</td>\n",
       "      <td>0.109090</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               lags                                  params  \\\n",
       "0                         [1, 2, 3]    {'max_depth': 5, 'n_estimators': 50}   \n",
       "17                    [1, 2, 3, 20]  {'max_depth': 15, 'n_estimators': 100}   \n",
       "5                         [1, 2, 3]  {'max_depth': 15, 'n_estimators': 100}   \n",
       "12                    [1, 2, 3, 20]    {'max_depth': 5, 'n_estimators': 50}   \n",
       "6   [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]    {'max_depth': 5, 'n_estimators': 50}   \n",
       "14                    [1, 2, 3, 20]   {'max_depth': 10, 'n_estimators': 50}   \n",
       "2                         [1, 2, 3]   {'max_depth': 10, 'n_estimators': 50}   \n",
       "4                         [1, 2, 3]   {'max_depth': 15, 'n_estimators': 50}   \n",
       "13                    [1, 2, 3, 20]   {'max_depth': 5, 'n_estimators': 100}   \n",
       "15                    [1, 2, 3, 20]  {'max_depth': 10, 'n_estimators': 100}   \n",
       "1                         [1, 2, 3]   {'max_depth': 5, 'n_estimators': 100}   \n",
       "8   [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]   {'max_depth': 10, 'n_estimators': 50}   \n",
       "7   [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]   {'max_depth': 5, 'n_estimators': 100}   \n",
       "16                    [1, 2, 3, 20]   {'max_depth': 15, 'n_estimators': 50}   \n",
       "9   [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]  {'max_depth': 10, 'n_estimators': 100}   \n",
       "11  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]  {'max_depth': 15, 'n_estimators': 100}   \n",
       "10  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]   {'max_depth': 15, 'n_estimators': 50}   \n",
       "3                         [1, 2, 3]  {'max_depth': 10, 'n_estimators': 100}   \n",
       "\n",
       "    custom_metric  max_depth  n_estimators  \n",
       "0        0.048675          5            50  \n",
       "17       0.052172         15           100  \n",
       "5        0.055920         15           100  \n",
       "12       0.056981          5            50  \n",
       "6        0.057507          5            50  \n",
       "14       0.058631         10            50  \n",
       "2        0.060032         10            50  \n",
       "4        0.063681         15            50  \n",
       "13       0.064490          5           100  \n",
       "15       0.066499         10           100  \n",
       "1        0.066522          5           100  \n",
       "8        0.066599         10            50  \n",
       "7        0.069684          5           100  \n",
       "16       0.070077         15            50  \n",
       "9        0.071078         10           100  \n",
       "11       0.072183         15           100  \n",
       "10       0.085193         15            50  \n",
       "3        0.109090         10           100  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grid search hyperparameter and lags with custom metric\n",
    "# ==============================================================================\n",
    "def custom_metric(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate the mean squared error using only the predicted values of the last\n",
    "    3 months of the year.\n",
    "    \"\"\"\n",
    "    mask = y_true.index.month.isin([10, 11, 12])\n",
    "    metric = mean_squared_error(y_true[mask], y_pred[mask])\n",
    "    \n",
    "    return metric\n",
    "    \n",
    "forecaster = ForecasterAutoreg(\n",
    "                 regressor = RandomForestRegressor(random_state=123),\n",
    "                 lags      = 10 # Placeholder, the value will be overwritten\n",
    "             )\n",
    "\n",
    "# Lags used as predictors\n",
    "lags_grid = [3, 10, [1, 2, 3, 20]]\n",
    "\n",
    "# Regressor hyperparameters\n",
    "param_grid = {'n_estimators': [50, 100],\n",
    "              'max_depth': [5, 10, 15]}\n",
    "\n",
    "results_grid = grid_search_forecaster(\n",
    "                   forecaster         = forecaster,\n",
    "                   y                  = data.loc[:end_val, 'y'],\n",
    "                   param_grid         = param_grid,\n",
    "                   lags_grid          = lags_grid,\n",
    "                   steps              = 12,\n",
    "                   refit              = True,\n",
    "                   metric             = custom_metric,\n",
    "                   initial_train_size = len(data.loc[:end_train]),\n",
    "                   fixed_train_size   = False,\n",
    "                   return_best        = True,\n",
    "                   verbose            = False\n",
    "               )\n",
    "\n",
    "results_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f185ba5",
   "metadata": {},
   "source": [
    "## Compare multiple metrics\n",
    "\n",
    "All three functions (`grid_search_forecaster`, `random_search_forecaster`, and `bayesian_search_forecaster`) allow the calculation of multiple metrics for each forecaster configuration if a list is provided. This list may include custom metrics and the best model selection is done based on the first metric of the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d58707a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of models compared: 18.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|| 3/3 [00:09<00:00,  3.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [ 1  2  3  4  5  6  7  8  9 10] \n",
      "  Parameters: {'max_depth': 5, 'n_estimators': 50}\n",
      "  Backtesting metric: 0.14186925271863238\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lags</th>\n",
       "      <th>params</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <th>mean_squared_error</th>\n",
       "      <th>custom_metric</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>n_estimators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 50}</td>\n",
       "      <td>0.141869</td>\n",
       "      <td>0.033449</td>\n",
       "      <td>0.057507</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 50}</td>\n",
       "      <td>0.144912</td>\n",
       "      <td>0.039221</td>\n",
       "      <td>0.066599</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]</td>\n",
       "      <td>{'max_depth': 15, 'n_estimators': 50}</td>\n",
       "      <td>0.152188</td>\n",
       "      <td>0.040765</td>\n",
       "      <td>0.085193</td>\n",
       "      <td>15</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 100}</td>\n",
       "      <td>0.154576</td>\n",
       "      <td>0.040241</td>\n",
       "      <td>0.071078</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]</td>\n",
       "      <td>{'max_depth': 15, 'n_estimators': 100}</td>\n",
       "      <td>0.155862</td>\n",
       "      <td>0.039266</td>\n",
       "      <td>0.072183</td>\n",
       "      <td>15</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 100}</td>\n",
       "      <td>0.160582</td>\n",
       "      <td>0.039526</td>\n",
       "      <td>0.069684</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[1, 2, 3, 20]</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 100}</td>\n",
       "      <td>0.166288</td>\n",
       "      <td>0.044992</td>\n",
       "      <td>0.064490</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[1, 2, 3, 20]</td>\n",
       "      <td>{'max_depth': 15, 'n_estimators': 100}</td>\n",
       "      <td>0.167600</td>\n",
       "      <td>0.043909</td>\n",
       "      <td>0.052172</td>\n",
       "      <td>15</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[1, 2, 3, 20]</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 100}</td>\n",
       "      <td>0.170615</td>\n",
       "      <td>0.048991</td>\n",
       "      <td>0.066499</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[1, 2, 3, 20]</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 50}</td>\n",
       "      <td>0.172712</td>\n",
       "      <td>0.046224</td>\n",
       "      <td>0.056981</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[1, 2, 3, 20]</td>\n",
       "      <td>{'max_depth': 15, 'n_estimators': 50}</td>\n",
       "      <td>0.176946</td>\n",
       "      <td>0.051217</td>\n",
       "      <td>0.070077</td>\n",
       "      <td>15</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[1, 2, 3, 20]</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 50}</td>\n",
       "      <td>0.177002</td>\n",
       "      <td>0.050193</td>\n",
       "      <td>0.058631</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'max_depth': 15, 'n_estimators': 100}</td>\n",
       "      <td>0.177226</td>\n",
       "      <td>0.050556</td>\n",
       "      <td>0.055920</td>\n",
       "      <td>15</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 50}</td>\n",
       "      <td>0.178910</td>\n",
       "      <td>0.048666</td>\n",
       "      <td>0.048675</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 100}</td>\n",
       "      <td>0.191461</td>\n",
       "      <td>0.053123</td>\n",
       "      <td>0.066522</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 100}</td>\n",
       "      <td>0.199497</td>\n",
       "      <td>0.067334</td>\n",
       "      <td>0.109090</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 50}</td>\n",
       "      <td>0.203445</td>\n",
       "      <td>0.060951</td>\n",
       "      <td>0.060032</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'max_depth': 15, 'n_estimators': 50}</td>\n",
       "      <td>0.214713</td>\n",
       "      <td>0.060260</td>\n",
       "      <td>0.063681</td>\n",
       "      <td>15</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               lags                                  params  \\\n",
       "6   [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]    {'max_depth': 5, 'n_estimators': 50}   \n",
       "8   [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]   {'max_depth': 10, 'n_estimators': 50}   \n",
       "10  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]   {'max_depth': 15, 'n_estimators': 50}   \n",
       "9   [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]  {'max_depth': 10, 'n_estimators': 100}   \n",
       "11  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]  {'max_depth': 15, 'n_estimators': 100}   \n",
       "7   [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]   {'max_depth': 5, 'n_estimators': 100}   \n",
       "13                    [1, 2, 3, 20]   {'max_depth': 5, 'n_estimators': 100}   \n",
       "17                    [1, 2, 3, 20]  {'max_depth': 15, 'n_estimators': 100}   \n",
       "15                    [1, 2, 3, 20]  {'max_depth': 10, 'n_estimators': 100}   \n",
       "12                    [1, 2, 3, 20]    {'max_depth': 5, 'n_estimators': 50}   \n",
       "16                    [1, 2, 3, 20]   {'max_depth': 15, 'n_estimators': 50}   \n",
       "14                    [1, 2, 3, 20]   {'max_depth': 10, 'n_estimators': 50}   \n",
       "5                         [1, 2, 3]  {'max_depth': 15, 'n_estimators': 100}   \n",
       "0                         [1, 2, 3]    {'max_depth': 5, 'n_estimators': 50}   \n",
       "1                         [1, 2, 3]   {'max_depth': 5, 'n_estimators': 100}   \n",
       "3                         [1, 2, 3]  {'max_depth': 10, 'n_estimators': 100}   \n",
       "2                         [1, 2, 3]   {'max_depth': 10, 'n_estimators': 50}   \n",
       "4                         [1, 2, 3]   {'max_depth': 15, 'n_estimators': 50}   \n",
       "\n",
       "    mean_absolute_error  mean_squared_error  custom_metric  max_depth  \\\n",
       "6              0.141869            0.033449       0.057507          5   \n",
       "8              0.144912            0.039221       0.066599         10   \n",
       "10             0.152188            0.040765       0.085193         15   \n",
       "9              0.154576            0.040241       0.071078         10   \n",
       "11             0.155862            0.039266       0.072183         15   \n",
       "7              0.160582            0.039526       0.069684          5   \n",
       "13             0.166288            0.044992       0.064490          5   \n",
       "17             0.167600            0.043909       0.052172         15   \n",
       "15             0.170615            0.048991       0.066499         10   \n",
       "12             0.172712            0.046224       0.056981          5   \n",
       "16             0.176946            0.051217       0.070077         15   \n",
       "14             0.177002            0.050193       0.058631         10   \n",
       "5              0.177226            0.050556       0.055920         15   \n",
       "0              0.178910            0.048666       0.048675          5   \n",
       "1              0.191461            0.053123       0.066522          5   \n",
       "3              0.199497            0.067334       0.109090         10   \n",
       "2              0.203445            0.060951       0.060032         10   \n",
       "4              0.214713            0.060260       0.063681         15   \n",
       "\n",
       "    n_estimators  \n",
       "6             50  \n",
       "8             50  \n",
       "10            50  \n",
       "9            100  \n",
       "11           100  \n",
       "7            100  \n",
       "13           100  \n",
       "17           100  \n",
       "15           100  \n",
       "12            50  \n",
       "16            50  \n",
       "14            50  \n",
       "5            100  \n",
       "0             50  \n",
       "1            100  \n",
       "3            100  \n",
       "2             50  \n",
       "4             50  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grid search hyperparameter and lags with multiple metrics\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterAutoreg(\n",
    "                 regressor = RandomForestRegressor(random_state=123),\n",
    "                 lags      = 10 # Placeholder, the value will be overwritten\n",
    "             )\n",
    "\n",
    "# Metrics\n",
    "metrics = ['mean_absolute_error', mean_squared_error, custom_metric]\n",
    "\n",
    "# Lags used as predictors\n",
    "lags_grid = [3, 10, [1, 2, 3, 20]]\n",
    "\n",
    "# Regressor hyperparameters\n",
    "param_grid = {'n_estimators': [50, 100],\n",
    "              'max_depth': [5, 10, 15]}\n",
    "\n",
    "results_grid = grid_search_forecaster(\n",
    "                    forecaster         = forecaster,\n",
    "                    y                  = data.loc[:end_val, 'y'],\n",
    "                    param_grid         = param_grid,\n",
    "                    lags_grid          = lags_grid,\n",
    "                    steps              = 12,\n",
    "                    refit              = True,\n",
    "                    metric             = metrics,\n",
    "                    initial_train_size = len(data.loc[:end_train]),\n",
    "                    fixed_train_size   = False,\n",
    "                    return_best        = True,\n",
    "                    verbose            = False\n",
    "               )\n",
    "\n",
    "results_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21a6eba",
   "metadata": {},
   "source": [
    "## Compare multiple regressors\n",
    "\n",
    "It is also possible to tune several regressors in order to identify which one achieves better performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "edf210dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search for regressor: RandomForestRegressor(random_state=123)\n",
      "-------------------------\n",
      "Number of models compared: 8.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|| 2/2 [00:10<00:00,  5.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search for regressor: GradientBoostingRegressor(random_state=123)\n",
      "-------------------------\n",
      "Number of models compared: 8.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|| 2/2 [00:01<00:00,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search for regressor: Ridge(random_state=123)\n",
      "-------------------------\n",
      "Number of models compared: 6.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|| 2/2 [00:00<00:00,  7.54it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lags</th>\n",
       "      <th>params</th>\n",
       "      <th>mean_squared_error</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>model</th>\n",
       "      <th>alpha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 50}</td>\n",
       "      <td>0.045461</td>\n",
       "      <td>5.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'max_depth': 15, 'n_estimators': 50}</td>\n",
       "      <td>0.045826</td>\n",
       "      <td>15.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 100}</td>\n",
       "      <td>0.048252</td>\n",
       "      <td>5.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'max_depth': 15, 'n_estimators': 100}</td>\n",
       "      <td>0.048994</td>\n",
       "      <td>15.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'alpha': 0.01}</td>\n",
       "      <td>0.054196</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ridge</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'alpha': 0.01}</td>\n",
       "      <td>0.054255</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ridge</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'alpha': 0.1}</td>\n",
       "      <td>0.054266</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ridge</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'alpha': 0.1}</td>\n",
       "      <td>0.054287</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ridge</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 50}</td>\n",
       "      <td>0.054291</td>\n",
       "      <td>10.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 20}</td>\n",
       "      <td>0.054773</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'alpha': 1}</td>\n",
       "      <td>0.054858</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ridge</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'alpha': 1}</td>\n",
       "      <td>0.055189</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ridge</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 20}</td>\n",
       "      <td>0.057305</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 100}</td>\n",
       "      <td>0.058374</td>\n",
       "      <td>5.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 50}</td>\n",
       "      <td>0.059118</td>\n",
       "      <td>5.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'max_depth': 15, 'n_estimators': 100}</td>\n",
       "      <td>0.062309</td>\n",
       "      <td>15.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 50}</td>\n",
       "      <td>0.062625</td>\n",
       "      <td>5.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 20}</td>\n",
       "      <td>0.063042</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'max_depth': 15, 'n_estimators': 50}</td>\n",
       "      <td>0.063856</td>\n",
       "      <td>15.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 50}</td>\n",
       "      <td>0.069501</td>\n",
       "      <td>5.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 20}</td>\n",
       "      <td>0.087865</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 50}</td>\n",
       "      <td>0.101529</td>\n",
       "      <td>10.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              lags                                  params  \\\n",
       "4  [1, 2, 3, 4, 5]    {'max_depth': 5, 'n_estimators': 50}   \n",
       "6  [1, 2, 3, 4, 5]   {'max_depth': 15, 'n_estimators': 50}   \n",
       "5  [1, 2, 3, 4, 5]   {'max_depth': 5, 'n_estimators': 100}   \n",
       "7  [1, 2, 3, 4, 5]  {'max_depth': 15, 'n_estimators': 100}   \n",
       "0        [1, 2, 3]                         {'alpha': 0.01}   \n",
       "3  [1, 2, 3, 4, 5]                         {'alpha': 0.01}   \n",
       "4  [1, 2, 3, 4, 5]                          {'alpha': 0.1}   \n",
       "1        [1, 2, 3]                          {'alpha': 0.1}   \n",
       "7  [1, 2, 3, 4, 5]   {'max_depth': 10, 'n_estimators': 50}   \n",
       "6  [1, 2, 3, 4, 5]   {'max_depth': 10, 'n_estimators': 20}   \n",
       "5  [1, 2, 3, 4, 5]                            {'alpha': 1}   \n",
       "2        [1, 2, 3]                            {'alpha': 1}   \n",
       "4  [1, 2, 3, 4, 5]    {'max_depth': 5, 'n_estimators': 20}   \n",
       "1        [1, 2, 3]   {'max_depth': 5, 'n_estimators': 100}   \n",
       "5  [1, 2, 3, 4, 5]    {'max_depth': 5, 'n_estimators': 50}   \n",
       "3        [1, 2, 3]  {'max_depth': 15, 'n_estimators': 100}   \n",
       "0        [1, 2, 3]    {'max_depth': 5, 'n_estimators': 50}   \n",
       "0        [1, 2, 3]    {'max_depth': 5, 'n_estimators': 20}   \n",
       "2        [1, 2, 3]   {'max_depth': 15, 'n_estimators': 50}   \n",
       "1        [1, 2, 3]    {'max_depth': 5, 'n_estimators': 50}   \n",
       "2        [1, 2, 3]   {'max_depth': 10, 'n_estimators': 20}   \n",
       "3        [1, 2, 3]   {'max_depth': 10, 'n_estimators': 50}   \n",
       "\n",
       "   mean_squared_error  max_depth  n_estimators                      model  \\\n",
       "4            0.045461        5.0          50.0      RandomForestRegressor   \n",
       "6            0.045826       15.0          50.0      RandomForestRegressor   \n",
       "5            0.048252        5.0         100.0      RandomForestRegressor   \n",
       "7            0.048994       15.0         100.0      RandomForestRegressor   \n",
       "0            0.054196        NaN           NaN                      Ridge   \n",
       "3            0.054255        NaN           NaN                      Ridge   \n",
       "4            0.054266        NaN           NaN                      Ridge   \n",
       "1            0.054287        NaN           NaN                      Ridge   \n",
       "7            0.054291       10.0          50.0  GradientBoostingRegressor   \n",
       "6            0.054773       10.0          20.0  GradientBoostingRegressor   \n",
       "5            0.054858        NaN           NaN                      Ridge   \n",
       "2            0.055189        NaN           NaN                      Ridge   \n",
       "4            0.057305        5.0          20.0  GradientBoostingRegressor   \n",
       "1            0.058374        5.0         100.0      RandomForestRegressor   \n",
       "5            0.059118        5.0          50.0  GradientBoostingRegressor   \n",
       "3            0.062309       15.0         100.0      RandomForestRegressor   \n",
       "0            0.062625        5.0          50.0      RandomForestRegressor   \n",
       "0            0.063042        5.0          20.0  GradientBoostingRegressor   \n",
       "2            0.063856       15.0          50.0      RandomForestRegressor   \n",
       "1            0.069501        5.0          50.0  GradientBoostingRegressor   \n",
       "2            0.087865       10.0          20.0  GradientBoostingRegressor   \n",
       "3            0.101529       10.0          50.0  GradientBoostingRegressor   \n",
       "\n",
       "   alpha  \n",
       "4    NaN  \n",
       "6    NaN  \n",
       "5    NaN  \n",
       "7    NaN  \n",
       "0   0.01  \n",
       "3   0.01  \n",
       "4   0.10  \n",
       "1   0.10  \n",
       "7    NaN  \n",
       "6    NaN  \n",
       "5   1.00  \n",
       "2   1.00  \n",
       "4    NaN  \n",
       "1    NaN  \n",
       "5    NaN  \n",
       "3    NaN  \n",
       "0    NaN  \n",
       "0    NaN  \n",
       "2    NaN  \n",
       "1    NaN  \n",
       "2    NaN  \n",
       "3    NaN  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Models to compare\n",
    "# ==============================================================================\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "models = [RandomForestRegressor(random_state=123), \n",
    "          GradientBoostingRegressor(random_state=123),\n",
    "          Ridge(random_state=123)]\n",
    "\n",
    "# param_grid for each model\n",
    "param_grids = {'RandomForestRegressor': {'n_estimators': [50, 100], 'max_depth': [5, 15]},\n",
    "               'GradientBoostingRegressor': {'n_estimators': [20, 50], 'max_depth': [5, 10]},\n",
    "               'Ridge': {'alpha': [0.01, 0.1, 1]}}\n",
    "\n",
    "# Lags used as predictors\n",
    "lags_grid = [3, 5]\n",
    "\n",
    "\n",
    "df_results = pd.DataFrame()\n",
    "for i, model in enumerate(models):\n",
    "    print(f\"Grid search for regressor: {model}\")\n",
    "    print(f\"-------------------------\")\n",
    "\n",
    "    forecaster = ForecasterAutoreg(\n",
    "                     regressor = model,\n",
    "                     lags      = 3\n",
    "                 )\n",
    "\n",
    "    # Regressor hyperparameters\n",
    "    param_grid = param_grids[list(param_grids)[i]]\n",
    "\n",
    "    results_grid = grid_search_forecaster(\n",
    "                       forecaster         = forecaster,\n",
    "                       y                  = data.loc[:end_val, 'y'],\n",
    "                       param_grid         = param_grid,\n",
    "                       lags_grid          = lags_grid,\n",
    "                       steps              = 3,\n",
    "                       refit              = True,\n",
    "                       metric             = 'mean_squared_error',\n",
    "                       initial_train_size = len(data.loc[:end_train]),\n",
    "                       fixed_train_size   = True,\n",
    "                       return_best        = False,\n",
    "                       verbose            = False\n",
    "                   )\n",
    "    \n",
    "    # Create a column with model name\n",
    "    results_grid['model'] = list(param_grids)[i]\n",
    "    \n",
    "    df_results = pd.concat([df_results, results_grid])\n",
    "\n",
    "df_results.sort_values(by='mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241e58a2",
   "metadata": {},
   "source": [
    "## Hide progress bar\n",
    "\n",
    "It is possible to hide the progress bar using the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc666f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of models compared: 6.\n",
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [1 2 3] \n",
      "  Parameters: {'alpha': 1}\n",
      "  Backtesting metric: 0.08758355918903007\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from functools import partialmethod\n",
    "tqdm.__init__ = partialmethod(tqdm.__init__, disable=True)\n",
    "\n",
    "results_grid = grid_search_forecaster(\n",
    "                   forecaster         = forecaster,\n",
    "                   y                  = data.loc[:end_val, 'y'],\n",
    "                   param_grid         = param_grid,\n",
    "                   lags_grid          = lags_grid,\n",
    "                   steps              = 12,\n",
    "                   refit              = True,\n",
    "                   metric             = 'mean_squared_error',\n",
    "                   initial_train_size = len(data.loc[:end_train]),\n",
    "                   fixed_train_size   = False,\n",
    "                   return_best        = True,\n",
    "                   verbose            = False\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec8ff309",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".jupyter-wrapper .jp-CodeCell .jp-Cell-inputWrapper .jp-InputPrompt {display: none;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    ".jupyter-wrapper .jp-CodeCell .jp-Cell-inputWrapper .jp-InputPrompt {display: none;}\n",
    "</style>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('skforecast')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "6ffed84beb63baa96f7d22d816ccf3255c078420a09b57d1f48b4641bbf1489e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
