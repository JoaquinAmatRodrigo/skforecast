{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecasting with XGBoost\n",
    "\n",
    "XGBoost, the acronym for Extreme Gradient Boosting, is a very efficient implementation of the stochastic gradient boosting algorithm that has become a benchmark in machine learning. Besides its API, the XGBoost library includes the XGBRegressor class which follows the scikit-learn API and, therefore it is compatible with skforecast."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<script src=\"https://kit.fontawesome.com/d20edc211b.js\" crossorigin=\"anonymous\"></script>\n",
    "\n",
    "<div class=\"admonition note\" name=\"html-admonition\" style=\"background: rgba(0,184,212,.1); padding-top: 0px; padding-bottom: 6px; border-radius: 8px; border-left: 8px solid #00b8d4;\">\n",
    "\n",
    "<p class=\"title\">\n",
    "    <i class=\"fa-circle-exclamation fa\" style=\"font-size: 18px; color:#00b8d4;\"></i>\n",
    "    <b> &nbsp Note</b>\n",
    "</p>\n",
    "\n",
    "Since the success of XGBoost as a machine learning algorithm, new implementations have been developed that also achieve excellent results, two of them are: <a href=\"https://lightgbm.readthedocs.io/en/latest/\">LightGBM</a> and <a href=\"https://catboost.ai/\">CatBoost</a>. A more detailed example can be found <a href=\"https://www.cienciadedatos.net/documentos/py39-forecasting-time-series-with-skforecast-xgboost-lightgbm-catboost.html\">here</a>. \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "# ==============================================================================\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from xgboost import XGBRegressor\n",
    "from skforecast.ForecasterAutoreg import ForecasterAutoreg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data\n",
    "# ==============================================================================\n",
    "url = ('https://raw.githubusercontent.com/JoaquinAmatRodrigo/skforecast/master/data/h2o_exog.csv')\n",
    "data = pd.read_csv(url, sep=',', header=0, names=['date', 'y', 'exog_1', 'exog_2'])\n",
    "\n",
    "# Data preprocessing\n",
    "# ==============================================================================\n",
    "data['date'] = pd.to_datetime(data['date'], format='%Y/%m/%d')\n",
    "data = data.set_index('date')\n",
    "data = data.asfreq('MS')\n",
    "\n",
    "steps = 36\n",
    "data_train = data.iloc[:-steps, :]\n",
    "data_test  = data.iloc[-steps:, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and train forecaster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "================= \n",
       "ForecasterAutoreg \n",
       "================= \n",
       "Regressor: XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "             gamma=0, gpu_id=-1, importance_type=None,\n",
       "             interaction_constraints='', learning_rate=0.300000012,\n",
       "             max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "             monotone_constraints='()', n_estimators=100, n_jobs=8,\n",
       "             num_parallel_tree=1, predictor='auto', random_state=0, reg_alpha=0,\n",
       "             reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method='exact',\n",
       "             validate_parameters=1, verbosity=None) \n",
       "Lags: [1 2 3 4 5 6 7 8] \n",
       "Window size: 8 \n",
       "Included exogenous: True \n",
       "Type of exogenous variable: <class 'pandas.core.frame.DataFrame'> \n",
       "Exogenous variables names: ['exog_1', 'exog_2'] \n",
       "Training range: [Timestamp('1992-04-01 00:00:00'), Timestamp('2008-06-01 00:00:00')] \n",
       "Training index type: DatetimeIndex \n",
       "Training index frequency: MS \n",
       "Regressor parameters: {'objective': 'reg:squarederror', 'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bynode': 1, 'colsample_bytree': 1, 'enable_categorical': False, 'gamma': 0, 'gpu_id': -1, 'importance_type': None, 'interaction_constraints': '', 'learning_rate': 0.300000012, 'max_delta_step': 0, 'max_depth': 6, 'min_child_weight': 1, 'missing': nan, 'monotone_constraints': '()', 'n_estimators': 100, 'n_jobs': 8, 'num_parallel_tree': 1, 'predictor': 'auto', 'random_state': 0, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'subsample': 1, 'tree_method': 'exact', 'validate_parameters': 1, 'verbosity': None} \n",
       "Creation date: 2022-03-12 12:26:21 \n",
       "Last fit date: 2022-03-12 12:26:21 \n",
       "Skforecast version: 0.4.3 "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create and fit forecaster\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterAutoreg(\n",
    "                    regressor = XGBRegressor(),\n",
    "                    lags = 8\n",
    "             )\n",
    "\n",
    "forecaster.fit(y=data['y'], exog=data[['exog_1', 'exog_2']])\n",
    "forecaster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2008-07-01    0.700701\n",
       "2008-08-01    0.829139\n",
       "2008-09-01    0.983677\n",
       "2008-10-01    1.098782\n",
       "2008-11-01    1.078021\n",
       "2008-12-01    1.206761\n",
       "2009-01-01    1.149827\n",
       "2009-02-01    1.049927\n",
       "2009-03-01    0.947129\n",
       "2009-04-01    0.700440\n",
       "Freq: MS, Name: pred, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict\n",
    "# ==============================================================================\n",
    "forecaster.predict(steps=10, exog=data_test[['exog_1', 'exog_2']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lag_1</td>\n",
       "      <td>0.358967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lag_2</td>\n",
       "      <td>0.093567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lag_3</td>\n",
       "      <td>0.016729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lag_4</td>\n",
       "      <td>0.044611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lag_5</td>\n",
       "      <td>0.054733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>lag_6</td>\n",
       "      <td>0.009510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>lag_7</td>\n",
       "      <td>0.097179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>lag_8</td>\n",
       "      <td>0.027964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>exog_1</td>\n",
       "      <td>0.186294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>exog_2</td>\n",
       "      <td>0.110447</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  feature  importance\n",
       "0   lag_1    0.358967\n",
       "1   lag_2    0.093567\n",
       "2   lag_3    0.016729\n",
       "3   lag_4    0.044611\n",
       "4   lag_5    0.054733\n",
       "5   lag_6    0.009510\n",
       "6   lag_7    0.097179\n",
       "7   lag_8    0.027964\n",
       "8  exog_1    0.186294\n",
       "9  exog_2    0.110447"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predictors importance\n",
    "# ==============================================================================\n",
    "forecaster.get_feature_importance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".jupyter-wrapper .jp-CodeCell .jp-Cell-inputWrapper .jp-InputPrompt {display: none;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    ".jupyter-wrapper .jp-CodeCell .jp-Cell-inputWrapper .jp-InputPrompt {display: none;}\n",
    "</style>"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6ea9a7bd5acac7ef50d998c0248a4db17b38ee2b9d85779465a12782ddc26457"
  },
  "kernelspec": {
   "display_name": "skforecast_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Tabla de contenidos",
   "title_sidebar": "Tabla de contenidos",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "144.391px",
    "left": "1478px",
    "right": "20px",
    "top": "126px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
