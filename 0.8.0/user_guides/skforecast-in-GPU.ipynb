{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c5148957",
   "metadata": {},
   "source": [
    "# Skforecast in GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce2a3d8",
   "metadata": {},
   "source": [
    "Traditionally, machine learning algorithms are executed on CPUs (Central Processing Units), which are general-purpose processors that are designed to handle a wide range of tasks. However, CPUs are not optimized for the highly parallelized matrix operations that are required by many machine learning algorithms, which can result in slow training times and limited scalability. GPUs, on the other hand, are designed specifically for parallel processing and can perform thousands of mathematical operations simultaneously, making them ideal for training and deploying large-scale machine learning models.\n",
    "\n",
    "Two popular machine learning libraries that have implemented GPU acceleration are **XGBoost** and **LightGBM**. These libraries are used for building gradient boosting models, which are a type of machine learning algorithm that is highly effective for a wide range of tasks, including forecasting. With GPU acceleration, these libraries can significantly reduce the training time required to build these models and improve their scalability.\n",
    "\n",
    "Despite the significant advantages offered by GPUs (specifically Nvidia GPUs) in accelerating machine learning computations, access to them is often limited due to high costs or other practical constraints. Fortunatelly, **Google Colaboratory (Colab)**, a free Jupyter notebook environment, allows users to run Python code in the cloud, with access to powerful hardware resources such as GPUs. This makes it an excellent platform for experimenting with machine learning models, especially those that require intensive computations.\n",
    "\n",
    "The following sections demonstrate how to install and use **XGBoost** and **LightGBM** with GPU acceleration to create powerful forecasting models."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4b9fd63a",
   "metadata": {},
   "source": [
    "<script src=\"https://kit.fontawesome.com/d20edc211b.js\" crossorigin=\"anonymous\"></script>\n",
    "\n",
    "<div class=\"admonition note\" name=\"html-admonition\" style=\"background: rgba(255,145,0,.1); padding-top: 0px; padding-bottom: 6px; border-radius: 8px; border-left: 8px solid #ff9100;\">\n",
    "\n",
    "<p class=\"title\">\n",
    "    <i class=\"fa-triangle-exclamation fa\" style=\"font-size: 18px; color:#ff9100;\"></i>\n",
    "    <b> &nbsp Warning</b>\n",
    "</p>\n",
    "\n",
    "The following code assumes that the user is executing it in Google Colab with an activated GPU runtime.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "074ca42f",
   "metadata": {},
   "source": [
    "## XGBoost\n",
    "\n",
    "When creating the model, only two arguments are need to indicate XGBoost to GPU, if it available: `tree_method='gpu_hist'` and `gpu_id=0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14e11a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "# ==============================================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from xgboost import XGBRegressor\n",
    "from skforecast.ForecasterAutoreg import ForecasterAutoreg\n",
    "import torch\n",
    "import os\n",
    "import sys\n",
    "import psutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e0be51c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "CPU RAM Free: 6.81 GB\n"
     ]
    }
   ],
   "source": [
    "# Setting device on GPU if available, else CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "\n",
    "# GPU info\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_cached(0)/1024**3,1), 'GB')\n",
    "\n",
    "# CPU info\n",
    "print(f\"CPU RAM Free: {psutil.virtual_memory().available / 1024**3:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8181b8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "# ==============================================================================\n",
    "data = pd.Series(np.random.normal(size=1000000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9a6c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train forecaster with a XGBRegressor using GPU\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterAutoreg(\n",
    "                regressor = XGBRegressor(\n",
    "                              n_estimators=5000,\n",
    "                              tree_method='gpu_hist',\n",
    "                              gpu_id=0\n",
    "                            ),\n",
    "                lags = 20\n",
    "             )\n",
    "\n",
    "forecaster.fit(y=data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a27b9011",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef624ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r /opt/conda/lib/python3.6/site-packages/lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e23eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone --recursive https://github.com/Microsoft/LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88704475",
   "metadata": {},
   "outputs": [],
   "source": [
    "!apt-get install -y -qq libboost-all-dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d69b0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd LightGBM\n",
    "rm -r build\n",
    "mkdir build\n",
    "cd build\n",
    "cmake -DUSE_GPU=1 -DOpenCL_LIBRARY=/usr/local/cuda/lib64/libOpenCL.so -DOpenCL_INCLUDE_DIR=/usr/local/cuda/include/ ..\n",
    "make -j$(nproc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e97669",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd LightGBM/python-package/;python3 setup.py install --precompile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50dea497",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p /etc/OpenCL/vendors && echo \"libnvidia-opencl.so.1\" > /etc/OpenCL/vendors/nvidia.icd\n",
    "!rm -r LightGBM"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9f1bc7c7",
   "metadata": {},
   "source": [
    "Once all the above installation has been executed, it is necessary to **restart** the runtime (kernel)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2175e44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "# ==============================================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from lightgbm  import LGBMRegressor\n",
    "from skforecast.ForecasterAutoreg import ForecasterAutoreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d3ecab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "# ==============================================================================\n",
    "data = pd.Series(np.random.normal(size=1000000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da945f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train forecaster with a LGBMRegressor using GPU\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterAutoreg(\n",
    "                regressor = LGBMRegressor(n_estimators=5000, device_type='gpu'),\n",
    "                lags = 20\n",
    "             )\n",
    "\n",
    "forecaster.fit(y=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac014ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".jupyter-wrapper .jp-CodeCell .jp-Cell-inputWrapper .jp-InputPrompt {display: none;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    ".jupyter-wrapper .jp-CodeCell .jp-Cell-inputWrapper .jp-InputPrompt {display: none;}\n",
    "</style>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('skforecast')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "6ffed84beb63baa96f7d22d816ccf3255c078420a09b57d1f48b4641bbf1489e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
