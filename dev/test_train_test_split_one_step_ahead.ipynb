{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/varios/skforecast\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "from pathlib import Path\n",
    "path = str(Path.cwd().parent)\n",
    "print(path)\n",
    "sys.path.insert(1, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from skforecast.metrics import mean_absolute_scaled_error\n",
    "from skforecast.metrics import root_mean_squared_scaled_error\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.linear_model import Ridge\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from skforecast.ForecasterAutoregMultiSeries import ForecasterAutoregMultiSeries\n",
    "from skforecast.ForecasterAutoregMultiVariate import ForecasterAutoregMultiVariate\n",
    "from skforecast.model_selection_multiseries.model_selection_multiseries import _evaluate_grid_hyperparameters_multiseries\n",
    "from skforecast.model_selection_multiseries.model_selection_multiseries import _predict_and_calculate_metrics_multiseries_one_step_ahead\n",
    "\n",
    "# Fixtures\n",
    "from skforecast.model_selection.tests.fixtures_model_selection import y_feature_selection\n",
    "from skforecast.model_selection.tests.fixtures_model_selection import exog_feature_selection\n",
    "\n",
    "from skforecast.datasets import fetch_dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/varios/skforecast/skforecast/ForecasterAutoregMultiSeries/ForecasterAutoregMultiSeries.py:400: UserWarning: When using a linear model, it is recommended to use a transformer_series to ensure all series are in the same scale. You can use, for example, a `StandardScaler` from sklearn.preprocessing.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def test_train_test_split_one_step_ahead_when_y_is_series_and_exog_are_dataframe_encoding_none():\n",
    "    \"\"\"\n",
    "    Test the output of _train_test_split_one_step_ahead when series and exog are\n",
    "    pandas dataframes, and encoding is None.\n",
    "    \"\"\"\n",
    "    series = pd.DataFrame(\n",
    "        {\n",
    "            \"series_1\": np.arange(15),\n",
    "            \"series_2\": np.arange(50, 65),\n",
    "        },\n",
    "        index=pd.date_range(\"2020-01-01\", periods=15),\n",
    "        dtype=float,\n",
    "    )\n",
    "    exog = pd.DataFrame(\n",
    "        {\n",
    "            \"exog_1\": np.arange(100, 115, dtype=float),\n",
    "            \"exog_2\": np.arange(1000, 1015, dtype=int),\n",
    "        },\n",
    "        index=pd.date_range(\"2020-01-01\", periods=15),\n",
    "    )\n",
    "\n",
    "    forecaster = ForecasterAutoregMultiSeries(\n",
    "        LinearRegression(),\n",
    "        lags=5,\n",
    "        encoding=None,\n",
    "    )\n",
    "\n",
    "    X_train, y_train, X_test, y_test, X_train_encoding, X_test_encoding = (\n",
    "        forecaster._train_test_split_one_step_ahead(\n",
    "            series=series, exog=exog, initial_train_size=10\n",
    "        )\n",
    "    )\n",
    "\n",
    "    expected_X_trian = pd.DataFrame(\n",
    "        {\n",
    "            \"lag_1\": [4.0, 5.0, 6.0, 7.0, 8.0, 54.0, 55.0, 56.0, 57.0, 58.0],\n",
    "            \"lag_2\": [3.0, 4.0, 5.0, 6.0, 7.0, 53.0, 54.0, 55.0, 56.0, 57.0],\n",
    "            \"lag_3\": [2.0, 3.0, 4.0, 5.0, 6.0, 52.0, 53.0, 54.0, 55.0, 56.0],\n",
    "            \"lag_4\": [1.0, 2.0, 3.0, 4.0, 5.0, 51.0, 52.0, 53.0, 54.0, 55.0],\n",
    "            \"lag_5\": [0.0, 1.0, 2.0, 3.0, 4.0, 50.0, 51.0, 52.0, 53.0, 54.0],\n",
    "            \"exog_1\": [\n",
    "                105.0,\n",
    "                106.0,\n",
    "                107.0,\n",
    "                108.0,\n",
    "                109.0,\n",
    "                105.0,\n",
    "                106.0,\n",
    "                107.0,\n",
    "                108.0,\n",
    "                109.0,\n",
    "            ],\n",
    "            \"exog_2\": [1005, 1006, 1007, 1008, 1009, 1005, 1006, 1007, 1008, 1009],\n",
    "        },\n",
    "        index=pd.DatetimeIndex(\n",
    "            [\n",
    "                \"2020-01-06\",\n",
    "                \"2020-01-07\",\n",
    "                \"2020-01-08\",\n",
    "                \"2020-01-09\",\n",
    "                \"2020-01-10\",\n",
    "                \"2020-01-06\",\n",
    "                \"2020-01-07\",\n",
    "                \"2020-01-08\",\n",
    "                \"2020-01-09\",\n",
    "                \"2020-01-10\",\n",
    "            ]\n",
    "        ),\n",
    "    ).astype({\"exog_2\": int})\n",
    "\n",
    "    expected_y_train = pd.Series(\n",
    "        [5.0, 6.0, 7.0, 8.0, 9.0, 55.0, 56.0, 57.0, 58.0, 59.0],\n",
    "        index=pd.DatetimeIndex(\n",
    "            [\n",
    "                \"2020-01-06\",\n",
    "                \"2020-01-07\",\n",
    "                \"2020-01-08\",\n",
    "                \"2020-01-09\",\n",
    "                \"2020-01-10\",\n",
    "                \"2020-01-06\",\n",
    "                \"2020-01-07\",\n",
    "                \"2020-01-08\",\n",
    "                \"2020-01-09\",\n",
    "                \"2020-01-10\",\n",
    "            ]\n",
    "        ),\n",
    "        name=\"y\",\n",
    "    )\n",
    "\n",
    "    expected_X_test = pd.DataFrame(\n",
    "        {\n",
    "            \"lag_1\": [9.0, 10.0, 11.0, 12.0, 13.0, 59.0, 60.0, 61.0, 62.0, 63.0],\n",
    "            \"lag_2\": [8.0, 9.0, 10.0, 11.0, 12.0, 58.0, 59.0, 60.0, 61.0, 62.0],\n",
    "            \"lag_3\": [7.0, 8.0, 9.0, 10.0, 11.0, 57.0, 58.0, 59.0, 60.0, 61.0],\n",
    "            \"lag_4\": [6.0, 7.0, 8.0, 9.0, 10.0, 56.0, 57.0, 58.0, 59.0, 60.0],\n",
    "            \"lag_5\": [5.0, 6.0, 7.0, 8.0, 9.0, 55.0, 56.0, 57.0, 58.0, 59.0],\n",
    "            \"exog_1\": [\n",
    "                110.0,\n",
    "                111.0,\n",
    "                112.0,\n",
    "                113.0,\n",
    "                114.0,\n",
    "                110.0,\n",
    "                111.0,\n",
    "                112.0,\n",
    "                113.0,\n",
    "                114.0,\n",
    "            ],\n",
    "            \"exog_2\": [1010, 1011, 1012, 1013, 1014, 1010, 1011, 1012, 1013, 1014],\n",
    "        },\n",
    "        index=pd.DatetimeIndex(\n",
    "            [\n",
    "                \"2020-01-11\",\n",
    "                \"2020-01-12\",\n",
    "                \"2020-01-13\",\n",
    "                \"2020-01-14\",\n",
    "                \"2020-01-15\",\n",
    "                \"2020-01-11\",\n",
    "                \"2020-01-12\",\n",
    "                \"2020-01-13\",\n",
    "                \"2020-01-14\",\n",
    "                \"2020-01-15\",\n",
    "            ]\n",
    "        ),\n",
    "    ).astype({\"exog_2\": int})\n",
    "\n",
    "    expected_y_test = pd.Series(\n",
    "        [10.0, 11.0, 12.0, 13.0, 14.0, 60.0, 61.0, 62.0, 63.0, 64.0],\n",
    "        index=pd.DatetimeIndex(\n",
    "            [\n",
    "                \"2020-01-11\",\n",
    "                \"2020-01-12\",\n",
    "                \"2020-01-13\",\n",
    "                \"2020-01-14\",\n",
    "                \"2020-01-15\",\n",
    "                \"2020-01-11\",\n",
    "                \"2020-01-12\",\n",
    "                \"2020-01-13\",\n",
    "                \"2020-01-14\",\n",
    "                \"2020-01-15\",\n",
    "            ]\n",
    "        ),\n",
    "        name=\"y\",\n",
    "    )\n",
    "\n",
    "    expected_X_train_encoding = pd.Series(\n",
    "        [\n",
    "            \"series_1\",\n",
    "            \"series_1\",\n",
    "            \"series_1\",\n",
    "            \"series_1\",\n",
    "            \"series_1\",\n",
    "            \"series_2\",\n",
    "            \"series_2\",\n",
    "            \"series_2\",\n",
    "            \"series_2\",\n",
    "            \"series_2\",\n",
    "        ],\n",
    "        index=pd.DatetimeIndex(\n",
    "            [\n",
    "                \"2020-01-06\",\n",
    "                \"2020-01-07\",\n",
    "                \"2020-01-08\",\n",
    "                \"2020-01-09\",\n",
    "                \"2020-01-10\",\n",
    "                \"2020-01-06\",\n",
    "                \"2020-01-07\",\n",
    "                \"2020-01-08\",\n",
    "                \"2020-01-09\",\n",
    "                \"2020-01-10\",\n",
    "            ]\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    expected_X_test_encoding = pd.Series(\n",
    "        [\n",
    "            \"series_1\",\n",
    "            \"series_1\",\n",
    "            \"series_1\",\n",
    "            \"series_1\",\n",
    "            \"series_1\",\n",
    "            \"series_2\",\n",
    "            \"series_2\",\n",
    "            \"series_2\",\n",
    "            \"series_2\",\n",
    "            \"series_2\",\n",
    "        ],\n",
    "        index=pd.DatetimeIndex(\n",
    "            [\n",
    "                \"2020-01-11\",\n",
    "                \"2020-01-12\",\n",
    "                \"2020-01-13\",\n",
    "                \"2020-01-14\",\n",
    "                \"2020-01-15\",\n",
    "                \"2020-01-11\",\n",
    "                \"2020-01-12\",\n",
    "                \"2020-01-13\",\n",
    "                \"2020-01-14\",\n",
    "                \"2020-01-15\",\n",
    "            ]\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    pd.testing.assert_frame_equal(X_train, expected_X_trian)\n",
    "    pd.testing.assert_series_equal(y_train, expected_y_train)\n",
    "    pd.testing.assert_frame_equal(X_test, expected_X_test)\n",
    "    pd.testing.assert_series_equal(y_test, expected_y_test)\n",
    "    pd.testing.assert_series_equal(X_train_encoding, expected_X_train_encoding)\n",
    "    pd.testing.assert_series_equal(X_test_encoding, expected_X_test_encoding)\n",
    "\n",
    "\n",
    "test_train_test_split_one_step_ahead_when_y_is_series_and_exog_are_dataframe_encoding_none()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/varios/skforecast/skforecast/ForecasterAutoregMultiSeries/ForecasterAutoregMultiSeries.py:400: UserWarning: When using a linear model, it is recommended to use a transformer_series to ensure all series are in the same scale. You can use, for example, a `StandardScaler` from sklearn.preprocessing.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'lag_1': [9.0, 10.0, 11.0, 12.0, 13.0, 59.0, 60.0, 61.0, 62.0, 63.0],\n",
       " 'lag_2': [8.0, 9.0, 10.0, 11.0, 12.0, 58.0, 59.0, 60.0, 61.0, 62.0],\n",
       " 'lag_3': [7.0, 8.0, 9.0, 10.0, 11.0, 57.0, 58.0, 59.0, 60.0, 61.0],\n",
       " 'lag_4': [6.0, 7.0, 8.0, 9.0, 10.0, 56.0, 57.0, 58.0, 59.0, 60.0],\n",
       " 'lag_5': [5.0, 6.0, 7.0, 8.0, 9.0, 55.0, 56.0, 57.0, 58.0, 59.0],\n",
       " 'exog_1': [110.0,\n",
       "  111.0,\n",
       "  112.0,\n",
       "  113.0,\n",
       "  114.0,\n",
       "  110.0,\n",
       "  111.0,\n",
       "  112.0,\n",
       "  113.0,\n",
       "  114.0],\n",
       " 'exog_2': [1010, 1011, 1012, 1013, 1014, 1010, 1011, 1012, 1013, 1014]}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series = pd.DataFrame(\n",
    "    {\n",
    "        \"series_1\": np.arange(15),\n",
    "        \"series_2\": np.arange(50, 65),\n",
    "    },\n",
    "    index=pd.date_range(\"2020-01-01\", periods=15),\n",
    "    dtype=float,\n",
    ")\n",
    "exog = pd.DataFrame(\n",
    "    {\n",
    "        \"exog_1\": np.arange(100, 115, dtype=float),\n",
    "        \"exog_2\": np.arange(1000, 1015, dtype=int),\n",
    "    },\n",
    "    index=pd.date_range(\"2020-01-01\", periods=15),\n",
    ")\n",
    "\n",
    "forecaster = ForecasterAutoregMultiSeries(\n",
    "    LinearRegression(),\n",
    "    lags=5,\n",
    "    encoding=None,\n",
    ")\n",
    "\n",
    "X_train, y_train, X_test, y_test, X_train_encoding, X_test_encoding = (\n",
    "    forecaster._train_test_split_one_step_ahead(\n",
    "        series=series, exog=exog, initial_train_size=10\n",
    "    )\n",
    ")\n",
    "\n",
    "expected_X_trian = pd.DataFrame(\n",
    "    {\n",
    "        \"lag_1\": [4.0, 5.0, 6.0, 7.0, 8.0, 54.0, 55.0, 56.0, 57.0, 58.0],\n",
    "        \"lag_2\": [3.0, 4.0, 5.0, 6.0, 7.0, 53.0, 54.0, 55.0, 56.0, 57.0],\n",
    "        \"lag_3\": [2.0, 3.0, 4.0, 5.0, 6.0, 52.0, 53.0, 54.0, 55.0, 56.0],\n",
    "        \"lag_4\": [1.0, 2.0, 3.0, 4.0, 5.0, 51.0, 52.0, 53.0, 54.0, 55.0],\n",
    "        \"lag_5\": [0.0, 1.0, 2.0, 3.0, 4.0, 50.0, 51.0, 52.0, 53.0, 54.0],\n",
    "        \"_level_skforecast\": [0, 0, 0, 0, 0, 1, 1, 1, 1, 1],\n",
    "        \"exog_1\": [\n",
    "            105.0,\n",
    "            106.0,\n",
    "            107.0,\n",
    "            108.0,\n",
    "            109.0,\n",
    "            105.0,\n",
    "            106.0,\n",
    "            107.0,\n",
    "            108.0,\n",
    "            109.0,\n",
    "        ],\n",
    "        \"exog_2\": [1005, 1006, 1007, 1008, 1009, 1005, 1006, 1007, 1008, 1009],\n",
    "    },\n",
    "    index=pd.DatetimeIndex(\n",
    "        [\n",
    "            \"2020-01-06\",\n",
    "            \"2020-01-07\",\n",
    "            \"2020-01-08\",\n",
    "            \"2020-01-09\",\n",
    "            \"2020-01-10\",\n",
    "            \"2020-01-06\",\n",
    "            \"2020-01-07\",\n",
    "            \"2020-01-08\",\n",
    "            \"2020-01-09\",\n",
    "            \"2020-01-10\",\n",
    "        ]\n",
    "    ),\n",
    ").astype({\"exog_2\": int})\n",
    "\n",
    "expected_y_train = pd.Series(\n",
    "    [5.0, 6.0, 7.0, 8.0, 9.0, 55.0, 56.0, 57.0, 58.0, 59.0],\n",
    "    index=pd.DatetimeIndex(\n",
    "        [\n",
    "            \"2020-01-06\",\n",
    "            \"2020-01-07\",\n",
    "            \"2020-01-08\",\n",
    "            \"2020-01-09\",\n",
    "            \"2020-01-10\",\n",
    "            \"2020-01-06\",\n",
    "            \"2020-01-07\",\n",
    "            \"2020-01-08\",\n",
    "            \"2020-01-09\",\n",
    "            \"2020-01-10\",\n",
    "        ]\n",
    "    ),\n",
    "    name=\"y\",\n",
    ")\n",
    "\n",
    "expected_X_test = pd.DataFrame(\n",
    "    {\n",
    "        \"lag_1\": [9.0, 10.0, 11.0, 12.0, 13.0, 59.0, 60.0, 61.0, 62.0, 63.0],\n",
    "        \"lag_2\": [8.0, 9.0, 10.0, 11.0, 12.0, 58.0, 59.0, 60.0, 61.0, 62.0],\n",
    "        \"lag_3\": [7.0, 8.0, 9.0, 10.0, 11.0, 57.0, 58.0, 59.0, 60.0, 61.0],\n",
    "        \"lag_4\": [6.0, 7.0, 8.0, 9.0, 10.0, 56.0, 57.0, 58.0, 59.0, 60.0],\n",
    "        \"lag_5\": [5.0, 6.0, 7.0, 8.0, 9.0, 55.0, 56.0, 57.0, 58.0, 59.0],\n",
    "        \"_level_skforecast\": [0, 0, 0, 0, 0, 1, 1, 1, 1, 1],\n",
    "        \"exog_1\": [\n",
    "            110.0,\n",
    "            111.0,\n",
    "            112.0,\n",
    "            113.0,\n",
    "            114.0,\n",
    "            110.0,\n",
    "            111.0,\n",
    "            112.0,\n",
    "            113.0,\n",
    "            114.0,\n",
    "        ],\n",
    "        \"exog_2\": [1010, 1011, 1012, 1013, 1014, 1010, 1011, 1012, 1013, 1014],\n",
    "    },\n",
    "    index=pd.DatetimeIndex(\n",
    "        [\n",
    "            \"2020-01-11\",\n",
    "            \"2020-01-12\",\n",
    "            \"2020-01-13\",\n",
    "            \"2020-01-14\",\n",
    "            \"2020-01-15\",\n",
    "            \"2020-01-11\",\n",
    "            \"2020-01-12\",\n",
    "            \"2020-01-13\",\n",
    "            \"2020-01-14\",\n",
    "            \"2020-01-15\",\n",
    "        ]\n",
    "    ),\n",
    ").astype({\"exog_2\": int})\n",
    "\n",
    "expected_y_test = pd.Series(\n",
    "    [10.0, 11.0, 12.0, 13.0, 14.0, 60.0, 61.0, 62.0, 63.0, 64.0],\n",
    "    index=pd.DatetimeIndex(\n",
    "        [\n",
    "            \"2020-01-11\",\n",
    "            \"2020-01-12\",\n",
    "            \"2020-01-13\",\n",
    "            \"2020-01-14\",\n",
    "            \"2020-01-15\",\n",
    "            \"2020-01-11\",\n",
    "            \"2020-01-12\",\n",
    "            \"2020-01-13\",\n",
    "            \"2020-01-14\",\n",
    "            \"2020-01-15\",\n",
    "        ]\n",
    "    ),\n",
    "    name=\"y\",\n",
    ")\n",
    "\n",
    "expected_X_train_encoding = pd.Series(\n",
    "    [\n",
    "        \"series_1\",\n",
    "        \"series_1\",\n",
    "        \"series_1\",\n",
    "        \"series_1\",\n",
    "        \"series_1\",\n",
    "        \"series_2\",\n",
    "        \"series_2\",\n",
    "        \"series_2\",\n",
    "        \"series_2\",\n",
    "        \"series_2\",\n",
    "    ],\n",
    "    index=pd.DatetimeIndex(\n",
    "        [\n",
    "            \"2020-01-06\",\n",
    "            \"2020-01-07\",\n",
    "            \"2020-01-08\",\n",
    "            \"2020-01-09\",\n",
    "            \"2020-01-10\",\n",
    "            \"2020-01-06\",\n",
    "            \"2020-01-07\",\n",
    "            \"2020-01-08\",\n",
    "            \"2020-01-09\",\n",
    "            \"2020-01-10\",\n",
    "        ]\n",
    "    ),\n",
    ")\n",
    "\n",
    "expected_X_test_encoding = pd.Series(\n",
    "    [\n",
    "        \"series_1\",\n",
    "        \"series_1\",\n",
    "        \"series_1\",\n",
    "        \"series_1\",\n",
    "        \"series_1\",\n",
    "        \"series_2\",\n",
    "        \"series_2\",\n",
    "        \"series_2\",\n",
    "        \"series_2\",\n",
    "        \"series_2\",\n",
    "    ],\n",
    "    index=pd.DatetimeIndex(\n",
    "        [\n",
    "            \"2020-01-11\",\n",
    "            \"2020-01-12\",\n",
    "            \"2020-01-13\",\n",
    "            \"2020-01-14\",\n",
    "            \"2020-01-15\",\n",
    "            \"2020-01-11\",\n",
    "            \"2020-01-12\",\n",
    "            \"2020-01-13\",\n",
    "            \"2020-01-14\",\n",
    "            \"2020-01-15\",\n",
    "        ]\n",
    "    ),\n",
    ")\n",
    "\n",
    "X_test.to_dict(orient='list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5421/2840598471.py:9: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  \"series_2\": pd.Series(np.arange(50, 65, dtype=float), index=pd.date_range(\"2020-01-01\", periods=15, freq=\"H\"))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'series_1': 2020-01-01     0.0\n",
       " 2020-01-02     1.0\n",
       " 2020-01-03     2.0\n",
       " 2020-01-04     3.0\n",
       " 2020-01-05     4.0\n",
       " 2020-01-06     5.0\n",
       " 2020-01-07     6.0\n",
       " 2020-01-08     7.0\n",
       " 2020-01-09     8.0\n",
       " 2020-01-10     9.0\n",
       " 2020-01-11    10.0\n",
       " 2020-01-12    11.0\n",
       " 2020-01-13    12.0\n",
       " 2020-01-14    13.0\n",
       " 2020-01-15    14.0\n",
       " dtype: float64,\n",
       " 'series_2': 2020-01-01 00:00:00    50.0\n",
       " 2020-01-01 01:00:00    51.0\n",
       " 2020-01-01 02:00:00    52.0\n",
       " 2020-01-01 03:00:00    53.0\n",
       " 2020-01-01 04:00:00    54.0\n",
       " 2020-01-01 05:00:00    55.0\n",
       " 2020-01-01 06:00:00    56.0\n",
       " 2020-01-01 07:00:00    57.0\n",
       " 2020-01-01 08:00:00    58.0\n",
       " 2020-01-01 09:00:00    59.0\n",
       " 2020-01-01 10:00:00    60.0\n",
       " 2020-01-01 11:00:00    61.0\n",
       " 2020-01-01 12:00:00    62.0\n",
       " 2020-01-01 13:00:00    63.0\n",
       " 2020-01-01 14:00:00    64.0\n",
       " Freq: h, dtype: float64}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Repeat this code but the series should not have frequency\n",
    "# series = {\n",
    "#             \"series_1\": pd.Series(np.arange(15, dtype=float), index=pd.date_range(\"2020-01-01\", periods=15)),\n",
    "#             \"series_2\": pd.Series(np.arange(50, 65, dtype=float), index=pd.date_range(\"2020-01-01\", periods=15))\n",
    "#         }\n",
    "\n",
    "series = {\n",
    "            \"series_1\": pd.Series(np.arange(15, dtype=float), index=pd.date_range(\"2020-01-01\", periods=15, freq=\"D\")),\n",
    "            \"series_2\": pd.Series(np.arange(50, 65, dtype=float), index=pd.date_range(\"2020-01-01\", periods=15, freq=\"H\"))\n",
    "        }\n",
    "\n",
    "series['series_1'].index.freq = None\n",
    "series['series_2'].index.freq = None\n",
    "series\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expected_X_trian = pd.DataFrame(\n",
    "        {\n",
    "            'lag_1': [4.0, 5.0, 6.0, 7.0, 8.0, 54.0, 55.0, 56.0, 57.0, 58.0],\n",
    "            'lag_2': [3.0, 4.0, 5.0, 6.0, 7.0, 53.0, 54.0, 55.0, 56.0, 57.0],\n",
    "            'lag_3': [2.0, 3.0, 4.0, 5.0, 6.0, 52.0, 53.0, 54.0, 55.0, 56.0],\n",
    "            'lag_4': [1.0, 2.0, 3.0, 4.0, 5.0, 51.0, 52.0, 53.0, 54.0, 55.0],\n",
    "            'lag_5': [0.0, 1.0, 2.0, 3.0, 4.0, 50.0, 51.0, 52.0, 53.0, 54.0],\n",
    "            '_level_skforecast': [0, 0, 0, 0, 0, 1, 1, 1, 1, 1],\n",
    "            'exog_1': [105.0,\n",
    "            106.0,\n",
    "            107.0,\n",
    "            108.0,\n",
    "            109.0,\n",
    "            105.0,\n",
    "            106.0,\n",
    "            107.0,\n",
    "            108.0,\n",
    "            109.0],\n",
    "            'exog_2': [1005, 1006, 1007, 1008, 1009, 1005, 1006, 1007, 1008, 1009]\n",
    "        },\n",
    "        index=pd.DatetimeIndex(\n",
    "            ['2020-01-06', '2020-01-07', '2020-01-08', '2020-01-09', '2020-01-10',\n",
    "             '2020-01-06', '2020-01-07', '2020-01-08', '2020-01-09', '2020-01-10']\n",
    "        ),\n",
    "    ).astype({\"exog_2\": int})\n",
    "\n",
    "expected_X_trian.equals(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/varios/skforecast/skforecast/model_selection_multiseries/model_selection_multiseries.py:1802: UserWarning: One-step-ahead predictions are used for faster model comparison, but they may not fully represent multi-step prediction performance. It is recommended to backtest the final model for a more accurate multi-step performance estimate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce492b8f825243879ea2a75dd118a7b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lags grid:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f52a828ea5f4172bcef2e0804a2d885",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "params grid:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>levels</th>\n",
       "      <th>lags</th>\n",
       "      <th>lags_label</th>\n",
       "      <th>params</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <th>mean_squared_error</th>\n",
       "      <th>mean_absolute_percentage_error</th>\n",
       "      <th>mean_absolute_scaled_error</th>\n",
       "      <th>root_mean_squared_scaled_error</th>\n",
       "      <th>alpha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[item_1]</td>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'alpha': 0.001}</td>\n",
       "      <td>1.154476</td>\n",
       "      <td>2.582983</td>\n",
       "      <td>0.051834</td>\n",
       "      <td>0.774511</td>\n",
       "      <td>0.817991</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     levels             lags       lags_label            params  \\\n",
       "0  [item_1]  [1, 2, 3, 4, 5]  [1, 2, 3, 4, 5]  {'alpha': 0.001}   \n",
       "\n",
       "   mean_absolute_error  mean_squared_error  mean_absolute_percentage_error  \\\n",
       "0             1.154476            2.582983                        0.051834   \n",
       "\n",
       "   mean_absolute_scaled_error  root_mean_squared_scaled_error  alpha  \n",
       "0                    0.774511                        0.817991  0.001  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = ['mean_absolute_error', mean_absolute_percentage_error, mean_absolute_scaled_error]\n",
    "data = fetch_dataset(name=\"items_sales\", verbose=False)\n",
    "data['day_of_week'] = data.index.dayofweek\n",
    "end_train = \"2014-07-15 23:59:00\"\n",
    "initial_train_size = len(data.loc[:end_train, :].copy())\n",
    "data_test = data.loc[end_train:, :].copy()\n",
    "levels = [\"item_1\", \"item_2\", \"item_3\"]\n",
    "exog_features = 'day_of_week'\n",
    "\n",
    "metrics = [\n",
    "    \"mean_absolute_error\",\n",
    "    \"mean_squared_error\",\n",
    "    mean_absolute_percentage_error,\n",
    "    mean_absolute_scaled_error,\n",
    "    root_mean_squared_scaled_error,\n",
    "]\n",
    "steps = 1\n",
    "initial_train_size = 100\n",
    "param_grid = {\n",
    "    \"alpha\": np.logspace(-3, 3, 1),\n",
    "}\n",
    "lags_grid = [5]\n",
    "param_grid = list(ParameterGrid(param_grid))\n",
    "\n",
    "forecaster = ForecasterAutoregMultiSeries(\n",
    "    regressor=Ridge(random_state=678),\n",
    "    lags=5,\n",
    "    transformer_series=StandardScaler(),\n",
    "    transformer_exog=StandardScaler(),\n",
    ")\n",
    "\n",
    "forecaster = ForecasterAutoregMultiVariate(\n",
    "    regressor=Ridge(random_state=678),\n",
    "    lags=3,\n",
    "    steps=1,\n",
    "    level=\"item_1\",\n",
    "    transformer_series=StandardScaler(),\n",
    "    transformer_exog=StandardScaler(),\n",
    ")\n",
    "\n",
    "X_train, y_train, X_test, y_test, X_train_encoding, X_test_encoding = (\n",
    "    forecaster._train_test_split_one_step_ahead(\n",
    "        series=data.loc[:, levels],\n",
    "        exog=data.loc[:, exog_features] if exog_features else None,\n",
    "        initial_train_size=initial_train_size,\n",
    "    )\n",
    ")\n",
    "\n",
    "results_one_step_ahead = _evaluate_grid_hyperparameters_multiseries(\n",
    "        forecaster         = forecaster,\n",
    "        series             = data.loc[:, levels],\n",
    "        exog               = data.loc[:, exog_features] if exog_features else None,\n",
    "        param_grid         = param_grid,\n",
    "        lags_grid          = lags_grid,\n",
    "        metric             = metrics,\n",
    "        initial_train_size = initial_train_size,\n",
    "        method             = 'one_step_ahead',\n",
    "        return_best        = False,\n",
    "        verbose            = False,\n",
    "        show_progress      = True\n",
    "    )\n",
    "\n",
    "results_one_step_ahead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/varios/skforecast/skforecast/ForecasterAutoregMultiSeries/ForecasterAutoregMultiSeries.py:400: UserWarning: When using a linear model, it is recommended to use a transformer_series to ensure all series are in the same scale. You can use, for example, a `StandardScaler` from sklearn.preprocessing.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 92\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, forecaster \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(forecasters):\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;28mprint\u001b[39m(i)\n\u001b[0;32m---> 92\u001b[0m     \u001b[43mtest_evaluate_grid_hyperparameters_equivalent_outputs_backtesting_one_step_ahead\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforecaster\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforecaster\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 26\u001b[0m, in \u001b[0;36mtest_evaluate_grid_hyperparameters_equivalent_outputs_backtesting_one_step_ahead\u001b[0;34m(forecaster)\u001b[0m\n\u001b[1;32m     24\u001b[0m lags_grid \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m7\u001b[39m]\n\u001b[1;32m     25\u001b[0m param_grid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ParameterGrid(param_grid))\n\u001b[0;32m---> 26\u001b[0m results_backtesting \u001b[38;5;241m=\u001b[39m \u001b[43m_evaluate_grid_hyperparameters_multiseries\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforecaster\u001b[49m\u001b[43m         \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mforecaster\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseries\u001b[49m\u001b[43m             \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevels\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m               \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog_features\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mexog_features\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m         \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlags_grid\u001b[49m\u001b[43m          \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlags_grid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m              \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrefit\u001b[49m\u001b[43m              \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m             \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_train_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minitial_train_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m             \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbacktesting\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43maggregate_metric\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maverage\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweighted_average\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpooling\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfixed_train_size\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_best\u001b[49m\u001b[43m        \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m             \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m            \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m     43\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m display(results_backtesting)\n\u001b[1;32m     45\u001b[0m results_one_step_ahead \u001b[38;5;241m=\u001b[39m _evaluate_grid_hyperparameters_multiseries(\n\u001b[1;32m     46\u001b[0m     forecaster         \u001b[38;5;241m=\u001b[39m deepcopy(forecaster),\n\u001b[1;32m     47\u001b[0m     series             \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mloc[:, levels],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     57\u001b[0m     show_progress      \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     58\u001b[0m )\n",
      "File \u001b[0;32m~/varios/skforecast/skforecast/model_selection_multiseries/model_selection_multiseries.py:1901\u001b[0m, in \u001b[0;36m_evaluate_grid_hyperparameters_multiseries\u001b[0;34m(forecaster, series, param_grid, metric, initial_train_size, steps, method, aggregate_metric, fixed_train_size, gap, skip_folds, allow_incomplete_fold, levels, exog, lags_grid, refit, return_best, n_jobs, verbose, show_progress, suppress_warnings, output_file)\u001b[0m\n\u001b[1;32m   1897\u001b[0m forecaster\u001b[38;5;241m.\u001b[39mset_params(params)\n\u001b[1;32m   1899\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbacktesting\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m-> 1901\u001b[0m     metrics, _ \u001b[38;5;241m=\u001b[39m \u001b[43mbacktesting_forecaster_multiseries\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1902\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforecaster\u001b[49m\u001b[43m            \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mforecaster\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1903\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseries\u001b[49m\u001b[43m                \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mseries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1904\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m                  \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1905\u001b[0m \u001b[43m        \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m                 \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1906\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevels\u001b[49m\u001b[43m                \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlevels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1907\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m                \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1908\u001b[0m \u001b[43m        \u001b[49m\u001b[43madd_aggregated_metric\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43madd_aggregated_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1909\u001b[0m \u001b[43m        \u001b[49m\u001b[43minitial_train_size\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minitial_train_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1910\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfixed_train_size\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfixed_train_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1911\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgap\u001b[49m\u001b[43m                   \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mgap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1912\u001b[0m \u001b[43m        \u001b[49m\u001b[43mskip_folds\u001b[49m\u001b[43m            \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mskip_folds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1913\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_incomplete_fold\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mallow_incomplete_fold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1914\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrefit\u001b[49m\u001b[43m                 \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrefit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1915\u001b[0m \u001b[43m        \u001b[49m\u001b[43minterval\u001b[49m\u001b[43m              \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1916\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m               \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1917\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m                \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1918\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[43m         \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1919\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuppress_warnings\u001b[49m\u001b[43m     \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msuppress_warnings\u001b[49m\n\u001b[1;32m   1920\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1922\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1924\u001b[0m     metrics, _ \u001b[38;5;241m=\u001b[39m _predict_and_calculate_metrics_multiseries_one_step_ahead(\n\u001b[1;32m   1925\u001b[0m         forecaster            \u001b[38;5;241m=\u001b[39m forecaster,\n\u001b[1;32m   1926\u001b[0m         series                \u001b[38;5;241m=\u001b[39m series,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1935\u001b[0m         add_aggregated_metric \u001b[38;5;241m=\u001b[39m add_aggregated_metric\n\u001b[1;32m   1936\u001b[0m     )\n",
      "File \u001b[0;32m~/varios/skforecast/skforecast/model_selection_multiseries/model_selection_multiseries.py:1290\u001b[0m, in \u001b[0;36mbacktesting_forecaster_multiseries\u001b[0;34m(forecaster, series, steps, metric, initial_train_size, fixed_train_size, gap, skip_folds, allow_incomplete_fold, levels, add_aggregated_metric, exog, refit, interval, n_boot, random_state, use_in_sample_residuals, n_jobs, verbose, show_progress, suppress_warnings)\u001b[0m\n\u001b[1;32m   1261\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m   1262\u001b[0m         (\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`forecaster` must be of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmulti_series_forecasters\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1263\u001b[0m          \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor all other types of forecasters use the functions available in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1264\u001b[0m          \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe `model_selection` module. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mforecaster_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1265\u001b[0m     )\n\u001b[1;32m   1267\u001b[0m check_backtesting_input(\n\u001b[1;32m   1268\u001b[0m     forecaster              \u001b[38;5;241m=\u001b[39m forecaster,\n\u001b[1;32m   1269\u001b[0m     steps                   \u001b[38;5;241m=\u001b[39m steps,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1287\u001b[0m     suppress_warnings       \u001b[38;5;241m=\u001b[39m suppress_warnings\n\u001b[1;32m   1288\u001b[0m )\n\u001b[0;32m-> 1290\u001b[0m metrics_levels, backtest_predictions \u001b[38;5;241m=\u001b[39m \u001b[43m_backtesting_forecaster_multiseries\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforecaster\u001b[49m\u001b[43m              \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mforecaster\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseries\u001b[49m\u001b[43m                  \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mseries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1293\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m                   \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevels\u001b[49m\u001b[43m                  \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlevels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m                  \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1296\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_aggregated_metric\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43madd_aggregated_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1297\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_train_size\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minitial_train_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfixed_train_size\u001b[49m\u001b[43m        \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfixed_train_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1299\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgap\u001b[49m\u001b[43m                     \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mgap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1300\u001b[0m \u001b[43m    \u001b[49m\u001b[43mskip_folds\u001b[49m\u001b[43m              \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mskip_folds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1301\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_incomplete_fold\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mallow_incomplete_fold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1302\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m                    \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1303\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrefit\u001b[49m\u001b[43m                   \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrefit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1304\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterval\u001b[49m\u001b[43m                \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minterval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1305\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_boot\u001b[49m\u001b[43m                  \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mn_boot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1306\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m            \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1307\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_in_sample_residuals\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43muse_in_sample_residuals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1308\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m                  \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1309\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m                 \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1310\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[43m           \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1311\u001b[0m \u001b[43m    \u001b[49m\u001b[43msuppress_warnings\u001b[49m\u001b[43m       \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msuppress_warnings\u001b[49m\n\u001b[1;32m   1312\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1314\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m metrics_levels, backtest_predictions\n",
      "File \u001b[0;32m~/varios/skforecast/skforecast/model_selection_multiseries/model_selection_multiseries.py:1072\u001b[0m, in \u001b[0;36m_backtesting_forecaster_multiseries\u001b[0;34m(forecaster, series, steps, metric, initial_train_size, fixed_train_size, gap, skip_folds, allow_incomplete_fold, levels, add_aggregated_metric, exog, refit, interval, n_boot, random_state, use_in_sample_residuals, n_jobs, verbose, show_progress, suppress_warnings)\u001b[0m\n\u001b[1;32m   1068\u001b[0m         pred \u001b[38;5;241m=\u001b[39m pred\u001b[38;5;241m.\u001b[39miloc[gap:, ]\n\u001b[1;32m   1070\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pred\n\u001b[0;32m-> 1072\u001b[0m backtest_predictions \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1073\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_predict_forecaster\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1074\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_fold\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata_fold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1075\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforecaster\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mforecaster\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1076\u001b[0m \u001b[43m        \u001b[49m\u001b[43minterval\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minterval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1077\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevels\u001b[49m\u001b[43m     \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlevels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1078\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1079\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata_fold\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata_folds\u001b[49m\n\u001b[1;32m   1080\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1082\u001b[0m backtest_predictions \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(backtest_predictions, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m   1084\u001b[0m levels_in_backtest_predictions \u001b[38;5;241m=\u001b[39m backtest_predictions\u001b[38;5;241m.\u001b[39mcolumns\n",
      "File \u001b[0;32m~/anaconda3/envs/skforecast_13_py12/lib/python3.12/site-packages/joblib/parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/skforecast_13_py12/lib/python3.12/site-packages/joblib/parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/skforecast_13_py12/lib/python3.12/site-packages/joblib/parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data = fetch_dataset(name=\"items_sales\", verbose=False)\n",
    "data['day_of_week'] = data.index.dayofweek\n",
    "end_train = \"2014-07-15 23:59:00\"\n",
    "initial_train_size = len(data.loc[:end_train, :].copy())\n",
    "levels = [\"item_1\", \"item_2\", \"item_3\"]\n",
    "exog_features = ['day_of_week']\n",
    "\n",
    "def test_evaluate_grid_hyperparameters_equivalent_outputs_backtesting_one_step_ahead(\n",
    "    forecaster,\n",
    "):\n",
    "\n",
    "    metrics = [\n",
    "        \"mean_absolute_error\",\n",
    "        \"mean_squared_error\",\n",
    "        mean_absolute_percentage_error,\n",
    "        mean_absolute_scaled_error,\n",
    "        root_mean_squared_scaled_error,\n",
    "    ]\n",
    "    steps = 1\n",
    "    initial_train_size = 1000\n",
    "    param_grid = {\n",
    "        \"alpha\": np.logspace(-1, 1, 3),\n",
    "    }\n",
    "    lags_grid = [3, 7]\n",
    "    param_grid = list(ParameterGrid(param_grid))\n",
    "    results_backtesting = _evaluate_grid_hyperparameters_multiseries(\n",
    "        forecaster         = deepcopy(forecaster),\n",
    "        series             = data.loc[:, levels],\n",
    "        exog               = data.loc[:, exog_features] if exog_features else None,\n",
    "        param_grid         = param_grid,\n",
    "        lags_grid          = lags_grid,\n",
    "        steps              = steps,\n",
    "        refit              = False,\n",
    "        metric             = metrics,\n",
    "        initial_train_size = initial_train_size,\n",
    "        method             = 'backtesting',\n",
    "        aggregate_metric   = [\"average\", \"weighted_average\", \"pooling\"],\n",
    "        fixed_train_size   = False,\n",
    "        return_best        = False,\n",
    "        n_jobs             = 'auto',\n",
    "        verbose            = False,\n",
    "        show_progress      = False\n",
    "    )\n",
    "    display(results_backtesting)\n",
    "    results_one_step_ahead = _evaluate_grid_hyperparameters_multiseries(\n",
    "        forecaster         = deepcopy(forecaster),\n",
    "        series             = data.loc[:, levels],\n",
    "        exog               = data.loc[:, exog_features] if exog_features else None,\n",
    "        param_grid         = param_grid,\n",
    "        lags_grid          = lags_grid,\n",
    "        metric             = metrics,\n",
    "        initial_train_size = initial_train_size,\n",
    "        method             = 'one_step_ahead',\n",
    "        aggregate_metric   = [\"average\", \"weighted_average\", \"pooling\"],\n",
    "        return_best        = False,\n",
    "        verbose            = False,\n",
    "        show_progress      = False\n",
    "    )\n",
    "\n",
    "    display(results_backtesting)\n",
    "    pd.testing.assert_frame_equal(results_backtesting, results_one_step_ahead)\n",
    "\n",
    "\n",
    "regressor = Ridge(random_state=678)\n",
    "forecasters = [\n",
    "    # Diferenciation must be 0 for this test\n",
    "    ForecasterAutoregMultiSeries(regressor=regressor, lags=3),\n",
    "    ForecasterAutoregMultiSeries(\n",
    "        regressor=regressor,\n",
    "        lags=3,\n",
    "        transformer_series=None,\n",
    "    ),\n",
    "    ForecasterAutoregMultiSeries(\n",
    "        regressor=regressor,\n",
    "        lags=3,\n",
    "        transformer_series=StandardScaler(),\n",
    "        transformer_exog=StandardScaler()\n",
    "    ),\n",
    "    ForecasterAutoregMultiVariate(\n",
    "        regressor=regressor,\n",
    "        level='item_1',\n",
    "        lags=3,\n",
    "        steps=1,\n",
    "        transformer_series=StandardScaler(),\n",
    "        transformer_exog=StandardScaler()\n",
    "    )\n",
    "\n",
    "]\n",
    "\n",
    "for i, forecaster in enumerate(forecasters):\n",
    "    print(i)\n",
    "    test_evaluate_grid_hyperparameters_equivalent_outputs_backtesting_one_step_ahead(\n",
    "        forecaster=forecaster\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/varios/skforecast/skforecast/ForecasterAutoregMultiSeries/ForecasterAutoregMultiSeries.py:400: UserWarning: When using a linear model, it is recommended to use a transformer_series to ensure all series are in the same scale. You can use, for example, a `StandardScaler` from sklearn.preprocessing.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>levels</th>\n",
       "      <th>lags</th>\n",
       "      <th>lags_label</th>\n",
       "      <th>params</th>\n",
       "      <th>mean_absolute_error__average</th>\n",
       "      <th>mean_absolute_error__weighted_average</th>\n",
       "      <th>mean_absolute_error__pooling</th>\n",
       "      <th>mean_squared_error__average</th>\n",
       "      <th>mean_squared_error__weighted_average</th>\n",
       "      <th>mean_squared_error__pooling</th>\n",
       "      <th>mean_absolute_percentage_error__average</th>\n",
       "      <th>mean_absolute_percentage_error__weighted_average</th>\n",
       "      <th>mean_absolute_percentage_error__pooling</th>\n",
       "      <th>mean_absolute_scaled_error__average</th>\n",
       "      <th>mean_absolute_scaled_error__weighted_average</th>\n",
       "      <th>mean_absolute_scaled_error__pooling</th>\n",
       "      <th>root_mean_squared_scaled_error__average</th>\n",
       "      <th>root_mean_squared_scaled_error__weighted_average</th>\n",
       "      <th>root_mean_squared_scaled_error__pooling</th>\n",
       "      <th>alpha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[l1, l2]</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'alpha': 0.1}</td>\n",
       "      <td>0.181897</td>\n",
       "      <td>0.181897</td>\n",
       "      <td>0.181897</td>\n",
       "      <td>0.048689</td>\n",
       "      <td>0.048689</td>\n",
       "      <td>0.048689</td>\n",
       "      <td>1.034332</td>\n",
       "      <td>1.034332</td>\n",
       "      <td>1.034332</td>\n",
       "      <td>0.696273</td>\n",
       "      <td>0.696273</td>\n",
       "      <td>0.694963</td>\n",
       "      <td>0.673709</td>\n",
       "      <td>0.673709</td>\n",
       "      <td>0.674524</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[l1, l2]</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'alpha': 1.0}</td>\n",
       "      <td>0.187109</td>\n",
       "      <td>0.187109</td>\n",
       "      <td>0.187109</td>\n",
       "      <td>0.050646</td>\n",
       "      <td>0.050646</td>\n",
       "      <td>0.050646</td>\n",
       "      <td>1.114850</td>\n",
       "      <td>1.114850</td>\n",
       "      <td>1.114850</td>\n",
       "      <td>0.716711</td>\n",
       "      <td>0.716711</td>\n",
       "      <td>0.714877</td>\n",
       "      <td>0.686177</td>\n",
       "      <td>0.686177</td>\n",
       "      <td>0.687946</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[l1, l2]</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7]</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7]</td>\n",
       "      <td>{'alpha': 0.1}</td>\n",
       "      <td>0.199475</td>\n",
       "      <td>0.199475</td>\n",
       "      <td>0.199475</td>\n",
       "      <td>0.061923</td>\n",
       "      <td>0.061923</td>\n",
       "      <td>0.061923</td>\n",
       "      <td>1.171530</td>\n",
       "      <td>1.171530</td>\n",
       "      <td>1.171530</td>\n",
       "      <td>0.745361</td>\n",
       "      <td>0.745361</td>\n",
       "      <td>0.743463</td>\n",
       "      <td>0.738244</td>\n",
       "      <td>0.738244</td>\n",
       "      <td>0.730532</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[l1, l2]</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7]</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7]</td>\n",
       "      <td>{'alpha': 1.0}</td>\n",
       "      <td>0.200192</td>\n",
       "      <td>0.200192</td>\n",
       "      <td>0.200192</td>\n",
       "      <td>0.058144</td>\n",
       "      <td>0.058144</td>\n",
       "      <td>0.058144</td>\n",
       "      <td>1.239896</td>\n",
       "      <td>1.239896</td>\n",
       "      <td>1.239896</td>\n",
       "      <td>0.746616</td>\n",
       "      <td>0.746616</td>\n",
       "      <td>0.746137</td>\n",
       "      <td>0.715926</td>\n",
       "      <td>0.715926</td>\n",
       "      <td>0.707888</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[l1, l2]</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'alpha': 10.0}</td>\n",
       "      <td>0.206143</td>\n",
       "      <td>0.206143</td>\n",
       "      <td>0.206143</td>\n",
       "      <td>0.060303</td>\n",
       "      <td>0.060303</td>\n",
       "      <td>0.060303</td>\n",
       "      <td>1.267311</td>\n",
       "      <td>1.267311</td>\n",
       "      <td>1.267311</td>\n",
       "      <td>0.790667</td>\n",
       "      <td>0.790667</td>\n",
       "      <td>0.787598</td>\n",
       "      <td>0.747907</td>\n",
       "      <td>0.747907</td>\n",
       "      <td>0.750675</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[l1, l2]</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7]</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7]</td>\n",
       "      <td>{'alpha': 10.0}</td>\n",
       "      <td>0.207645</td>\n",
       "      <td>0.207645</td>\n",
       "      <td>0.207645</td>\n",
       "      <td>0.062203</td>\n",
       "      <td>0.062203</td>\n",
       "      <td>0.062203</td>\n",
       "      <td>1.294716</td>\n",
       "      <td>1.294716</td>\n",
       "      <td>1.294716</td>\n",
       "      <td>0.773001</td>\n",
       "      <td>0.773001</td>\n",
       "      <td>0.773914</td>\n",
       "      <td>0.738505</td>\n",
       "      <td>0.738505</td>\n",
       "      <td>0.732181</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     levels                   lags             lags_label           params  \\\n",
       "0  [l1, l2]              [1, 2, 3]              [1, 2, 3]   {'alpha': 0.1}   \n",
       "1  [l1, l2]              [1, 2, 3]              [1, 2, 3]   {'alpha': 1.0}   \n",
       "2  [l1, l2]  [1, 2, 3, 4, 5, 6, 7]  [1, 2, 3, 4, 5, 6, 7]   {'alpha': 0.1}   \n",
       "3  [l1, l2]  [1, 2, 3, 4, 5, 6, 7]  [1, 2, 3, 4, 5, 6, 7]   {'alpha': 1.0}   \n",
       "4  [l1, l2]              [1, 2, 3]              [1, 2, 3]  {'alpha': 10.0}   \n",
       "5  [l1, l2]  [1, 2, 3, 4, 5, 6, 7]  [1, 2, 3, 4, 5, 6, 7]  {'alpha': 10.0}   \n",
       "\n",
       "   mean_absolute_error__average  mean_absolute_error__weighted_average  \\\n",
       "0                      0.181897                               0.181897   \n",
       "1                      0.187109                               0.187109   \n",
       "2                      0.199475                               0.199475   \n",
       "3                      0.200192                               0.200192   \n",
       "4                      0.206143                               0.206143   \n",
       "5                      0.207645                               0.207645   \n",
       "\n",
       "   mean_absolute_error__pooling  mean_squared_error__average  \\\n",
       "0                      0.181897                     0.048689   \n",
       "1                      0.187109                     0.050646   \n",
       "2                      0.199475                     0.061923   \n",
       "3                      0.200192                     0.058144   \n",
       "4                      0.206143                     0.060303   \n",
       "5                      0.207645                     0.062203   \n",
       "\n",
       "   mean_squared_error__weighted_average  mean_squared_error__pooling  \\\n",
       "0                              0.048689                     0.048689   \n",
       "1                              0.050646                     0.050646   \n",
       "2                              0.061923                     0.061923   \n",
       "3                              0.058144                     0.058144   \n",
       "4                              0.060303                     0.060303   \n",
       "5                              0.062203                     0.062203   \n",
       "\n",
       "   mean_absolute_percentage_error__average  \\\n",
       "0                                 1.034332   \n",
       "1                                 1.114850   \n",
       "2                                 1.171530   \n",
       "3                                 1.239896   \n",
       "4                                 1.267311   \n",
       "5                                 1.294716   \n",
       "\n",
       "   mean_absolute_percentage_error__weighted_average  \\\n",
       "0                                          1.034332   \n",
       "1                                          1.114850   \n",
       "2                                          1.171530   \n",
       "3                                          1.239896   \n",
       "4                                          1.267311   \n",
       "5                                          1.294716   \n",
       "\n",
       "   mean_absolute_percentage_error__pooling  \\\n",
       "0                                 1.034332   \n",
       "1                                 1.114850   \n",
       "2                                 1.171530   \n",
       "3                                 1.239896   \n",
       "4                                 1.267311   \n",
       "5                                 1.294716   \n",
       "\n",
       "   mean_absolute_scaled_error__average  \\\n",
       "0                             0.696273   \n",
       "1                             0.716711   \n",
       "2                             0.745361   \n",
       "3                             0.746616   \n",
       "4                             0.790667   \n",
       "5                             0.773001   \n",
       "\n",
       "   mean_absolute_scaled_error__weighted_average  \\\n",
       "0                                      0.696273   \n",
       "1                                      0.716711   \n",
       "2                                      0.745361   \n",
       "3                                      0.746616   \n",
       "4                                      0.790667   \n",
       "5                                      0.773001   \n",
       "\n",
       "   mean_absolute_scaled_error__pooling  \\\n",
       "0                             0.694963   \n",
       "1                             0.714877   \n",
       "2                             0.743463   \n",
       "3                             0.746137   \n",
       "4                             0.787598   \n",
       "5                             0.773914   \n",
       "\n",
       "   root_mean_squared_scaled_error__average  \\\n",
       "0                                 0.673709   \n",
       "1                                 0.686177   \n",
       "2                                 0.738244   \n",
       "3                                 0.715926   \n",
       "4                                 0.747907   \n",
       "5                                 0.738505   \n",
       "\n",
       "   root_mean_squared_scaled_error__weighted_average  \\\n",
       "0                                          0.673709   \n",
       "1                                          0.686177   \n",
       "2                                          0.738244   \n",
       "3                                          0.715926   \n",
       "4                                          0.747907   \n",
       "5                                          0.738505   \n",
       "\n",
       "   root_mean_squared_scaled_error__pooling  alpha  \n",
       "0                                 0.674524    0.1  \n",
       "1                                 0.687946    1.0  \n",
       "2                                 0.730532    0.1  \n",
       "3                                 0.707888    1.0  \n",
       "4                                 0.750675   10.0  \n",
       "5                                 0.732181   10.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/varios/skforecast/skforecast/model_selection_multiseries/model_selection_multiseries.py:1802: UserWarning: One-step-ahead predictions are used for faster model comparison, but they may not fully represent multi-step prediction performance. It is recommended to backtest the final model for a more accurate multi-step performance estimate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>levels</th>\n",
       "      <th>lags</th>\n",
       "      <th>lags_label</th>\n",
       "      <th>params</th>\n",
       "      <th>mean_absolute_error__average</th>\n",
       "      <th>mean_absolute_error__weighted_average</th>\n",
       "      <th>mean_absolute_error__pooling</th>\n",
       "      <th>mean_squared_error__average</th>\n",
       "      <th>mean_squared_error__weighted_average</th>\n",
       "      <th>mean_squared_error__pooling</th>\n",
       "      <th>mean_absolute_percentage_error__average</th>\n",
       "      <th>mean_absolute_percentage_error__weighted_average</th>\n",
       "      <th>mean_absolute_percentage_error__pooling</th>\n",
       "      <th>mean_absolute_scaled_error__average</th>\n",
       "      <th>mean_absolute_scaled_error__weighted_average</th>\n",
       "      <th>mean_absolute_scaled_error__pooling</th>\n",
       "      <th>root_mean_squared_scaled_error__average</th>\n",
       "      <th>root_mean_squared_scaled_error__weighted_average</th>\n",
       "      <th>root_mean_squared_scaled_error__pooling</th>\n",
       "      <th>alpha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[l1, l2]</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'alpha': 0.1}</td>\n",
       "      <td>0.181897</td>\n",
       "      <td>0.181897</td>\n",
       "      <td>0.181897</td>\n",
       "      <td>0.048689</td>\n",
       "      <td>0.048689</td>\n",
       "      <td>0.048689</td>\n",
       "      <td>1.034332</td>\n",
       "      <td>1.034332</td>\n",
       "      <td>1.034332</td>\n",
       "      <td>0.696273</td>\n",
       "      <td>0.696273</td>\n",
       "      <td>0.694963</td>\n",
       "      <td>0.673709</td>\n",
       "      <td>0.673709</td>\n",
       "      <td>0.674524</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[l1, l2]</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'alpha': 1.0}</td>\n",
       "      <td>0.187109</td>\n",
       "      <td>0.187109</td>\n",
       "      <td>0.187109</td>\n",
       "      <td>0.050646</td>\n",
       "      <td>0.050646</td>\n",
       "      <td>0.050646</td>\n",
       "      <td>1.114850</td>\n",
       "      <td>1.114850</td>\n",
       "      <td>1.114850</td>\n",
       "      <td>0.716711</td>\n",
       "      <td>0.716711</td>\n",
       "      <td>0.714877</td>\n",
       "      <td>0.686177</td>\n",
       "      <td>0.686177</td>\n",
       "      <td>0.687946</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[l1, l2]</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7]</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7]</td>\n",
       "      <td>{'alpha': 0.1}</td>\n",
       "      <td>0.199475</td>\n",
       "      <td>0.199475</td>\n",
       "      <td>0.199475</td>\n",
       "      <td>0.061923</td>\n",
       "      <td>0.061923</td>\n",
       "      <td>0.061923</td>\n",
       "      <td>1.171530</td>\n",
       "      <td>1.171530</td>\n",
       "      <td>1.171530</td>\n",
       "      <td>0.745361</td>\n",
       "      <td>0.745361</td>\n",
       "      <td>0.743463</td>\n",
       "      <td>0.738244</td>\n",
       "      <td>0.738244</td>\n",
       "      <td>0.730532</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[l1, l2]</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7]</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7]</td>\n",
       "      <td>{'alpha': 1.0}</td>\n",
       "      <td>0.200192</td>\n",
       "      <td>0.200192</td>\n",
       "      <td>0.200192</td>\n",
       "      <td>0.058144</td>\n",
       "      <td>0.058144</td>\n",
       "      <td>0.058144</td>\n",
       "      <td>1.239896</td>\n",
       "      <td>1.239896</td>\n",
       "      <td>1.239896</td>\n",
       "      <td>0.746616</td>\n",
       "      <td>0.746616</td>\n",
       "      <td>0.746137</td>\n",
       "      <td>0.715926</td>\n",
       "      <td>0.715926</td>\n",
       "      <td>0.707888</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[l1, l2]</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'alpha': 10.0}</td>\n",
       "      <td>0.206143</td>\n",
       "      <td>0.206143</td>\n",
       "      <td>0.206143</td>\n",
       "      <td>0.060303</td>\n",
       "      <td>0.060303</td>\n",
       "      <td>0.060303</td>\n",
       "      <td>1.267311</td>\n",
       "      <td>1.267311</td>\n",
       "      <td>1.267311</td>\n",
       "      <td>0.790667</td>\n",
       "      <td>0.790667</td>\n",
       "      <td>0.787598</td>\n",
       "      <td>0.747907</td>\n",
       "      <td>0.747907</td>\n",
       "      <td>0.750675</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[l1, l2]</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7]</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7]</td>\n",
       "      <td>{'alpha': 10.0}</td>\n",
       "      <td>0.207645</td>\n",
       "      <td>0.207645</td>\n",
       "      <td>0.207645</td>\n",
       "      <td>0.062203</td>\n",
       "      <td>0.062203</td>\n",
       "      <td>0.062203</td>\n",
       "      <td>1.294716</td>\n",
       "      <td>1.294716</td>\n",
       "      <td>1.294716</td>\n",
       "      <td>0.773001</td>\n",
       "      <td>0.773001</td>\n",
       "      <td>0.773914</td>\n",
       "      <td>0.738505</td>\n",
       "      <td>0.738505</td>\n",
       "      <td>0.732181</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     levels                   lags             lags_label           params  \\\n",
       "0  [l1, l2]              [1, 2, 3]              [1, 2, 3]   {'alpha': 0.1}   \n",
       "1  [l1, l2]              [1, 2, 3]              [1, 2, 3]   {'alpha': 1.0}   \n",
       "2  [l1, l2]  [1, 2, 3, 4, 5, 6, 7]  [1, 2, 3, 4, 5, 6, 7]   {'alpha': 0.1}   \n",
       "3  [l1, l2]  [1, 2, 3, 4, 5, 6, 7]  [1, 2, 3, 4, 5, 6, 7]   {'alpha': 1.0}   \n",
       "4  [l1, l2]              [1, 2, 3]              [1, 2, 3]  {'alpha': 10.0}   \n",
       "5  [l1, l2]  [1, 2, 3, 4, 5, 6, 7]  [1, 2, 3, 4, 5, 6, 7]  {'alpha': 10.0}   \n",
       "\n",
       "   mean_absolute_error__average  mean_absolute_error__weighted_average  \\\n",
       "0                      0.181897                               0.181897   \n",
       "1                      0.187109                               0.187109   \n",
       "2                      0.199475                               0.199475   \n",
       "3                      0.200192                               0.200192   \n",
       "4                      0.206143                               0.206143   \n",
       "5                      0.207645                               0.207645   \n",
       "\n",
       "   mean_absolute_error__pooling  mean_squared_error__average  \\\n",
       "0                      0.181897                     0.048689   \n",
       "1                      0.187109                     0.050646   \n",
       "2                      0.199475                     0.061923   \n",
       "3                      0.200192                     0.058144   \n",
       "4                      0.206143                     0.060303   \n",
       "5                      0.207645                     0.062203   \n",
       "\n",
       "   mean_squared_error__weighted_average  mean_squared_error__pooling  \\\n",
       "0                              0.048689                     0.048689   \n",
       "1                              0.050646                     0.050646   \n",
       "2                              0.061923                     0.061923   \n",
       "3                              0.058144                     0.058144   \n",
       "4                              0.060303                     0.060303   \n",
       "5                              0.062203                     0.062203   \n",
       "\n",
       "   mean_absolute_percentage_error__average  \\\n",
       "0                                 1.034332   \n",
       "1                                 1.114850   \n",
       "2                                 1.171530   \n",
       "3                                 1.239896   \n",
       "4                                 1.267311   \n",
       "5                                 1.294716   \n",
       "\n",
       "   mean_absolute_percentage_error__weighted_average  \\\n",
       "0                                          1.034332   \n",
       "1                                          1.114850   \n",
       "2                                          1.171530   \n",
       "3                                          1.239896   \n",
       "4                                          1.267311   \n",
       "5                                          1.294716   \n",
       "\n",
       "   mean_absolute_percentage_error__pooling  \\\n",
       "0                                 1.034332   \n",
       "1                                 1.114850   \n",
       "2                                 1.171530   \n",
       "3                                 1.239896   \n",
       "4                                 1.267311   \n",
       "5                                 1.294716   \n",
       "\n",
       "   mean_absolute_scaled_error__average  \\\n",
       "0                             0.696273   \n",
       "1                             0.716711   \n",
       "2                             0.745361   \n",
       "3                             0.746616   \n",
       "4                             0.790667   \n",
       "5                             0.773001   \n",
       "\n",
       "   mean_absolute_scaled_error__weighted_average  \\\n",
       "0                                      0.696273   \n",
       "1                                      0.716711   \n",
       "2                                      0.745361   \n",
       "3                                      0.746616   \n",
       "4                                      0.790667   \n",
       "5                                      0.773001   \n",
       "\n",
       "   mean_absolute_scaled_error__pooling  \\\n",
       "0                             0.694963   \n",
       "1                             0.714877   \n",
       "2                             0.743463   \n",
       "3                             0.746137   \n",
       "4                             0.787598   \n",
       "5                             0.773914   \n",
       "\n",
       "   root_mean_squared_scaled_error__average  \\\n",
       "0                                 0.673709   \n",
       "1                                 0.686177   \n",
       "2                                 0.738244   \n",
       "3                                 0.715926   \n",
       "4                                 0.747907   \n",
       "5                                 0.738505   \n",
       "\n",
       "   root_mean_squared_scaled_error__weighted_average  \\\n",
       "0                                          0.673709   \n",
       "1                                          0.686177   \n",
       "2                                          0.738244   \n",
       "3                                          0.715926   \n",
       "4                                          0.747907   \n",
       "5                                          0.738505   \n",
       "\n",
       "   root_mean_squared_scaled_error__pooling  alpha  \n",
       "0                                 0.674524    0.1  \n",
       "1                                 0.687946    1.0  \n",
       "2                                 0.730532    0.1  \n",
       "3                                 0.707888    1.0  \n",
       "4                                 0.750675   10.0  \n",
       "5                                 0.732181   10.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>levels</th>\n",
       "      <th>lags</th>\n",
       "      <th>lags_label</th>\n",
       "      <th>params</th>\n",
       "      <th>mean_absolute_error__average</th>\n",
       "      <th>mean_absolute_error__weighted_average</th>\n",
       "      <th>mean_absolute_error__pooling</th>\n",
       "      <th>mean_squared_error__average</th>\n",
       "      <th>mean_squared_error__weighted_average</th>\n",
       "      <th>mean_squared_error__pooling</th>\n",
       "      <th>mean_absolute_percentage_error__average</th>\n",
       "      <th>mean_absolute_percentage_error__weighted_average</th>\n",
       "      <th>mean_absolute_percentage_error__pooling</th>\n",
       "      <th>mean_absolute_scaled_error__average</th>\n",
       "      <th>mean_absolute_scaled_error__weighted_average</th>\n",
       "      <th>mean_absolute_scaled_error__pooling</th>\n",
       "      <th>root_mean_squared_scaled_error__average</th>\n",
       "      <th>root_mean_squared_scaled_error__weighted_average</th>\n",
       "      <th>root_mean_squared_scaled_error__pooling</th>\n",
       "      <th>alpha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[l1, l2]</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'alpha': 0.1}</td>\n",
       "      <td>0.181897</td>\n",
       "      <td>0.181897</td>\n",
       "      <td>0.181897</td>\n",
       "      <td>0.048689</td>\n",
       "      <td>0.048689</td>\n",
       "      <td>0.048689</td>\n",
       "      <td>1.034332</td>\n",
       "      <td>1.034332</td>\n",
       "      <td>1.034332</td>\n",
       "      <td>0.696273</td>\n",
       "      <td>0.696273</td>\n",
       "      <td>0.694963</td>\n",
       "      <td>0.673709</td>\n",
       "      <td>0.673709</td>\n",
       "      <td>0.674524</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[l1, l2]</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'alpha': 1.0}</td>\n",
       "      <td>0.187109</td>\n",
       "      <td>0.187109</td>\n",
       "      <td>0.187109</td>\n",
       "      <td>0.050646</td>\n",
       "      <td>0.050646</td>\n",
       "      <td>0.050646</td>\n",
       "      <td>1.114850</td>\n",
       "      <td>1.114850</td>\n",
       "      <td>1.114850</td>\n",
       "      <td>0.716711</td>\n",
       "      <td>0.716711</td>\n",
       "      <td>0.714877</td>\n",
       "      <td>0.686177</td>\n",
       "      <td>0.686177</td>\n",
       "      <td>0.687946</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[l1, l2]</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7]</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7]</td>\n",
       "      <td>{'alpha': 0.1}</td>\n",
       "      <td>0.199475</td>\n",
       "      <td>0.199475</td>\n",
       "      <td>0.199475</td>\n",
       "      <td>0.061923</td>\n",
       "      <td>0.061923</td>\n",
       "      <td>0.061923</td>\n",
       "      <td>1.171530</td>\n",
       "      <td>1.171530</td>\n",
       "      <td>1.171530</td>\n",
       "      <td>0.745361</td>\n",
       "      <td>0.745361</td>\n",
       "      <td>0.743463</td>\n",
       "      <td>0.738244</td>\n",
       "      <td>0.738244</td>\n",
       "      <td>0.730532</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[l1, l2]</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7]</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7]</td>\n",
       "      <td>{'alpha': 1.0}</td>\n",
       "      <td>0.200192</td>\n",
       "      <td>0.200192</td>\n",
       "      <td>0.200192</td>\n",
       "      <td>0.058144</td>\n",
       "      <td>0.058144</td>\n",
       "      <td>0.058144</td>\n",
       "      <td>1.239896</td>\n",
       "      <td>1.239896</td>\n",
       "      <td>1.239896</td>\n",
       "      <td>0.746616</td>\n",
       "      <td>0.746616</td>\n",
       "      <td>0.746137</td>\n",
       "      <td>0.715926</td>\n",
       "      <td>0.715926</td>\n",
       "      <td>0.707888</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[l1, l2]</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'alpha': 10.0}</td>\n",
       "      <td>0.206143</td>\n",
       "      <td>0.206143</td>\n",
       "      <td>0.206143</td>\n",
       "      <td>0.060303</td>\n",
       "      <td>0.060303</td>\n",
       "      <td>0.060303</td>\n",
       "      <td>1.267311</td>\n",
       "      <td>1.267311</td>\n",
       "      <td>1.267311</td>\n",
       "      <td>0.790667</td>\n",
       "      <td>0.790667</td>\n",
       "      <td>0.787598</td>\n",
       "      <td>0.747907</td>\n",
       "      <td>0.747907</td>\n",
       "      <td>0.750675</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[l1, l2]</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7]</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7]</td>\n",
       "      <td>{'alpha': 10.0}</td>\n",
       "      <td>0.207645</td>\n",
       "      <td>0.207645</td>\n",
       "      <td>0.207645</td>\n",
       "      <td>0.062203</td>\n",
       "      <td>0.062203</td>\n",
       "      <td>0.062203</td>\n",
       "      <td>1.294716</td>\n",
       "      <td>1.294716</td>\n",
       "      <td>1.294716</td>\n",
       "      <td>0.773001</td>\n",
       "      <td>0.773001</td>\n",
       "      <td>0.773914</td>\n",
       "      <td>0.738505</td>\n",
       "      <td>0.738505</td>\n",
       "      <td>0.732181</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     levels                   lags             lags_label           params  \\\n",
       "0  [l1, l2]              [1, 2, 3]              [1, 2, 3]   {'alpha': 0.1}   \n",
       "1  [l1, l2]              [1, 2, 3]              [1, 2, 3]   {'alpha': 1.0}   \n",
       "2  [l1, l2]  [1, 2, 3, 4, 5, 6, 7]  [1, 2, 3, 4, 5, 6, 7]   {'alpha': 0.1}   \n",
       "3  [l1, l2]  [1, 2, 3, 4, 5, 6, 7]  [1, 2, 3, 4, 5, 6, 7]   {'alpha': 1.0}   \n",
       "4  [l1, l2]              [1, 2, 3]              [1, 2, 3]  {'alpha': 10.0}   \n",
       "5  [l1, l2]  [1, 2, 3, 4, 5, 6, 7]  [1, 2, 3, 4, 5, 6, 7]  {'alpha': 10.0}   \n",
       "\n",
       "   mean_absolute_error__average  mean_absolute_error__weighted_average  \\\n",
       "0                      0.181897                               0.181897   \n",
       "1                      0.187109                               0.187109   \n",
       "2                      0.199475                               0.199475   \n",
       "3                      0.200192                               0.200192   \n",
       "4                      0.206143                               0.206143   \n",
       "5                      0.207645                               0.207645   \n",
       "\n",
       "   mean_absolute_error__pooling  mean_squared_error__average  \\\n",
       "0                      0.181897                     0.048689   \n",
       "1                      0.187109                     0.050646   \n",
       "2                      0.199475                     0.061923   \n",
       "3                      0.200192                     0.058144   \n",
       "4                      0.206143                     0.060303   \n",
       "5                      0.207645                     0.062203   \n",
       "\n",
       "   mean_squared_error__weighted_average  mean_squared_error__pooling  \\\n",
       "0                              0.048689                     0.048689   \n",
       "1                              0.050646                     0.050646   \n",
       "2                              0.061923                     0.061923   \n",
       "3                              0.058144                     0.058144   \n",
       "4                              0.060303                     0.060303   \n",
       "5                              0.062203                     0.062203   \n",
       "\n",
       "   mean_absolute_percentage_error__average  \\\n",
       "0                                 1.034332   \n",
       "1                                 1.114850   \n",
       "2                                 1.171530   \n",
       "3                                 1.239896   \n",
       "4                                 1.267311   \n",
       "5                                 1.294716   \n",
       "\n",
       "   mean_absolute_percentage_error__weighted_average  \\\n",
       "0                                          1.034332   \n",
       "1                                          1.114850   \n",
       "2                                          1.171530   \n",
       "3                                          1.239896   \n",
       "4                                          1.267311   \n",
       "5                                          1.294716   \n",
       "\n",
       "   mean_absolute_percentage_error__pooling  \\\n",
       "0                                 1.034332   \n",
       "1                                 1.114850   \n",
       "2                                 1.171530   \n",
       "3                                 1.239896   \n",
       "4                                 1.267311   \n",
       "5                                 1.294716   \n",
       "\n",
       "   mean_absolute_scaled_error__average  \\\n",
       "0                             0.696273   \n",
       "1                             0.716711   \n",
       "2                             0.745361   \n",
       "3                             0.746616   \n",
       "4                             0.790667   \n",
       "5                             0.773001   \n",
       "\n",
       "   mean_absolute_scaled_error__weighted_average  \\\n",
       "0                                      0.696273   \n",
       "1                                      0.716711   \n",
       "2                                      0.745361   \n",
       "3                                      0.746616   \n",
       "4                                      0.790667   \n",
       "5                                      0.773001   \n",
       "\n",
       "   mean_absolute_scaled_error__pooling  \\\n",
       "0                             0.694963   \n",
       "1                             0.714877   \n",
       "2                             0.743463   \n",
       "3                             0.746137   \n",
       "4                             0.787598   \n",
       "5                             0.773914   \n",
       "\n",
       "   root_mean_squared_scaled_error__average  \\\n",
       "0                                 0.673709   \n",
       "1                                 0.686177   \n",
       "2                                 0.738244   \n",
       "3                                 0.715926   \n",
       "4                                 0.747907   \n",
       "5                                 0.738505   \n",
       "\n",
       "   root_mean_squared_scaled_error__weighted_average  \\\n",
       "0                                          0.673709   \n",
       "1                                          0.686177   \n",
       "2                                          0.738244   \n",
       "3                                          0.715926   \n",
       "4                                          0.747907   \n",
       "5                                          0.738505   \n",
       "\n",
       "   root_mean_squared_scaled_error__pooling  alpha  \n",
       "0                                 0.674524    0.1  \n",
       "1                                 0.687946    1.0  \n",
       "2                                 0.730532    0.1  \n",
       "3                                 0.707888    1.0  \n",
       "4                                 0.750675   10.0  \n",
       "5                                 0.732181   10.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/varios/skforecast/skforecast/model_selection_multiseries/model_selection_multiseries.py:1802: UserWarning: One-step-ahead predictions are used for faster model comparison, but they may not fully represent multi-step prediction performance. It is recommended to backtest the final model for a more accurate multi-step performance estimate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>levels</th>\n",
       "      <th>lags</th>\n",
       "      <th>lags_label</th>\n",
       "      <th>params</th>\n",
       "      <th>mean_absolute_error__average</th>\n",
       "      <th>mean_absolute_error__weighted_average</th>\n",
       "      <th>mean_absolute_error__pooling</th>\n",
       "      <th>mean_squared_error__average</th>\n",
       "      <th>mean_squared_error__weighted_average</th>\n",
       "      <th>mean_squared_error__pooling</th>\n",
       "      <th>mean_absolute_percentage_error__average</th>\n",
       "      <th>mean_absolute_percentage_error__weighted_average</th>\n",
       "      <th>mean_absolute_percentage_error__pooling</th>\n",
       "      <th>mean_absolute_scaled_error__average</th>\n",
       "      <th>mean_absolute_scaled_error__weighted_average</th>\n",
       "      <th>mean_absolute_scaled_error__pooling</th>\n",
       "      <th>root_mean_squared_scaled_error__average</th>\n",
       "      <th>root_mean_squared_scaled_error__weighted_average</th>\n",
       "      <th>root_mean_squared_scaled_error__pooling</th>\n",
       "      <th>alpha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[l1, l2]</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'alpha': 0.1}</td>\n",
       "      <td>0.181897</td>\n",
       "      <td>0.181897</td>\n",
       "      <td>0.181897</td>\n",
       "      <td>0.048689</td>\n",
       "      <td>0.048689</td>\n",
       "      <td>0.048689</td>\n",
       "      <td>1.034332</td>\n",
       "      <td>1.034332</td>\n",
       "      <td>1.034332</td>\n",
       "      <td>0.696273</td>\n",
       "      <td>0.696273</td>\n",
       "      <td>0.694963</td>\n",
       "      <td>0.673709</td>\n",
       "      <td>0.673709</td>\n",
       "      <td>0.674524</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[l1, l2]</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'alpha': 1.0}</td>\n",
       "      <td>0.187109</td>\n",
       "      <td>0.187109</td>\n",
       "      <td>0.187109</td>\n",
       "      <td>0.050646</td>\n",
       "      <td>0.050646</td>\n",
       "      <td>0.050646</td>\n",
       "      <td>1.114850</td>\n",
       "      <td>1.114850</td>\n",
       "      <td>1.114850</td>\n",
       "      <td>0.716711</td>\n",
       "      <td>0.716711</td>\n",
       "      <td>0.714877</td>\n",
       "      <td>0.686177</td>\n",
       "      <td>0.686177</td>\n",
       "      <td>0.687946</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[l1, l2]</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7]</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7]</td>\n",
       "      <td>{'alpha': 0.1}</td>\n",
       "      <td>0.199475</td>\n",
       "      <td>0.199475</td>\n",
       "      <td>0.199475</td>\n",
       "      <td>0.061923</td>\n",
       "      <td>0.061923</td>\n",
       "      <td>0.061923</td>\n",
       "      <td>1.171530</td>\n",
       "      <td>1.171530</td>\n",
       "      <td>1.171530</td>\n",
       "      <td>0.745361</td>\n",
       "      <td>0.745361</td>\n",
       "      <td>0.743463</td>\n",
       "      <td>0.738244</td>\n",
       "      <td>0.738244</td>\n",
       "      <td>0.730532</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[l1, l2]</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7]</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7]</td>\n",
       "      <td>{'alpha': 1.0}</td>\n",
       "      <td>0.200192</td>\n",
       "      <td>0.200192</td>\n",
       "      <td>0.200192</td>\n",
       "      <td>0.058144</td>\n",
       "      <td>0.058144</td>\n",
       "      <td>0.058144</td>\n",
       "      <td>1.239896</td>\n",
       "      <td>1.239896</td>\n",
       "      <td>1.239896</td>\n",
       "      <td>0.746616</td>\n",
       "      <td>0.746616</td>\n",
       "      <td>0.746137</td>\n",
       "      <td>0.715926</td>\n",
       "      <td>0.715926</td>\n",
       "      <td>0.707888</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[l1, l2]</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'alpha': 10.0}</td>\n",
       "      <td>0.206143</td>\n",
       "      <td>0.206143</td>\n",
       "      <td>0.206143</td>\n",
       "      <td>0.060303</td>\n",
       "      <td>0.060303</td>\n",
       "      <td>0.060303</td>\n",
       "      <td>1.267311</td>\n",
       "      <td>1.267311</td>\n",
       "      <td>1.267311</td>\n",
       "      <td>0.790667</td>\n",
       "      <td>0.790667</td>\n",
       "      <td>0.787598</td>\n",
       "      <td>0.747907</td>\n",
       "      <td>0.747907</td>\n",
       "      <td>0.750675</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[l1, l2]</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7]</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7]</td>\n",
       "      <td>{'alpha': 10.0}</td>\n",
       "      <td>0.207645</td>\n",
       "      <td>0.207645</td>\n",
       "      <td>0.207645</td>\n",
       "      <td>0.062203</td>\n",
       "      <td>0.062203</td>\n",
       "      <td>0.062203</td>\n",
       "      <td>1.294716</td>\n",
       "      <td>1.294716</td>\n",
       "      <td>1.294716</td>\n",
       "      <td>0.773001</td>\n",
       "      <td>0.773001</td>\n",
       "      <td>0.773914</td>\n",
       "      <td>0.738505</td>\n",
       "      <td>0.738505</td>\n",
       "      <td>0.732181</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     levels                   lags             lags_label           params  \\\n",
       "0  [l1, l2]              [1, 2, 3]              [1, 2, 3]   {'alpha': 0.1}   \n",
       "1  [l1, l2]              [1, 2, 3]              [1, 2, 3]   {'alpha': 1.0}   \n",
       "2  [l1, l2]  [1, 2, 3, 4, 5, 6, 7]  [1, 2, 3, 4, 5, 6, 7]   {'alpha': 0.1}   \n",
       "3  [l1, l2]  [1, 2, 3, 4, 5, 6, 7]  [1, 2, 3, 4, 5, 6, 7]   {'alpha': 1.0}   \n",
       "4  [l1, l2]              [1, 2, 3]              [1, 2, 3]  {'alpha': 10.0}   \n",
       "5  [l1, l2]  [1, 2, 3, 4, 5, 6, 7]  [1, 2, 3, 4, 5, 6, 7]  {'alpha': 10.0}   \n",
       "\n",
       "   mean_absolute_error__average  mean_absolute_error__weighted_average  \\\n",
       "0                      0.181897                               0.181897   \n",
       "1                      0.187109                               0.187109   \n",
       "2                      0.199475                               0.199475   \n",
       "3                      0.200192                               0.200192   \n",
       "4                      0.206143                               0.206143   \n",
       "5                      0.207645                               0.207645   \n",
       "\n",
       "   mean_absolute_error__pooling  mean_squared_error__average  \\\n",
       "0                      0.181897                     0.048689   \n",
       "1                      0.187109                     0.050646   \n",
       "2                      0.199475                     0.061923   \n",
       "3                      0.200192                     0.058144   \n",
       "4                      0.206143                     0.060303   \n",
       "5                      0.207645                     0.062203   \n",
       "\n",
       "   mean_squared_error__weighted_average  mean_squared_error__pooling  \\\n",
       "0                              0.048689                     0.048689   \n",
       "1                              0.050646                     0.050646   \n",
       "2                              0.061923                     0.061923   \n",
       "3                              0.058144                     0.058144   \n",
       "4                              0.060303                     0.060303   \n",
       "5                              0.062203                     0.062203   \n",
       "\n",
       "   mean_absolute_percentage_error__average  \\\n",
       "0                                 1.034332   \n",
       "1                                 1.114850   \n",
       "2                                 1.171530   \n",
       "3                                 1.239896   \n",
       "4                                 1.267311   \n",
       "5                                 1.294716   \n",
       "\n",
       "   mean_absolute_percentage_error__weighted_average  \\\n",
       "0                                          1.034332   \n",
       "1                                          1.114850   \n",
       "2                                          1.171530   \n",
       "3                                          1.239896   \n",
       "4                                          1.267311   \n",
       "5                                          1.294716   \n",
       "\n",
       "   mean_absolute_percentage_error__pooling  \\\n",
       "0                                 1.034332   \n",
       "1                                 1.114850   \n",
       "2                                 1.171530   \n",
       "3                                 1.239896   \n",
       "4                                 1.267311   \n",
       "5                                 1.294716   \n",
       "\n",
       "   mean_absolute_scaled_error__average  \\\n",
       "0                             0.696273   \n",
       "1                             0.716711   \n",
       "2                             0.745361   \n",
       "3                             0.746616   \n",
       "4                             0.790667   \n",
       "5                             0.773001   \n",
       "\n",
       "   mean_absolute_scaled_error__weighted_average  \\\n",
       "0                                      0.696273   \n",
       "1                                      0.716711   \n",
       "2                                      0.745361   \n",
       "3                                      0.746616   \n",
       "4                                      0.790667   \n",
       "5                                      0.773001   \n",
       "\n",
       "   mean_absolute_scaled_error__pooling  \\\n",
       "0                             0.694963   \n",
       "1                             0.714877   \n",
       "2                             0.743463   \n",
       "3                             0.746137   \n",
       "4                             0.787598   \n",
       "5                             0.773914   \n",
       "\n",
       "   root_mean_squared_scaled_error__average  \\\n",
       "0                                 0.673709   \n",
       "1                                 0.686177   \n",
       "2                                 0.738244   \n",
       "3                                 0.715926   \n",
       "4                                 0.747907   \n",
       "5                                 0.738505   \n",
       "\n",
       "   root_mean_squared_scaled_error__weighted_average  \\\n",
       "0                                          0.673709   \n",
       "1                                          0.686177   \n",
       "2                                          0.738244   \n",
       "3                                          0.715926   \n",
       "4                                          0.747907   \n",
       "5                                          0.738505   \n",
       "\n",
       "   root_mean_squared_scaled_error__pooling  alpha  \n",
       "0                                 0.674524    0.1  \n",
       "1                                 0.687946    1.0  \n",
       "2                                 0.730532    0.1  \n",
       "3                                 0.707888    1.0  \n",
       "4                                 0.750675   10.0  \n",
       "5                                 0.732181   10.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>levels</th>\n",
       "      <th>lags</th>\n",
       "      <th>lags_label</th>\n",
       "      <th>params</th>\n",
       "      <th>mean_absolute_error__average</th>\n",
       "      <th>mean_absolute_error__weighted_average</th>\n",
       "      <th>mean_absolute_error__pooling</th>\n",
       "      <th>mean_squared_error__average</th>\n",
       "      <th>mean_squared_error__weighted_average</th>\n",
       "      <th>mean_squared_error__pooling</th>\n",
       "      <th>mean_absolute_percentage_error__average</th>\n",
       "      <th>mean_absolute_percentage_error__weighted_average</th>\n",
       "      <th>mean_absolute_percentage_error__pooling</th>\n",
       "      <th>mean_absolute_scaled_error__average</th>\n",
       "      <th>mean_absolute_scaled_error__weighted_average</th>\n",
       "      <th>mean_absolute_scaled_error__pooling</th>\n",
       "      <th>root_mean_squared_scaled_error__average</th>\n",
       "      <th>root_mean_squared_scaled_error__weighted_average</th>\n",
       "      <th>root_mean_squared_scaled_error__pooling</th>\n",
       "      <th>alpha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[l1, l2]</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'alpha': 0.1}</td>\n",
       "      <td>0.182203</td>\n",
       "      <td>0.182203</td>\n",
       "      <td>0.182203</td>\n",
       "      <td>0.048846</td>\n",
       "      <td>0.048846</td>\n",
       "      <td>0.048846</td>\n",
       "      <td>1.027423</td>\n",
       "      <td>1.027423</td>\n",
       "      <td>1.027423</td>\n",
       "      <td>0.697561</td>\n",
       "      <td>0.697561</td>\n",
       "      <td>0.696131</td>\n",
       "      <td>0.674418</td>\n",
       "      <td>0.674418</td>\n",
       "      <td>0.675612</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[l1, l2]</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'alpha': 1.0}</td>\n",
       "      <td>0.182259</td>\n",
       "      <td>0.182259</td>\n",
       "      <td>0.182259</td>\n",
       "      <td>0.048839</td>\n",
       "      <td>0.048839</td>\n",
       "      <td>0.048839</td>\n",
       "      <td>1.034999</td>\n",
       "      <td>1.034999</td>\n",
       "      <td>1.034999</td>\n",
       "      <td>0.697837</td>\n",
       "      <td>0.697837</td>\n",
       "      <td>0.696346</td>\n",
       "      <td>0.674234</td>\n",
       "      <td>0.674234</td>\n",
       "      <td>0.675564</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[l1, l2]</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'alpha': 10.0}</td>\n",
       "      <td>0.185275</td>\n",
       "      <td>0.185275</td>\n",
       "      <td>0.185275</td>\n",
       "      <td>0.050052</td>\n",
       "      <td>0.050052</td>\n",
       "      <td>0.050052</td>\n",
       "      <td>1.098270</td>\n",
       "      <td>1.098270</td>\n",
       "      <td>1.098270</td>\n",
       "      <td>0.709829</td>\n",
       "      <td>0.709829</td>\n",
       "      <td>0.707868</td>\n",
       "      <td>0.681587</td>\n",
       "      <td>0.681587</td>\n",
       "      <td>0.683902</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[l1, l2]</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7]</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7]</td>\n",
       "      <td>{'alpha': 10.0}</td>\n",
       "      <td>0.193272</td>\n",
       "      <td>0.193272</td>\n",
       "      <td>0.193272</td>\n",
       "      <td>0.055314</td>\n",
       "      <td>0.055314</td>\n",
       "      <td>0.055314</td>\n",
       "      <td>1.207098</td>\n",
       "      <td>1.207098</td>\n",
       "      <td>1.207098</td>\n",
       "      <td>0.720035</td>\n",
       "      <td>0.720035</td>\n",
       "      <td>0.720344</td>\n",
       "      <td>0.694680</td>\n",
       "      <td>0.694680</td>\n",
       "      <td>0.690446</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[l1, l2]</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7]</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7]</td>\n",
       "      <td>{'alpha': 1.0}</td>\n",
       "      <td>0.198754</td>\n",
       "      <td>0.198754</td>\n",
       "      <td>0.198754</td>\n",
       "      <td>0.061508</td>\n",
       "      <td>0.061508</td>\n",
       "      <td>0.061508</td>\n",
       "      <td>1.165742</td>\n",
       "      <td>1.165742</td>\n",
       "      <td>1.165742</td>\n",
       "      <td>0.741826</td>\n",
       "      <td>0.741826</td>\n",
       "      <td>0.740777</td>\n",
       "      <td>0.734049</td>\n",
       "      <td>0.734049</td>\n",
       "      <td>0.728079</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[l1, l2]</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7]</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7]</td>\n",
       "      <td>{'alpha': 0.1}</td>\n",
       "      <td>0.203171</td>\n",
       "      <td>0.203171</td>\n",
       "      <td>0.203171</td>\n",
       "      <td>0.064074</td>\n",
       "      <td>0.064074</td>\n",
       "      <td>0.064074</td>\n",
       "      <td>1.164854</td>\n",
       "      <td>1.164854</td>\n",
       "      <td>1.164854</td>\n",
       "      <td>0.758583</td>\n",
       "      <td>0.758583</td>\n",
       "      <td>0.757238</td>\n",
       "      <td>0.749397</td>\n",
       "      <td>0.749397</td>\n",
       "      <td>0.743113</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     levels                   lags             lags_label           params  \\\n",
       "0  [l1, l2]              [1, 2, 3]              [1, 2, 3]   {'alpha': 0.1}   \n",
       "1  [l1, l2]              [1, 2, 3]              [1, 2, 3]   {'alpha': 1.0}   \n",
       "2  [l1, l2]              [1, 2, 3]              [1, 2, 3]  {'alpha': 10.0}   \n",
       "3  [l1, l2]  [1, 2, 3, 4, 5, 6, 7]  [1, 2, 3, 4, 5, 6, 7]  {'alpha': 10.0}   \n",
       "4  [l1, l2]  [1, 2, 3, 4, 5, 6, 7]  [1, 2, 3, 4, 5, 6, 7]   {'alpha': 1.0}   \n",
       "5  [l1, l2]  [1, 2, 3, 4, 5, 6, 7]  [1, 2, 3, 4, 5, 6, 7]   {'alpha': 0.1}   \n",
       "\n",
       "   mean_absolute_error__average  mean_absolute_error__weighted_average  \\\n",
       "0                      0.182203                               0.182203   \n",
       "1                      0.182259                               0.182259   \n",
       "2                      0.185275                               0.185275   \n",
       "3                      0.193272                               0.193272   \n",
       "4                      0.198754                               0.198754   \n",
       "5                      0.203171                               0.203171   \n",
       "\n",
       "   mean_absolute_error__pooling  mean_squared_error__average  \\\n",
       "0                      0.182203                     0.048846   \n",
       "1                      0.182259                     0.048839   \n",
       "2                      0.185275                     0.050052   \n",
       "3                      0.193272                     0.055314   \n",
       "4                      0.198754                     0.061508   \n",
       "5                      0.203171                     0.064074   \n",
       "\n",
       "   mean_squared_error__weighted_average  mean_squared_error__pooling  \\\n",
       "0                              0.048846                     0.048846   \n",
       "1                              0.048839                     0.048839   \n",
       "2                              0.050052                     0.050052   \n",
       "3                              0.055314                     0.055314   \n",
       "4                              0.061508                     0.061508   \n",
       "5                              0.064074                     0.064074   \n",
       "\n",
       "   mean_absolute_percentage_error__average  \\\n",
       "0                                 1.027423   \n",
       "1                                 1.034999   \n",
       "2                                 1.098270   \n",
       "3                                 1.207098   \n",
       "4                                 1.165742   \n",
       "5                                 1.164854   \n",
       "\n",
       "   mean_absolute_percentage_error__weighted_average  \\\n",
       "0                                          1.027423   \n",
       "1                                          1.034999   \n",
       "2                                          1.098270   \n",
       "3                                          1.207098   \n",
       "4                                          1.165742   \n",
       "5                                          1.164854   \n",
       "\n",
       "   mean_absolute_percentage_error__pooling  \\\n",
       "0                                 1.027423   \n",
       "1                                 1.034999   \n",
       "2                                 1.098270   \n",
       "3                                 1.207098   \n",
       "4                                 1.165742   \n",
       "5                                 1.164854   \n",
       "\n",
       "   mean_absolute_scaled_error__average  \\\n",
       "0                             0.697561   \n",
       "1                             0.697837   \n",
       "2                             0.709829   \n",
       "3                             0.720035   \n",
       "4                             0.741826   \n",
       "5                             0.758583   \n",
       "\n",
       "   mean_absolute_scaled_error__weighted_average  \\\n",
       "0                                      0.697561   \n",
       "1                                      0.697837   \n",
       "2                                      0.709829   \n",
       "3                                      0.720035   \n",
       "4                                      0.741826   \n",
       "5                                      0.758583   \n",
       "\n",
       "   mean_absolute_scaled_error__pooling  \\\n",
       "0                             0.696131   \n",
       "1                             0.696346   \n",
       "2                             0.707868   \n",
       "3                             0.720344   \n",
       "4                             0.740777   \n",
       "5                             0.757238   \n",
       "\n",
       "   root_mean_squared_scaled_error__average  \\\n",
       "0                                 0.674418   \n",
       "1                                 0.674234   \n",
       "2                                 0.681587   \n",
       "3                                 0.694680   \n",
       "4                                 0.734049   \n",
       "5                                 0.749397   \n",
       "\n",
       "   root_mean_squared_scaled_error__weighted_average  \\\n",
       "0                                          0.674418   \n",
       "1                                          0.674234   \n",
       "2                                          0.681587   \n",
       "3                                          0.694680   \n",
       "4                                          0.734049   \n",
       "5                                          0.749397   \n",
       "\n",
       "   root_mean_squared_scaled_error__pooling  alpha  \n",
       "0                                 0.675612    0.1  \n",
       "1                                 0.675564    1.0  \n",
       "2                                 0.683902   10.0  \n",
       "3                                 0.690446   10.0  \n",
       "4                                 0.728079    1.0  \n",
       "5                                 0.743113    0.1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/varios/skforecast/skforecast/model_selection_multiseries/model_selection_multiseries.py:1802: UserWarning: One-step-ahead predictions are used for faster model comparison, but they may not fully represent multi-step prediction performance. It is recommended to backtest the final model for a more accurate multi-step performance estimate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>levels</th>\n",
       "      <th>lags</th>\n",
       "      <th>lags_label</th>\n",
       "      <th>params</th>\n",
       "      <th>mean_absolute_error__average</th>\n",
       "      <th>mean_absolute_error__weighted_average</th>\n",
       "      <th>mean_absolute_error__pooling</th>\n",
       "      <th>mean_squared_error__average</th>\n",
       "      <th>mean_squared_error__weighted_average</th>\n",
       "      <th>mean_squared_error__pooling</th>\n",
       "      <th>mean_absolute_percentage_error__average</th>\n",
       "      <th>mean_absolute_percentage_error__weighted_average</th>\n",
       "      <th>mean_absolute_percentage_error__pooling</th>\n",
       "      <th>mean_absolute_scaled_error__average</th>\n",
       "      <th>mean_absolute_scaled_error__weighted_average</th>\n",
       "      <th>mean_absolute_scaled_error__pooling</th>\n",
       "      <th>root_mean_squared_scaled_error__average</th>\n",
       "      <th>root_mean_squared_scaled_error__weighted_average</th>\n",
       "      <th>root_mean_squared_scaled_error__pooling</th>\n",
       "      <th>alpha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[l1, l2]</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'alpha': 0.1}</td>\n",
       "      <td>0.182203</td>\n",
       "      <td>0.182203</td>\n",
       "      <td>0.182203</td>\n",
       "      <td>0.048846</td>\n",
       "      <td>0.048846</td>\n",
       "      <td>0.048846</td>\n",
       "      <td>1.027423</td>\n",
       "      <td>1.027423</td>\n",
       "      <td>1.027423</td>\n",
       "      <td>0.697561</td>\n",
       "      <td>0.697561</td>\n",
       "      <td>0.696131</td>\n",
       "      <td>0.674418</td>\n",
       "      <td>0.674418</td>\n",
       "      <td>0.675612</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[l1, l2]</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'alpha': 1.0}</td>\n",
       "      <td>0.182259</td>\n",
       "      <td>0.182259</td>\n",
       "      <td>0.182259</td>\n",
       "      <td>0.048839</td>\n",
       "      <td>0.048839</td>\n",
       "      <td>0.048839</td>\n",
       "      <td>1.034999</td>\n",
       "      <td>1.034999</td>\n",
       "      <td>1.034999</td>\n",
       "      <td>0.697837</td>\n",
       "      <td>0.697837</td>\n",
       "      <td>0.696346</td>\n",
       "      <td>0.674234</td>\n",
       "      <td>0.674234</td>\n",
       "      <td>0.675564</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[l1, l2]</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'alpha': 10.0}</td>\n",
       "      <td>0.185275</td>\n",
       "      <td>0.185275</td>\n",
       "      <td>0.185275</td>\n",
       "      <td>0.050052</td>\n",
       "      <td>0.050052</td>\n",
       "      <td>0.050052</td>\n",
       "      <td>1.098270</td>\n",
       "      <td>1.098270</td>\n",
       "      <td>1.098270</td>\n",
       "      <td>0.709829</td>\n",
       "      <td>0.709829</td>\n",
       "      <td>0.707868</td>\n",
       "      <td>0.681587</td>\n",
       "      <td>0.681587</td>\n",
       "      <td>0.683902</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[l1, l2]</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7]</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7]</td>\n",
       "      <td>{'alpha': 10.0}</td>\n",
       "      <td>0.193272</td>\n",
       "      <td>0.193272</td>\n",
       "      <td>0.193272</td>\n",
       "      <td>0.055314</td>\n",
       "      <td>0.055314</td>\n",
       "      <td>0.055314</td>\n",
       "      <td>1.207098</td>\n",
       "      <td>1.207098</td>\n",
       "      <td>1.207098</td>\n",
       "      <td>0.720035</td>\n",
       "      <td>0.720035</td>\n",
       "      <td>0.720344</td>\n",
       "      <td>0.694680</td>\n",
       "      <td>0.694680</td>\n",
       "      <td>0.690446</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[l1, l2]</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7]</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7]</td>\n",
       "      <td>{'alpha': 1.0}</td>\n",
       "      <td>0.198754</td>\n",
       "      <td>0.198754</td>\n",
       "      <td>0.198754</td>\n",
       "      <td>0.061508</td>\n",
       "      <td>0.061508</td>\n",
       "      <td>0.061508</td>\n",
       "      <td>1.165742</td>\n",
       "      <td>1.165742</td>\n",
       "      <td>1.165742</td>\n",
       "      <td>0.741826</td>\n",
       "      <td>0.741826</td>\n",
       "      <td>0.740777</td>\n",
       "      <td>0.734049</td>\n",
       "      <td>0.734049</td>\n",
       "      <td>0.728079</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[l1, l2]</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7]</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7]</td>\n",
       "      <td>{'alpha': 0.1}</td>\n",
       "      <td>0.203171</td>\n",
       "      <td>0.203171</td>\n",
       "      <td>0.203171</td>\n",
       "      <td>0.064074</td>\n",
       "      <td>0.064074</td>\n",
       "      <td>0.064074</td>\n",
       "      <td>1.164854</td>\n",
       "      <td>1.164854</td>\n",
       "      <td>1.164854</td>\n",
       "      <td>0.758583</td>\n",
       "      <td>0.758583</td>\n",
       "      <td>0.757238</td>\n",
       "      <td>0.749397</td>\n",
       "      <td>0.749397</td>\n",
       "      <td>0.743113</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     levels                   lags             lags_label           params  \\\n",
       "0  [l1, l2]              [1, 2, 3]              [1, 2, 3]   {'alpha': 0.1}   \n",
       "1  [l1, l2]              [1, 2, 3]              [1, 2, 3]   {'alpha': 1.0}   \n",
       "2  [l1, l2]              [1, 2, 3]              [1, 2, 3]  {'alpha': 10.0}   \n",
       "3  [l1, l2]  [1, 2, 3, 4, 5, 6, 7]  [1, 2, 3, 4, 5, 6, 7]  {'alpha': 10.0}   \n",
       "4  [l1, l2]  [1, 2, 3, 4, 5, 6, 7]  [1, 2, 3, 4, 5, 6, 7]   {'alpha': 1.0}   \n",
       "5  [l1, l2]  [1, 2, 3, 4, 5, 6, 7]  [1, 2, 3, 4, 5, 6, 7]   {'alpha': 0.1}   \n",
       "\n",
       "   mean_absolute_error__average  mean_absolute_error__weighted_average  \\\n",
       "0                      0.182203                               0.182203   \n",
       "1                      0.182259                               0.182259   \n",
       "2                      0.185275                               0.185275   \n",
       "3                      0.193272                               0.193272   \n",
       "4                      0.198754                               0.198754   \n",
       "5                      0.203171                               0.203171   \n",
       "\n",
       "   mean_absolute_error__pooling  mean_squared_error__average  \\\n",
       "0                      0.182203                     0.048846   \n",
       "1                      0.182259                     0.048839   \n",
       "2                      0.185275                     0.050052   \n",
       "3                      0.193272                     0.055314   \n",
       "4                      0.198754                     0.061508   \n",
       "5                      0.203171                     0.064074   \n",
       "\n",
       "   mean_squared_error__weighted_average  mean_squared_error__pooling  \\\n",
       "0                              0.048846                     0.048846   \n",
       "1                              0.048839                     0.048839   \n",
       "2                              0.050052                     0.050052   \n",
       "3                              0.055314                     0.055314   \n",
       "4                              0.061508                     0.061508   \n",
       "5                              0.064074                     0.064074   \n",
       "\n",
       "   mean_absolute_percentage_error__average  \\\n",
       "0                                 1.027423   \n",
       "1                                 1.034999   \n",
       "2                                 1.098270   \n",
       "3                                 1.207098   \n",
       "4                                 1.165742   \n",
       "5                                 1.164854   \n",
       "\n",
       "   mean_absolute_percentage_error__weighted_average  \\\n",
       "0                                          1.027423   \n",
       "1                                          1.034999   \n",
       "2                                          1.098270   \n",
       "3                                          1.207098   \n",
       "4                                          1.165742   \n",
       "5                                          1.164854   \n",
       "\n",
       "   mean_absolute_percentage_error__pooling  \\\n",
       "0                                 1.027423   \n",
       "1                                 1.034999   \n",
       "2                                 1.098270   \n",
       "3                                 1.207098   \n",
       "4                                 1.165742   \n",
       "5                                 1.164854   \n",
       "\n",
       "   mean_absolute_scaled_error__average  \\\n",
       "0                             0.697561   \n",
       "1                             0.697837   \n",
       "2                             0.709829   \n",
       "3                             0.720035   \n",
       "4                             0.741826   \n",
       "5                             0.758583   \n",
       "\n",
       "   mean_absolute_scaled_error__weighted_average  \\\n",
       "0                                      0.697561   \n",
       "1                                      0.697837   \n",
       "2                                      0.709829   \n",
       "3                                      0.720035   \n",
       "4                                      0.741826   \n",
       "5                                      0.758583   \n",
       "\n",
       "   mean_absolute_scaled_error__pooling  \\\n",
       "0                             0.696131   \n",
       "1                             0.696346   \n",
       "2                             0.707868   \n",
       "3                             0.720344   \n",
       "4                             0.740777   \n",
       "5                             0.757238   \n",
       "\n",
       "   root_mean_squared_scaled_error__average  \\\n",
       "0                                 0.674418   \n",
       "1                                 0.674234   \n",
       "2                                 0.681587   \n",
       "3                                 0.694680   \n",
       "4                                 0.734049   \n",
       "5                                 0.749397   \n",
       "\n",
       "   root_mean_squared_scaled_error__weighted_average  \\\n",
       "0                                          0.674418   \n",
       "1                                          0.674234   \n",
       "2                                          0.681587   \n",
       "3                                          0.694680   \n",
       "4                                          0.734049   \n",
       "5                                          0.749397   \n",
       "\n",
       "   root_mean_squared_scaled_error__pooling  alpha  \n",
       "0                                 0.675612    0.1  \n",
       "1                                 0.675564    1.0  \n",
       "2                                 0.683902   10.0  \n",
       "3                                 0.690446   10.0  \n",
       "4                                 0.728079    1.0  \n",
       "5                                 0.743113    0.1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>levels</th>\n",
       "      <th>lags</th>\n",
       "      <th>lags_label</th>\n",
       "      <th>params</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <th>mean_squared_error</th>\n",
       "      <th>mean_absolute_percentage_error</th>\n",
       "      <th>mean_absolute_scaled_error</th>\n",
       "      <th>root_mean_squared_scaled_error</th>\n",
       "      <th>alpha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[l1]</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'alpha': 0.1}</td>\n",
       "      <td>0.073671</td>\n",
       "      <td>0.009153</td>\n",
       "      <td>0.180190</td>\n",
       "      <td>0.273346</td>\n",
       "      <td>0.301710</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[l1]</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'alpha': 1.0}</td>\n",
       "      <td>0.077623</td>\n",
       "      <td>0.009842</td>\n",
       "      <td>0.208891</td>\n",
       "      <td>0.288008</td>\n",
       "      <td>0.312861</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[l1]</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'alpha': 10.0}</td>\n",
       "      <td>0.110021</td>\n",
       "      <td>0.018882</td>\n",
       "      <td>0.343295</td>\n",
       "      <td>0.408219</td>\n",
       "      <td>0.433336</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[l1]</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7]</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7]</td>\n",
       "      <td>{'alpha': 10.0}</td>\n",
       "      <td>0.179616</td>\n",
       "      <td>0.046386</td>\n",
       "      <td>0.502170</td>\n",
       "      <td>0.719871</td>\n",
       "      <td>0.713240</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[l1]</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7]</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7]</td>\n",
       "      <td>{'alpha': 1.0}</td>\n",
       "      <td>0.203850</td>\n",
       "      <td>0.057269</td>\n",
       "      <td>0.550379</td>\n",
       "      <td>0.816998</td>\n",
       "      <td>0.792510</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[l1]</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7]</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7]</td>\n",
       "      <td>{'alpha': 0.1}</td>\n",
       "      <td>0.215648</td>\n",
       "      <td>0.063630</td>\n",
       "      <td>0.576964</td>\n",
       "      <td>0.864284</td>\n",
       "      <td>0.835361</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  levels                   lags             lags_label           params  \\\n",
       "0   [l1]              [1, 2, 3]              [1, 2, 3]   {'alpha': 0.1}   \n",
       "1   [l1]              [1, 2, 3]              [1, 2, 3]   {'alpha': 1.0}   \n",
       "2   [l1]              [1, 2, 3]              [1, 2, 3]  {'alpha': 10.0}   \n",
       "3   [l1]  [1, 2, 3, 4, 5, 6, 7]  [1, 2, 3, 4, 5, 6, 7]  {'alpha': 10.0}   \n",
       "4   [l1]  [1, 2, 3, 4, 5, 6, 7]  [1, 2, 3, 4, 5, 6, 7]   {'alpha': 1.0}   \n",
       "5   [l1]  [1, 2, 3, 4, 5, 6, 7]  [1, 2, 3, 4, 5, 6, 7]   {'alpha': 0.1}   \n",
       "\n",
       "   mean_absolute_error  mean_squared_error  mean_absolute_percentage_error  \\\n",
       "0             0.073671            0.009153                        0.180190   \n",
       "1             0.077623            0.009842                        0.208891   \n",
       "2             0.110021            0.018882                        0.343295   \n",
       "3             0.179616            0.046386                        0.502170   \n",
       "4             0.203850            0.057269                        0.550379   \n",
       "5             0.215648            0.063630                        0.576964   \n",
       "\n",
       "   mean_absolute_scaled_error  root_mean_squared_scaled_error  alpha  \n",
       "0                    0.273346                        0.301710    0.1  \n",
       "1                    0.288008                        0.312861    1.0  \n",
       "2                    0.408219                        0.433336   10.0  \n",
       "3                    0.719871                        0.713240   10.0  \n",
       "4                    0.816998                        0.792510    1.0  \n",
       "5                    0.864284                        0.835361    0.1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/varios/skforecast/skforecast/model_selection_multiseries/model_selection_multiseries.py:1802: UserWarning: One-step-ahead predictions are used for faster model comparison, but they may not fully represent multi-step prediction performance. It is recommended to backtest the final model for a more accurate multi-step performance estimate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>levels</th>\n",
       "      <th>lags</th>\n",
       "      <th>lags_label</th>\n",
       "      <th>params</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <th>mean_squared_error</th>\n",
       "      <th>mean_absolute_percentage_error</th>\n",
       "      <th>mean_absolute_scaled_error</th>\n",
       "      <th>root_mean_squared_scaled_error</th>\n",
       "      <th>alpha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[l1]</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'alpha': 0.1}</td>\n",
       "      <td>0.073671</td>\n",
       "      <td>0.009153</td>\n",
       "      <td>0.180190</td>\n",
       "      <td>0.273346</td>\n",
       "      <td>0.301710</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[l1]</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'alpha': 1.0}</td>\n",
       "      <td>0.077623</td>\n",
       "      <td>0.009842</td>\n",
       "      <td>0.208891</td>\n",
       "      <td>0.288008</td>\n",
       "      <td>0.312861</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[l1]</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'alpha': 10.0}</td>\n",
       "      <td>0.110021</td>\n",
       "      <td>0.018882</td>\n",
       "      <td>0.343295</td>\n",
       "      <td>0.408219</td>\n",
       "      <td>0.433336</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[l1]</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7]</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7]</td>\n",
       "      <td>{'alpha': 10.0}</td>\n",
       "      <td>0.179616</td>\n",
       "      <td>0.046386</td>\n",
       "      <td>0.502170</td>\n",
       "      <td>0.719871</td>\n",
       "      <td>0.713240</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[l1]</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7]</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7]</td>\n",
       "      <td>{'alpha': 1.0}</td>\n",
       "      <td>0.203850</td>\n",
       "      <td>0.057269</td>\n",
       "      <td>0.550379</td>\n",
       "      <td>0.816998</td>\n",
       "      <td>0.792510</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[l1]</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7]</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7]</td>\n",
       "      <td>{'alpha': 0.1}</td>\n",
       "      <td>0.215648</td>\n",
       "      <td>0.063630</td>\n",
       "      <td>0.576964</td>\n",
       "      <td>0.864284</td>\n",
       "      <td>0.835361</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  levels                   lags             lags_label           params  \\\n",
       "0   [l1]              [1, 2, 3]              [1, 2, 3]   {'alpha': 0.1}   \n",
       "1   [l1]              [1, 2, 3]              [1, 2, 3]   {'alpha': 1.0}   \n",
       "2   [l1]              [1, 2, 3]              [1, 2, 3]  {'alpha': 10.0}   \n",
       "3   [l1]  [1, 2, 3, 4, 5, 6, 7]  [1, 2, 3, 4, 5, 6, 7]  {'alpha': 10.0}   \n",
       "4   [l1]  [1, 2, 3, 4, 5, 6, 7]  [1, 2, 3, 4, 5, 6, 7]   {'alpha': 1.0}   \n",
       "5   [l1]  [1, 2, 3, 4, 5, 6, 7]  [1, 2, 3, 4, 5, 6, 7]   {'alpha': 0.1}   \n",
       "\n",
       "   mean_absolute_error  mean_squared_error  mean_absolute_percentage_error  \\\n",
       "0             0.073671            0.009153                        0.180190   \n",
       "1             0.077623            0.009842                        0.208891   \n",
       "2             0.110021            0.018882                        0.343295   \n",
       "3             0.179616            0.046386                        0.502170   \n",
       "4             0.203850            0.057269                        0.550379   \n",
       "5             0.215648            0.063630                        0.576964   \n",
       "\n",
       "   mean_absolute_scaled_error  root_mean_squared_scaled_error  alpha  \n",
       "0                    0.273346                        0.301710    0.1  \n",
       "1                    0.288008                        0.312861    1.0  \n",
       "2                    0.408219                        0.433336   10.0  \n",
       "3                    0.719871                        0.713240   10.0  \n",
       "4                    0.816998                        0.792510    1.0  \n",
       "5                    0.864284                        0.835361    0.1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from skforecast.model_selection_multiseries.tests.fixtures_model_selection_multiseries import series\n",
    "from skforecast.model_selection_multiseries.tests.fixtures_model_selection_multiseries import exog\n",
    "\n",
    "series.index = pd.date_range(start='2024-01-01', periods=len(series), freq='D')\n",
    "exog.index = pd.date_range(start='2024-01-01', periods=len(exog), freq='D')\n",
    "\n",
    "def test_evaluate_grid_hyperparameters_equivalent_outputs_backtesting_one_step_ahead(\n",
    "    forecaster,\n",
    "):\n",
    "\n",
    "    metrics = [\n",
    "        \"mean_absolute_error\",\n",
    "        \"mean_squared_error\",\n",
    "        mean_absolute_percentage_error,\n",
    "        mean_absolute_scaled_error,\n",
    "        root_mean_squared_scaled_error,\n",
    "    ]\n",
    "    steps = 1\n",
    "    initial_train_size = 20\n",
    "    param_grid = {\n",
    "        \"alpha\": np.logspace(-1, 1, 3),\n",
    "    }\n",
    "    lags_grid = [3, 7]\n",
    "    param_grid = list(ParameterGrid(param_grid))\n",
    "    results_backtesting = _evaluate_grid_hyperparameters_multiseries(\n",
    "        forecaster         = forecaster,\n",
    "        series             = series,\n",
    "        exog               = exog,\n",
    "        param_grid         = param_grid,\n",
    "        lags_grid          = lags_grid,\n",
    "        steps              = steps,\n",
    "        refit              = False,\n",
    "        metric             = metrics,\n",
    "        initial_train_size = initial_train_size,\n",
    "        method             = 'backtesting',\n",
    "        aggregate_metric   = [\"average\", \"weighted_average\", \"pooling\"],\n",
    "        fixed_train_size   = False,\n",
    "        return_best        = False,\n",
    "        n_jobs             = 'auto',\n",
    "        verbose            = False,\n",
    "        show_progress      = False\n",
    "    )\n",
    "    display(results_backtesting)\n",
    "    results_one_step_ahead = _evaluate_grid_hyperparameters_multiseries(\n",
    "        forecaster         = forecaster,\n",
    "        series             = series,\n",
    "        exog               = exog,\n",
    "        param_grid         = param_grid,\n",
    "        lags_grid          = lags_grid,\n",
    "        metric             = metrics,\n",
    "        initial_train_size = initial_train_size,\n",
    "        method             = 'one_step_ahead',\n",
    "        aggregate_metric   = [\"average\", \"weighted_average\", \"pooling\"],\n",
    "        return_best        = False,\n",
    "        verbose            = False,\n",
    "        show_progress      = False\n",
    "    )\n",
    "    display(results_backtesting)\n",
    "\n",
    "    pd.testing.assert_frame_equal(results_backtesting, results_one_step_ahead)\n",
    "\n",
    "\n",
    "regressor = Ridge(random_state=678)\n",
    "forecasters = [\n",
    "    # Diferenciation must be 0 for this test\n",
    "    ForecasterAutoregMultiSeries(regressor=regressor, lags=3),\n",
    "    ForecasterAutoregMultiSeries(\n",
    "        regressor=regressor,\n",
    "        lags=3,\n",
    "        transformer_series=None,\n",
    "    ),\n",
    "    ForecasterAutoregMultiSeries(\n",
    "        regressor=regressor,\n",
    "        lags=3,\n",
    "        transformer_series=StandardScaler(),\n",
    "        transformer_exog=StandardScaler()\n",
    "    ),\n",
    "    ForecasterAutoregMultiVariate(\n",
    "        regressor=regressor,\n",
    "        level='l1',\n",
    "        lags=3,\n",
    "        steps=1,\n",
    "        transformer_series=StandardScaler(),\n",
    "        transformer_exog=StandardScaler()\n",
    "    )\n",
    "]\n",
    "\n",
    "for i, forecaster in enumerate(forecasters):\n",
    "    print(i)\n",
    "    test_evaluate_grid_hyperparameters_equivalent_outputs_backtesting_one_step_ahead(\n",
    "        forecaster=forecaster\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/varios/skforecast/skforecast/model_selection_multiseries/model_selection_multiseries.py:1802: UserWarning: One-step-ahead predictions are used for faster model comparison, but they may not fully represent multi-step prediction performance. It is recommended to backtest the final model for a more accurate multi-step performance estimate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/varios/skforecast/skforecast/model_selection_multiseries/model_selection_multiseries.py:1802: UserWarning: One-step-ahead predictions are used for faster model comparison, but they may not fully represent multi-step prediction performance. It is recommended to backtest the final model for a more accurate multi-step performance estimate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/varios/skforecast/skforecast/model_selection_multiseries/model_selection_multiseries.py:1802: UserWarning: One-step-ahead predictions are used for faster model comparison, but they may not fully represent multi-step prediction performance. It is recommended to backtest the final model for a more accurate multi-step performance estimate.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "from pathlib import Path\n",
    "# THIS_DIR = Path(__file__).parent\n",
    "# series_dict = joblib.load(THIS_DIR/'fixture_sample_multi_series.joblib')\n",
    "# exog_dict = joblib.load(THIS_DIR/'fixture_sample_multi_series_exog.joblib')\n",
    "series_dict = joblib.load(\"/home/ubuntu/varios/skforecast/skforecast/model_selection_multiseries/tests/fixture_sample_multi_series.joblib\")\n",
    "exog_dict = joblib.load(\"/home/ubuntu/varios/skforecast/skforecast/model_selection_multiseries/tests/fixture_sample_multi_series_exog.joblib\")\n",
    "end_train = \"2016-07-31 23:59:00\"\n",
    "initial_train_size = 213\n",
    "\n",
    "def test_evaluate_grid_hyperparameters_equivalent_outputs_backtesting_one_step_ahead(\n",
    "    forecaster,\n",
    "):\n",
    "\n",
    "    metrics = [\n",
    "        \"mean_absolute_error\",\n",
    "        \"mean_squared_error\",\n",
    "        mean_absolute_percentage_error,\n",
    "        mean_absolute_scaled_error,\n",
    "        root_mean_squared_scaled_error,\n",
    "    ]\n",
    "    steps = 1\n",
    "    initial_train_size = 213\n",
    "    param_grid = {\n",
    "        \"n_estimators\": [5, 10],\n",
    "        \"max_depth\": [2, 3]\n",
    "    }\n",
    "    lags_grid = [3, 5]\n",
    "    param_grid = list(ParameterGrid(param_grid))\n",
    "    results_backtesting = _evaluate_grid_hyperparameters_multiseries(\n",
    "        forecaster         = forecaster,\n",
    "        series             = series_dict,\n",
    "        exog               = exog_dict,\n",
    "        param_grid         = param_grid,\n",
    "        lags_grid          = lags_grid,\n",
    "        steps              = steps,\n",
    "        refit              = False,\n",
    "        metric             = metrics,\n",
    "        initial_train_size = initial_train_size,\n",
    "        method             = 'backtesting',\n",
    "        aggregate_metric   = [\"average\", \"weighted_average\", \"pooling\"],\n",
    "        fixed_train_size   = False,\n",
    "        return_best        = False,\n",
    "        n_jobs             = 'auto',\n",
    "        verbose            = False,\n",
    "        show_progress      = False\n",
    "    )\n",
    "    # display(results_backtesting)\n",
    "    results_one_step_ahead = _evaluate_grid_hyperparameters_multiseries(\n",
    "        forecaster         = forecaster,\n",
    "        series             = series_dict,\n",
    "        exog               = exog_dict,\n",
    "        param_grid         = param_grid,\n",
    "        lags_grid          = lags_grid,\n",
    "        metric             = metrics,\n",
    "        initial_train_size = initial_train_size,\n",
    "        method             = 'one_step_ahead',\n",
    "        aggregate_metric   = [\"average\", \"weighted_average\", \"pooling\"],\n",
    "        return_best        = False,\n",
    "        verbose            = False,\n",
    "        show_progress      = False\n",
    "    )\n",
    "    # display(results_one_step_ahead)\n",
    "\n",
    "    pd.testing.assert_frame_equal(results_backtesting, results_one_step_ahead)\n",
    "\n",
    "\n",
    "regressor = LGBMRegressor(random_state=678, verbose=-1)\n",
    "forecasters = [\n",
    "    ForecasterAutoregMultiSeries(regressor=LGBMRegressor(random_state=678, verbose=-1), lags=3, forecaster_id=1),\n",
    "    ForecasterAutoregMultiSeries(\n",
    "        regressor=LGBMRegressor(random_state=678, verbose=-1),\n",
    "        lags=3,\n",
    "        transformer_series=None,\n",
    "        forecaster_id=2\n",
    "    ),\n",
    "    ForecasterAutoregMultiSeries(\n",
    "        regressor=LGBMRegressor(random_state=678, verbose=-1),\n",
    "        lags=3,\n",
    "        transformer_series=StandardScaler(),\n",
    "        transformer_exog=StandardScaler(),\n",
    "        forecaster_id=3\n",
    "    )\n",
    "]\n",
    "for forecaster in forecasters:\n",
    "    print(forecaster.forecaster_id)\n",
    "    test_evaluate_grid_hyperparameters_equivalent_outputs_backtesting_one_step_ahead(\n",
    "        forecaster=forecaster\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "092623717e0642119e04189c8d3f0895",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/153 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>levels</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <th>mean_absolute_percentage_error</th>\n",
       "      <th>mean_absolute_scaled_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_1000</td>\n",
       "      <td>653.625859</td>\n",
       "      <td>5.121216e-01</td>\n",
       "      <td>2.963779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_1001</td>\n",
       "      <td>1769.398384</td>\n",
       "      <td>7.115652e+16</td>\n",
       "      <td>4.857173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_1002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_1003</td>\n",
       "      <td>628.248235</td>\n",
       "      <td>3.441142e-01</td>\n",
       "      <td>2.656275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_1004</td>\n",
       "      <td>1746.409857</td>\n",
       "      <td>2.157294e-01</td>\n",
       "      <td>1.447493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>average</td>\n",
       "      <td>1199.420584</td>\n",
       "      <td>1.778913e+16</td>\n",
       "      <td>2.981180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>weighted_average</td>\n",
       "      <td>1139.379553</td>\n",
       "      <td>2.610779e+16</td>\n",
       "      <td>3.486763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>pooling</td>\n",
       "      <td>1139.379553</td>\n",
       "      <td>2.610779e+16</td>\n",
       "      <td>2.696035</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             levels  mean_absolute_error  mean_absolute_percentage_error  \\\n",
       "0           id_1000           653.625859                    5.121216e-01   \n",
       "1           id_1001          1769.398384                    7.115652e+16   \n",
       "2           id_1002                  NaN                             NaN   \n",
       "3           id_1003           628.248235                    3.441142e-01   \n",
       "4           id_1004          1746.409857                    2.157294e-01   \n",
       "5           average          1199.420584                    1.778913e+16   \n",
       "6  weighted_average          1139.379553                    2.610779e+16   \n",
       "7           pooling          1139.379553                    2.610779e+16   \n",
       "\n",
       "   mean_absolute_scaled_error  \n",
       "0                    2.963779  \n",
       "1                    4.857173  \n",
       "2                         NaN  \n",
       "3                    2.656275  \n",
       "4                    1.447493  \n",
       "5                    2.981180  \n",
       "6                    3.486763  \n",
       "7                    2.696035  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>levels</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <th>mean_absolute_percentage_error</th>\n",
       "      <th>mean_absolute_scaled_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_1000</td>\n",
       "      <td>653.625859</td>\n",
       "      <td>5.121216e-01</td>\n",
       "      <td>2.963779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_1001</td>\n",
       "      <td>1769.398384</td>\n",
       "      <td>7.115652e+16</td>\n",
       "      <td>4.857173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_1002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_1003</td>\n",
       "      <td>628.248235</td>\n",
       "      <td>3.441142e-01</td>\n",
       "      <td>2.656275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_1004</td>\n",
       "      <td>1746.409857</td>\n",
       "      <td>2.157294e-01</td>\n",
       "      <td>1.447493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>average</td>\n",
       "      <td>1199.420584</td>\n",
       "      <td>1.778913e+16</td>\n",
       "      <td>2.981180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>weighted_average</td>\n",
       "      <td>1139.379553</td>\n",
       "      <td>2.610779e+16</td>\n",
       "      <td>3.486763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>pooling</td>\n",
       "      <td>1139.379553</td>\n",
       "      <td>2.610779e+16</td>\n",
       "      <td>2.696035</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             levels  mean_absolute_error  mean_absolute_percentage_error  \\\n",
       "0           id_1000           653.625859                    5.121216e-01   \n",
       "1           id_1001          1769.398384                    7.115652e+16   \n",
       "2           id_1002                  NaN                             NaN   \n",
       "3           id_1003           628.248235                    3.441142e-01   \n",
       "4           id_1004          1746.409857                    2.157294e-01   \n",
       "5           average          1199.420584                    1.778913e+16   \n",
       "6  weighted_average          1139.379553                    2.610779e+16   \n",
       "7           pooling          1139.379553                    2.610779e+16   \n",
       "\n",
       "   mean_absolute_scaled_error  \n",
       "0                    2.963779  \n",
       "1                    4.857173  \n",
       "2                         NaN  \n",
       "3                    2.656275  \n",
       "4                    1.447493  \n",
       "5                    2.981180  \n",
       "6                    3.486763  \n",
       "7                    2.696035  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from skforecast.model_selection_multiseries import backtesting_forecaster_multiseries\n",
    "\n",
    "forecaster = ForecasterAutoregMultiSeries(\n",
    "    regressor=LGBMRegressor(random_state=678, verbose=-1, **{'max_depth': 2, 'n_estimators': 10}),\n",
    "    lags=1\n",
    ")\n",
    "\n",
    "metrics, predictions = backtesting_forecaster_multiseries(\n",
    "    forecaster=forecaster,\n",
    "    series=series_dict,\n",
    "    exog=exog_dict,\n",
    "    steps=1,\n",
    "    initial_train_size=213,\n",
    "    metric=[\"mean_absolute_error\", mean_absolute_percentage_error, mean_absolute_scaled_error],\n",
    "    add_aggregated_metric=True,\n",
    "    n_jobs='auto',\n",
    "    verbose=False,\n",
    "    show_progress=True\n",
    ")\n",
    "\n",
    "display(metrics)\n",
    "\n",
    "forecaster = ForecasterAutoregMultiSeries(\n",
    "    regressor=LGBMRegressor(random_state=678, verbose=-1, **{'max_depth': 2, 'n_estimators': 10}),\n",
    "    lags=1\n",
    ")\n",
    "(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    X_train_encoding,\n",
    "    X_test_encoding\n",
    ") = forecaster._train_test_split_one_step_ahead(\n",
    "        series             = series_dict,\n",
    "        exog               = exog_dict,\n",
    "        initial_train_size = 213,\n",
    "    )\n",
    "\n",
    "metrics_one_step_ahead, predictions_one_step_ahead = _predict_and_calculate_metrics_multiseries_one_step_ahead(\n",
    "    forecaster=forecaster,\n",
    "    series=series_dict,\n",
    "    X_train = X_train,\n",
    "    y_train= y_train,\n",
    "    X_train_encoding = X_train_encoding,\n",
    "    X_test = X_test,\n",
    "    y_test = y_test,\n",
    "    X_test_encoding = X_test_encoding,\n",
    "    levels = ['id_1000', 'id_1001', 'id_1002', 'id_1003', 'id_1004'],\n",
    "    metrics=[\"mean_absolute_error\", mean_absolute_percentage_error, mean_absolute_scaled_error],\n",
    "    add_aggregated_metric = True\n",
    ")\n",
    "display(metrics_one_step_ahead)\n",
    "\n",
    "\n",
    "pd.testing.assert_frame_equal(metrics, metrics_one_step_ahead)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## backtesting vs _predict_and_calculate_metrics_multiseries_one_step_ahead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from skforecast.model_selection_multiseries import backtesting_forecaster_multiseries\n",
    "from skforecast.model_selection_multiseries.model_selection_multiseries import _predict_and_calculate_metrics_multiseries_one_step_ahead\n",
    "from skforecast.model_selection_multiseries.model_selection_multiseries import _calculate_metrics_multiseries\n",
    "from skforecast.model_selection.model_selection import _create_backtesting_folds\n",
    "from skforecast.metrics import add_y_train_argument\n",
    "from skforecast.metrics import mean_absolute_scaled_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "items_sales\n",
      "-----------\n",
      "Simulated time series for the sales of 3 different items.\n",
      "Simulated data.\n",
      "Shape of the dataset: (1097, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2012-01-01', '2012-01-02', '2012-01-03', '2012-01-04',\n",
       "               '2012-01-05', '2012-01-06', '2012-01-07', '2012-01-08',\n",
       "               '2012-01-09', '2012-01-10',\n",
       "               ...\n",
       "               '2014-12-23', '2014-12-24', '2014-12-25', '2014-12-26',\n",
       "               '2014-12-27', '2014-12-28', '2014-12-29', '2014-12-30',\n",
       "               '2014-12-31', '2015-01-01'],\n",
       "              dtype='datetime64[ns]', name='date', length=1097, freq='D')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series = fetch_dataset(name=\"items_sales\")\n",
    "series.to_parquet(\"fixture_items_sales.parquet\")\n",
    "series.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_1</th>\n",
       "      <th>item_2</th>\n",
       "      <th>item_3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-01-01</th>\n",
       "      <td>8.253175</td>\n",
       "      <td>21.047727</td>\n",
       "      <td>19.429739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-02</th>\n",
       "      <td>22.777826</td>\n",
       "      <td>26.578125</td>\n",
       "      <td>28.009863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-03</th>\n",
       "      <td>27.549099</td>\n",
       "      <td>31.751042</td>\n",
       "      <td>32.078922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-04</th>\n",
       "      <td>25.895533</td>\n",
       "      <td>24.567708</td>\n",
       "      <td>27.252276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-05</th>\n",
       "      <td>21.379238</td>\n",
       "      <td>18.191667</td>\n",
       "      <td>20.357737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-28</th>\n",
       "      <td>17.329233</td>\n",
       "      <td>18.189583</td>\n",
       "      <td>20.586030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-29</th>\n",
       "      <td>19.611623</td>\n",
       "      <td>24.539583</td>\n",
       "      <td>28.127390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-30</th>\n",
       "      <td>18.857026</td>\n",
       "      <td>17.677083</td>\n",
       "      <td>21.555782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31</th>\n",
       "      <td>18.721223</td>\n",
       "      <td>17.391667</td>\n",
       "      <td>18.605453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01</th>\n",
       "      <td>10.496302</td>\n",
       "      <td>21.034615</td>\n",
       "      <td>19.943717</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1097 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               item_1     item_2     item_3\n",
       "date                                       \n",
       "2012-01-01   8.253175  21.047727  19.429739\n",
       "2012-01-02  22.777826  26.578125  28.009863\n",
       "2012-01-03  27.549099  31.751042  32.078922\n",
       "2012-01-04  25.895533  24.567708  27.252276\n",
       "2012-01-05  21.379238  18.191667  20.357737\n",
       "...               ...        ...        ...\n",
       "2014-12-28  17.329233  18.189583  20.586030\n",
       "2014-12-29  19.611623  24.539583  28.127390\n",
       "2014-12-30  18.857026  17.677083  21.555782\n",
       "2014-12-31  18.721223  17.391667  18.605453\n",
       "2015-01-01  10.496302  21.034615  19.943717\n",
       "\n",
       "[1097 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series = pd.read_parquet(\"fixture_items_sales.parquet\")\n",
    "series.asfreq('D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/varios/skforecast/skforecast/ForecasterAutoregMultiSeries/ForecasterAutoregMultiSeries.py:400: UserWarning: When using a linear model, it is recommended to use a transformer_series to ensure all series are in the same scale. You can use, for example, a `StandardScaler` from sklearn.preprocessing.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>levels</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <th>mean_absolute_percentage_error</th>\n",
       "      <th>mean_absolute_scaled_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>item_1</td>\n",
       "      <td>1.192201</td>\n",
       "      <td>0.057958</td>\n",
       "      <td>0.778281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>item_2</td>\n",
       "      <td>2.369540</td>\n",
       "      <td>0.161063</td>\n",
       "      <td>1.004057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>item_3</td>\n",
       "      <td>3.316136</td>\n",
       "      <td>0.220772</td>\n",
       "      <td>0.892257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>average</td>\n",
       "      <td>2.292626</td>\n",
       "      <td>0.146597</td>\n",
       "      <td>0.891532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>weighted_average</td>\n",
       "      <td>2.292626</td>\n",
       "      <td>0.146597</td>\n",
       "      <td>0.891532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pooling</td>\n",
       "      <td>2.292626</td>\n",
       "      <td>0.146597</td>\n",
       "      <td>0.903988</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             levels  mean_absolute_error  mean_absolute_percentage_error  \\\n",
       "0            item_1             1.192201                        0.057958   \n",
       "1            item_2             2.369540                        0.161063   \n",
       "2            item_3             3.316136                        0.220772   \n",
       "3           average             2.292626                        0.146597   \n",
       "4  weighted_average             2.292626                        0.146597   \n",
       "5           pooling             2.292626                        0.146597   \n",
       "\n",
       "   mean_absolute_scaled_error  \n",
       "0                    0.778281  \n",
       "1                    1.004057  \n",
       "2                    0.892257  \n",
       "3                    0.891532  \n",
       "4                    0.891532  \n",
       "5                    0.903988  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>levels</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <th>mean_absolute_percentage_error</th>\n",
       "      <th>mean_absolute_scaled_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>item_1</td>\n",
       "      <td>1.192201</td>\n",
       "      <td>0.057958</td>\n",
       "      <td>0.778281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>item_2</td>\n",
       "      <td>2.369540</td>\n",
       "      <td>0.161063</td>\n",
       "      <td>1.004057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>item_3</td>\n",
       "      <td>3.316136</td>\n",
       "      <td>0.220772</td>\n",
       "      <td>0.892257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>average</td>\n",
       "      <td>2.292626</td>\n",
       "      <td>0.146597</td>\n",
       "      <td>0.891532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>weighted_average</td>\n",
       "      <td>2.292626</td>\n",
       "      <td>0.146597</td>\n",
       "      <td>0.891532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pooling</td>\n",
       "      <td>2.292626</td>\n",
       "      <td>0.146597</td>\n",
       "      <td>0.903988</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             levels  mean_absolute_error  mean_absolute_percentage_error  \\\n",
       "0            item_1             1.192201                        0.057958   \n",
       "1            item_2             2.369540                        0.161063   \n",
       "2            item_3             3.316136                        0.220772   \n",
       "3           average             2.292626                        0.146597   \n",
       "4  weighted_average             2.292626                        0.146597   \n",
       "5           pooling             2.292626                        0.146597   \n",
       "\n",
       "   mean_absolute_scaled_error  \n",
       "0                    0.778281  \n",
       "1                    1.004057  \n",
       "2                    0.892257  \n",
       "3                    0.891532  \n",
       "4                    0.891532  \n",
       "5                    0.903988  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>levels</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <th>mean_absolute_percentage_error</th>\n",
       "      <th>mean_absolute_scaled_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>item_1</td>\n",
       "      <td>1.192201</td>\n",
       "      <td>0.057958</td>\n",
       "      <td>0.778281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>item_2</td>\n",
       "      <td>2.369540</td>\n",
       "      <td>0.161063</td>\n",
       "      <td>1.004057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>item_3</td>\n",
       "      <td>3.316136</td>\n",
       "      <td>0.220772</td>\n",
       "      <td>0.892257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>average</td>\n",
       "      <td>2.292626</td>\n",
       "      <td>0.146597</td>\n",
       "      <td>0.891532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>weighted_average</td>\n",
       "      <td>2.292626</td>\n",
       "      <td>0.146597</td>\n",
       "      <td>0.891532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pooling</td>\n",
       "      <td>2.292626</td>\n",
       "      <td>0.146597</td>\n",
       "      <td>0.903988</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             levels  mean_absolute_error  mean_absolute_percentage_error  \\\n",
       "0            item_1             1.192201                        0.057958   \n",
       "1            item_2             2.369540                        0.161063   \n",
       "2            item_3             3.316136                        0.220772   \n",
       "3           average             2.292626                        0.146597   \n",
       "4  weighted_average             2.292626                        0.146597   \n",
       "5           pooling             2.292626                        0.146597   \n",
       "\n",
       "   mean_absolute_scaled_error  \n",
       "0                    0.778281  \n",
       "1                    1.004057  \n",
       "2                    0.892257  \n",
       "3                    0.891532  \n",
       "4                    0.891532  \n",
       "5                    0.903988  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>levels</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <th>mean_absolute_percentage_error</th>\n",
       "      <th>mean_absolute_scaled_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>item_1</td>\n",
       "      <td>1.192201</td>\n",
       "      <td>0.057958</td>\n",
       "      <td>0.778281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>item_2</td>\n",
       "      <td>2.369540</td>\n",
       "      <td>0.161063</td>\n",
       "      <td>1.004057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>item_3</td>\n",
       "      <td>3.316136</td>\n",
       "      <td>0.220772</td>\n",
       "      <td>0.892257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>average</td>\n",
       "      <td>2.292626</td>\n",
       "      <td>0.146597</td>\n",
       "      <td>0.891532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>weighted_average</td>\n",
       "      <td>2.292626</td>\n",
       "      <td>0.146597</td>\n",
       "      <td>0.891532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pooling</td>\n",
       "      <td>2.292626</td>\n",
       "      <td>0.146597</td>\n",
       "      <td>0.903988</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             levels  mean_absolute_error  mean_absolute_percentage_error  \\\n",
       "0            item_1             1.192201                        0.057958   \n",
       "1            item_2             2.369540                        0.161063   \n",
       "2            item_3             3.316136                        0.220772   \n",
       "3           average             2.292626                        0.146597   \n",
       "4  weighted_average             2.292626                        0.146597   \n",
       "5           pooling             2.292626                        0.146597   \n",
       "\n",
       "   mean_absolute_scaled_error  \n",
       "0                    0.778281  \n",
       "1                    1.004057  \n",
       "2                    0.892257  \n",
       "3                    0.891532  \n",
       "4                    0.891532  \n",
       "5                    0.903988  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>levels</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <th>mean_absolute_percentage_error</th>\n",
       "      <th>mean_absolute_scaled_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>item_1</td>\n",
       "      <td>1.117062</td>\n",
       "      <td>0.055294</td>\n",
       "      <td>0.729230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>item_2</td>\n",
       "      <td>2.308444</td>\n",
       "      <td>0.153721</td>\n",
       "      <td>0.978168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>item_3</td>\n",
       "      <td>3.491733</td>\n",
       "      <td>0.234365</td>\n",
       "      <td>0.939504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>average</td>\n",
       "      <td>2.305746</td>\n",
       "      <td>0.147793</td>\n",
       "      <td>0.882301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>weighted_average</td>\n",
       "      <td>2.305746</td>\n",
       "      <td>0.147793</td>\n",
       "      <td>0.882301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pooling</td>\n",
       "      <td>2.305746</td>\n",
       "      <td>0.147793</td>\n",
       "      <td>0.909161</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             levels  mean_absolute_error  mean_absolute_percentage_error  \\\n",
       "0            item_1             1.117062                        0.055294   \n",
       "1            item_2             2.308444                        0.153721   \n",
       "2            item_3             3.491733                        0.234365   \n",
       "3           average             2.305746                        0.147793   \n",
       "4  weighted_average             2.305746                        0.147793   \n",
       "5           pooling             2.305746                        0.147793   \n",
       "\n",
       "   mean_absolute_scaled_error  \n",
       "0                    0.729230  \n",
       "1                    0.978168  \n",
       "2                    0.939504  \n",
       "3                    0.882301  \n",
       "4                    0.882301  \n",
       "5                    0.909161  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>levels</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <th>mean_absolute_percentage_error</th>\n",
       "      <th>mean_absolute_scaled_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>item_1</td>\n",
       "      <td>1.117062</td>\n",
       "      <td>0.055294</td>\n",
       "      <td>0.729230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>item_2</td>\n",
       "      <td>2.308444</td>\n",
       "      <td>0.153721</td>\n",
       "      <td>0.978168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>item_3</td>\n",
       "      <td>3.491733</td>\n",
       "      <td>0.234365</td>\n",
       "      <td>0.939504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>average</td>\n",
       "      <td>2.305746</td>\n",
       "      <td>0.147793</td>\n",
       "      <td>0.882301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>weighted_average</td>\n",
       "      <td>2.305746</td>\n",
       "      <td>0.147793</td>\n",
       "      <td>0.882301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pooling</td>\n",
       "      <td>2.305746</td>\n",
       "      <td>0.147793</td>\n",
       "      <td>0.909161</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             levels  mean_absolute_error  mean_absolute_percentage_error  \\\n",
       "0            item_1             1.117062                        0.055294   \n",
       "1            item_2             2.308444                        0.153721   \n",
       "2            item_3             3.491733                        0.234365   \n",
       "3           average             2.305746                        0.147793   \n",
       "4  weighted_average             2.305746                        0.147793   \n",
       "5           pooling             2.305746                        0.147793   \n",
       "\n",
       "   mean_absolute_scaled_error  \n",
       "0                    0.729230  \n",
       "1                    0.978168  \n",
       "2                    0.939504  \n",
       "3                    0.882301  \n",
       "4                    0.882301  \n",
       "5                    0.909161  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>levels</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <th>mean_absolute_percentage_error</th>\n",
       "      <th>mean_absolute_scaled_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>item_1</td>\n",
       "      <td>0.889368</td>\n",
       "      <td>0.043968</td>\n",
       "      <td>0.580589</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   levels  mean_absolute_error  mean_absolute_percentage_error  \\\n",
       "0  item_1             0.889368                        0.043968   \n",
       "\n",
       "   mean_absolute_scaled_error  \n",
       "0                    0.580589  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>levels</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <th>mean_absolute_percentage_error</th>\n",
       "      <th>mean_absolute_scaled_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>item_1</td>\n",
       "      <td>0.889368</td>\n",
       "      <td>0.043968</td>\n",
       "      <td>0.580589</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   levels  mean_absolute_error  mean_absolute_percentage_error  \\\n",
       "0  item_1             0.889368                        0.043968   \n",
       "\n",
       "   mean_absolute_scaled_error  \n",
       "0                    0.580589  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test results _predict_and_calculate_metrics_multiseries_one_step_ahead and backtesting_forecaster_multiseries\n",
    "# ==============================================================================\n",
    "# Metrics and predictions should be equal when using step=1 and refit=False\n",
    "# in backtesting_forecaster_multiseries and _predict_and_calculate_metrics_multiseries_one_step_ahead\n",
    "\n",
    "\n",
    "# Data download\n",
    "series = pd.read_parquet(\"fixture_items_sales.parquet\")\n",
    "series = series.asfreq('D')\n",
    "exog = pd.DataFrame(\n",
    "    {\n",
    "        'day_of_week': series.index.dayofweek\n",
    "    },\n",
    "    index = series.index\n",
    ")\n",
    "initial_train_size = 927\n",
    "\n",
    "# Metrics with _calculate_metrics_multiseries_one_step_ahead\n",
    "metrics = [mean_absolute_error, mean_absolute_percentage_error, mean_absolute_scaled_error]\n",
    "\n",
    "forecasters = [\n",
    "            ForecasterAutoregMultiSeries(regressor=Ridge(random_state=678), lags=3),\n",
    "            ForecasterAutoregMultiSeries(\n",
    "                regressor=Ridge(random_state=678),\n",
    "                lags=3,\n",
    "                transformer_series=None,\n",
    "            ),\n",
    "            ForecasterAutoregMultiSeries(\n",
    "                regressor=Ridge(random_state=678),\n",
    "                lags=3,\n",
    "                transformer_series=StandardScaler(),\n",
    "                transformer_exog=StandardScaler()\n",
    "            ),\n",
    "            ForecasterAutoregMultiVariate(\n",
    "                regressor=Ridge(random_state=678),\n",
    "                level='item_1',\n",
    "                lags=3,\n",
    "                steps=1,\n",
    "                transformer_series=StandardScaler(),\n",
    "                transformer_exog=StandardScaler()\n",
    "            )\n",
    "        ]\n",
    "\n",
    "for forecaster in forecasters:\n",
    "\n",
    "    if type(forecaster) is ForecasterAutoregMultiSeries:\n",
    "        levels = ['item_1', 'item_2', 'item_3']\n",
    "    else:\n",
    "        levels = ['item_1']\n",
    "\n",
    "    metrics_backtesting, predictions = backtesting_forecaster_multiseries(\n",
    "        series=series,\n",
    "        exog=exog,\n",
    "        forecaster=forecaster,\n",
    "        steps=1,\n",
    "        metric=metrics,\n",
    "        initial_train_size = initial_train_size,\n",
    "        refit=False,\n",
    "        levels=levels,\n",
    "        add_aggregated_metric=True,\n",
    "        show_progress=False\n",
    "    )\n",
    "\n",
    "    display(metrics_backtesting)\n",
    "\n",
    "    (\n",
    "        X_train,\n",
    "        y_train,\n",
    "        X_test,\n",
    "        y_test,\n",
    "        X_train_encoding,\n",
    "        X_test_encoding\n",
    "    ) = forecaster._train_test_split_one_step_ahead(\n",
    "            series             = series,\n",
    "            exog               = exog,\n",
    "            initial_train_size = initial_train_size,\n",
    "        )\n",
    "\n",
    "    metrics_one_step_ahead, predictions_one_step_ahead = _predict_and_calculate_metrics_multiseries_one_step_ahead(\n",
    "        forecaster=forecaster,\n",
    "        series=series,\n",
    "        X_train = X_train,\n",
    "        y_train= y_train,\n",
    "        X_train_encoding = X_train_encoding,\n",
    "        X_test = X_test,\n",
    "        y_test = y_test,\n",
    "        X_test_encoding = X_test_encoding,\n",
    "        levels = levels,\n",
    "        metrics = metrics,\n",
    "        add_aggregated_metric = True\n",
    "    )\n",
    "\n",
    "    display(metrics_one_step_ahead)\n",
    "\n",
    "\n",
    "    pd.testing.assert_frame_equal(metrics_one_step_ahead, metrics_backtesting)\n",
    "    pd.testing.assert_frame_equal(predictions_one_step_ahead, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_predict_and_calculate_metrics_multiseries_one_step_ahead_output_equivalence_to_backtesting(forecaster):\n",
    "    \"\"\"\n",
    "    Test that the output of _predict_and_calculate_metrics_multiseries_one_step_ahead is equivalent to\n",
    "    the output of backtesting_forecaster_multiseries when steps=1 and refit=False.\n",
    "\n",
    "    Results are not equivalent if diferentiation is included\n",
    "    \"\"\"\n",
    "\n",
    "    initial_train_size = 927\n",
    "    metrics = ['mean_absolute_error', mean_absolute_percentage_error, mean_absolute_scaled_error]\n",
    "\n",
    "    if type(forecaster) is ForecasterAutoregMultiSeries:\n",
    "        levels = ['item_1', 'item_2', 'item_3']\n",
    "    else:\n",
    "        levels = ['item_1']\n",
    "\n",
    "    metrics_backtesting, pred_backtesting = backtesting_forecaster_multiseries(\n",
    "        series=series,\n",
    "        exog=exog,\n",
    "        forecaster=forecaster,\n",
    "        steps=1,\n",
    "        metric=metrics,\n",
    "        initial_train_size = initial_train_size,\n",
    "        refit=False,\n",
    "        levels=levels,\n",
    "        add_aggregated_metric=True,\n",
    "        show_progress=False\n",
    "    )\n",
    "\n",
    "    (\n",
    "        X_train,\n",
    "        y_train,\n",
    "        X_test,\n",
    "        y_test,\n",
    "        X_train_encoding,\n",
    "        X_test_encoding\n",
    "    ) = forecaster._train_test_split_one_step_ahead(\n",
    "            series             = series,\n",
    "            exog               = exog,\n",
    "            initial_train_size = initial_train_size,\n",
    "        )\n",
    "\n",
    "    metrics_one_step_ahead, pred_one_step_ahead = _predict_and_calculate_metrics_multiseries_one_step_ahead(\n",
    "        forecaster=forecaster,\n",
    "        series=series,\n",
    "        X_train = X_train,\n",
    "        y_train= y_train,\n",
    "        X_train_encoding = X_train_encoding,\n",
    "        X_test = X_test,\n",
    "        y_test = y_test,\n",
    "        X_test_encoding = X_test_encoding,\n",
    "        levels = levels,\n",
    "        metrics = metrics,\n",
    "        add_aggregated_metric = True\n",
    "    )\n",
    "\n",
    "\n",
    "    pd.testing.assert_frame_equal(metrics_one_step_ahead, metrics_backtesting)\n",
    "    pd.testing.assert_frame_equal(pred_one_step_ahead, pred_backtesting)\n",
    "\n",
    "for forecaster in forecasters:\n",
    "    test_predict_and_calculate_metrics_multiseries_one_step_ahead_output_equivalence_to_backtesting(forecaster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2014-07-16', '2014-07-17', '2014-07-18', '2014-07-19',\n",
       "               '2014-07-20', '2014-07-21', '2014-07-22', '2014-07-23',\n",
       "               '2014-07-24', '2014-07-25',\n",
       "               ...\n",
       "               '2014-12-23', '2014-12-24', '2014-12-25', '2014-12-26',\n",
       "               '2014-12-27', '2014-12-28', '2014-12-29', '2014-12-30',\n",
       "               '2014-12-31', '2015-01-01'],\n",
       "              dtype='datetime64[ns]', length=170, freq='D')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_one_step_ahead.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2014-07-16', '2014-07-17', '2014-07-18', '2014-07-19',\n",
       "               '2014-07-20', '2014-07-21', '2014-07-22', '2014-07-23',\n",
       "               '2014-07-24', '2014-07-25',\n",
       "               ...\n",
       "               '2014-12-23', '2014-12-24', '2014-12-25', '2014-12-26',\n",
       "               '2014-12-27', '2014-12-28', '2014-12-29', '2014-12-30',\n",
       "               '2014-12-31', '2015-01-01'],\n",
       "              dtype='datetime64[ns]', length=170, freq='D')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>levels</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <th>mean_absolute_percentage_error</th>\n",
       "      <th>mean_absolute_scaled_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_1000</td>\n",
       "      <td>128.956250</td>\n",
       "      <td>8.742856e-02</td>\n",
       "      <td>0.615734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_1001</td>\n",
       "      <td>901.076173</td>\n",
       "      <td>3.344592e+16</td>\n",
       "      <td>5.935943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_1002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_1003</td>\n",
       "      <td>196.715372</td>\n",
       "      <td>1.004418e-01</td>\n",
       "      <td>0.788344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_1004</td>\n",
       "      <td>804.919558</td>\n",
       "      <td>1.220198e-01</td>\n",
       "      <td>0.635045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>average</td>\n",
       "      <td>507.916838</td>\n",
       "      <td>8.361481e+15</td>\n",
       "      <td>1.993766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>weighted_average</td>\n",
       "      <td>475.502870</td>\n",
       "      <td>1.227153e+16</td>\n",
       "      <td>2.602303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>pooling</td>\n",
       "      <td>475.502870</td>\n",
       "      <td>1.227153e+16</td>\n",
       "      <td>1.165064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             levels  mean_absolute_error  mean_absolute_percentage_error  \\\n",
       "0           id_1000           128.956250                    8.742856e-02   \n",
       "1           id_1001           901.076173                    3.344592e+16   \n",
       "2           id_1002                  NaN                             NaN   \n",
       "3           id_1003           196.715372                    1.004418e-01   \n",
       "4           id_1004           804.919558                    1.220198e-01   \n",
       "5           average           507.916838                    8.361481e+15   \n",
       "6  weighted_average           475.502870                    1.227153e+16   \n",
       "7           pooling           475.502870                    1.227153e+16   \n",
       "\n",
       "   mean_absolute_scaled_error  \n",
       "0                    0.615734  \n",
       "1                    5.935943  \n",
       "2                         NaN  \n",
       "3                    0.788344  \n",
       "4                    0.635045  \n",
       "5                    1.993766  \n",
       "6                    2.602303  \n",
       "7                    1.165064  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>levels</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <th>mean_absolute_percentage_error</th>\n",
       "      <th>mean_absolute_scaled_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_1000</td>\n",
       "      <td>128.956250</td>\n",
       "      <td>8.742856e-02</td>\n",
       "      <td>0.615734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_1001</td>\n",
       "      <td>901.076173</td>\n",
       "      <td>3.344592e+16</td>\n",
       "      <td>5.935943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_1002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_1003</td>\n",
       "      <td>196.715372</td>\n",
       "      <td>1.004418e-01</td>\n",
       "      <td>0.788344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_1004</td>\n",
       "      <td>804.919558</td>\n",
       "      <td>1.220198e-01</td>\n",
       "      <td>0.635045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>average</td>\n",
       "      <td>507.916838</td>\n",
       "      <td>8.361481e+15</td>\n",
       "      <td>1.993766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>weighted_average</td>\n",
       "      <td>475.502870</td>\n",
       "      <td>1.227153e+16</td>\n",
       "      <td>2.602303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>pooling</td>\n",
       "      <td>475.502870</td>\n",
       "      <td>1.227153e+16</td>\n",
       "      <td>1.165064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             levels  mean_absolute_error  mean_absolute_percentage_error  \\\n",
       "0           id_1000           128.956250                    8.742856e-02   \n",
       "1           id_1001           901.076173                    3.344592e+16   \n",
       "2           id_1002                  NaN                             NaN   \n",
       "3           id_1003           196.715372                    1.004418e-01   \n",
       "4           id_1004           804.919558                    1.220198e-01   \n",
       "5           average           507.916838                    8.361481e+15   \n",
       "6  weighted_average           475.502870                    1.227153e+16   \n",
       "7           pooling           475.502870                    1.227153e+16   \n",
       "\n",
       "   mean_absolute_scaled_error  \n",
       "0                    0.615734  \n",
       "1                    5.935943  \n",
       "2                         NaN  \n",
       "3                    0.788344  \n",
       "4                    0.635045  \n",
       "5                    1.993766  \n",
       "6                    2.602303  \n",
       "7                    1.165064  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test results _predict_and_calculate_metrics_multiseries_one_step_ahead and backtesting_forecaster_multiseries\n",
    "# ==============================================================================\n",
    "# Metrics and predictions should be equal when using step=1 and refit=False in backtesting_forecaster_multiseries\n",
    "\n",
    "\n",
    "# Data download\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "# THIS_DIR = Path(__file__).parent\n",
    "# series_dict = joblib.load(THIS_DIR/'fixture_sample_multi_series.joblib')\n",
    "# exog_dict = joblib.load(THIS_DIR/'fixture_sample_multi_series_exog.joblib')\n",
    "series_dict = joblib.load(\"/home/ubuntu/varios/skforecast/skforecast/model_selection_multiseries/tests/fixture_sample_multi_series.joblib\")\n",
    "exog_dict = joblib.load(\"/home/ubuntu/varios/skforecast/skforecast/model_selection_multiseries/tests/fixture_sample_multi_series_exog.joblib\")\n",
    "end_train = \"2016-07-31 23:59:00\"\n",
    "initial_train_size = 213\n",
    "\n",
    "# Metrics with _calculate_metrics_multiseries_one_step_ahead\n",
    "metrics = [mean_absolute_error, mean_absolute_percentage_error, mean_absolute_scaled_error]\n",
    "metrics = [add_y_train_argument(metric) for metric in metrics]\n",
    "\n",
    "forecasters = [\n",
    "    ForecasterAutoregMultiSeries(\n",
    "        regressor          = LGBMRegressor(random_state=123, verbose=-1),\n",
    "        lags               = 24,\n",
    "        encoding           = 'ordinal',\n",
    "        transformer_series = StandardScaler(),\n",
    "        transformer_exog   = StandardScaler(),\n",
    "        weight_func        = None,\n",
    "        series_weights     = None,\n",
    "        differentiation    = None,\n",
    "        dropna_from_series = False,\n",
    "    ),\n",
    "\n",
    "]\n",
    "\n",
    "for forecaster in forecasters:\n",
    "\n",
    "    if type(forecaster) is ForecasterAutoregMultiSeries:\n",
    "        levels = ['id_1000', 'id_1001', 'id_1002', 'id_1003', 'id_1004']\n",
    "    else:\n",
    "        levels = ['id_1000']\n",
    "\n",
    "    metrics_backtesting, predictions = backtesting_forecaster_multiseries(\n",
    "        series=series_dict,\n",
    "        exog=exog_dict,\n",
    "        forecaster=forecaster,\n",
    "        steps=1,\n",
    "        metric=metrics,\n",
    "        initial_train_size = initial_train_size,\n",
    "        refit=False,\n",
    "        levels=levels,\n",
    "        add_aggregated_metric=True,\n",
    "        show_progress=False\n",
    "    )\n",
    "\n",
    "    display(metrics_backtesting)\n",
    "\n",
    "    (\n",
    "        X_train,\n",
    "        y_train,\n",
    "        X_test,\n",
    "        y_test,\n",
    "        X_train_encoding,\n",
    "        X_test_encoding\n",
    "    ) = forecaster._train_test_split_one_step_ahead(\n",
    "            series             = series_dict,\n",
    "            exog               = exog_dict,\n",
    "            initial_train_size = initial_train_size,\n",
    "        )\n",
    "\n",
    "    metrics_one_step_ahead, predictions_one_step_ahead = _predict_and_calculate_metrics_multiseries_one_step_ahead(\n",
    "        forecaster=forecaster,\n",
    "        series=series_dict,\n",
    "        X_train = X_train,\n",
    "        y_train= y_train,\n",
    "        X_train_encoding = X_train_encoding,\n",
    "        X_test = X_test,\n",
    "        y_test = y_test,\n",
    "        X_test_encoding = X_test_encoding,\n",
    "        levels = levels,\n",
    "        metrics = metrics,\n",
    "        add_aggregated_metric = True\n",
    "    )\n",
    "\n",
    "    display(metrics_one_step_ahead)\n",
    "\n",
    "\n",
    "    pd.testing.assert_frame_equal(metrics_one_step_ahead, metrics_backtesting)\n",
    "    pd.testing.assert_frame_equal(predictions_one_step_ahead, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>levels</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <th>mean_absolute_percentage_error</th>\n",
       "      <th>mean_absolute_scaled_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_1000</td>\n",
       "      <td>187.154572</td>\n",
       "      <td>1.317794e-01</td>\n",
       "      <td>0.868741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_1001</td>\n",
       "      <td>943.027968</td>\n",
       "      <td>3.296872e+16</td>\n",
       "      <td>2.761642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_1002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_1003</td>\n",
       "      <td>203.228478</td>\n",
       "      <td>1.087644e-01</td>\n",
       "      <td>0.848920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_1004</td>\n",
       "      <td>839.062142</td>\n",
       "      <td>1.352426e-01</td>\n",
       "      <td>0.680035</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    levels  mean_absolute_error  mean_absolute_percentage_error  \\\n",
       "0  id_1000           187.154572                    1.317794e-01   \n",
       "1  id_1001           943.027968                    3.296872e+16   \n",
       "2  id_1002                  NaN                             NaN   \n",
       "3  id_1003           203.228478                    1.087644e-01   \n",
       "4  id_1004           839.062142                    1.352426e-01   \n",
       "\n",
       "   mean_absolute_scaled_error  \n",
       "0                    0.868741  \n",
       "1                    2.761642  \n",
       "2                         NaN  \n",
       "3                    0.848920  \n",
       "4                    0.680035  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test results _predict_and_calculate_metrics_multiseries_one_step_ahead and backtesting_forecaster_multiseries\n",
    "# ==============================================================================\n",
    "# Metrics and predictions should be equal when using step=1 and refit=False in backtesting_forecaster_multiseries\n",
    "\n",
    "\n",
    "# Data download\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "# THIS_DIR = Path(__file__).parent\n",
    "# series_dict = joblib.load(THIS_DIR/'fixture_sample_multi_series.joblib')\n",
    "# exog_dict = joblib.load(THIS_DIR/'fixture_sample_multi_series_exog.joblib')\n",
    "series_dict = joblib.load(\"/home/ubuntu/varios/skforecast/skforecast/model_selection_multiseries/tests/fixture_sample_multi_series.joblib\")\n",
    "exog_dict = joblib.load(\"/home/ubuntu/varios/skforecast/skforecast/model_selection_multiseries/tests/fixture_sample_multi_series_exog.joblib\")\n",
    "end_train = \"2016-07-31 23:59:00\"\n",
    "initial_train_size = 213\n",
    "\n",
    "# Metrics with _calculate_metrics_multiseries_one_step_ahead\n",
    "metrics = [mean_absolute_error, mean_absolute_percentage_error, mean_absolute_scaled_error]\n",
    "metrics = [add_y_train_argument(metric) for metric in metrics]\n",
    "\n",
    "forecaster = ForecasterAutoregMultiSeries(\n",
    "        regressor          = Ridge(random_state=123),\n",
    "        lags               = 10,\n",
    "        encoding           = 'ordinal',\n",
    "        transformer_series = StandardScaler(),\n",
    "        transformer_exog   = StandardScaler(),\n",
    "        weight_func        = None,\n",
    "        series_weights     = None,\n",
    "        differentiation    = None,\n",
    "        dropna_from_series = True,\n",
    "    )\n",
    "\n",
    "\n",
    "metrics_backtesting, predictions = backtesting_forecaster_multiseries(\n",
    "    series=series_dict,\n",
    "    #exog=exog_dict,\n",
    "    forecaster=forecaster,\n",
    "    steps=10,\n",
    "    metric=metrics,\n",
    "    initial_train_size = initial_train_size,\n",
    "    refit=False,\n",
    "    levels=['id_1000', 'id_1001', 'id_1002', 'id_1003', 'id_1004'],\n",
    "    add_aggregated_metric=False,\n",
    "    show_progress=False\n",
    ")\n",
    "\n",
    "display(metrics_backtesting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>levels</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <th>mean_absolute_percentage_error</th>\n",
       "      <th>mean_absolute_scaled_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_1000</td>\n",
       "      <td>138.459914</td>\n",
       "      <td>9.302698e-02</td>\n",
       "      <td>0.642708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_1001</td>\n",
       "      <td>1326.348427</td>\n",
       "      <td>5.852032e+16</td>\n",
       "      <td>3.884190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_1002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_1003</td>\n",
       "      <td>194.510963</td>\n",
       "      <td>1.086343e-01</td>\n",
       "      <td>0.786311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_1004</td>\n",
       "      <td>684.720990</td>\n",
       "      <td>1.037579e-01</td>\n",
       "      <td>0.554946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>average</td>\n",
       "      <td>586.010073</td>\n",
       "      <td>1.463008e+16</td>\n",
       "      <td>1.467039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>weighted_average</td>\n",
       "      <td>636.259937</td>\n",
       "      <td>2.199904e+16</td>\n",
       "      <td>1.879264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>pooling</td>\n",
       "      <td>636.259937</td>\n",
       "      <td>2.199904e+16</td>\n",
       "      <td>1.498528</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             levels  mean_absolute_error  mean_absolute_percentage_error  \\\n",
       "0           id_1000           138.459914                    9.302698e-02   \n",
       "1           id_1001          1326.348427                    5.852032e+16   \n",
       "2           id_1002                  NaN                             NaN   \n",
       "3           id_1003           194.510963                    1.086343e-01   \n",
       "4           id_1004           684.720990                    1.037579e-01   \n",
       "5           average           586.010073                    1.463008e+16   \n",
       "6  weighted_average           636.259937                    2.199904e+16   \n",
       "7           pooling           636.259937                    2.199904e+16   \n",
       "\n",
       "   mean_absolute_scaled_error  \n",
       "0                    0.642708  \n",
       "1                    3.884190  \n",
       "2                         NaN  \n",
       "3                    0.786311  \n",
       "4                    0.554946  \n",
       "5                    1.467039  \n",
       "6                    1.879264  \n",
       "7                    1.498528  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_train_size = 213\n",
    "forecaster = ForecasterAutoregMultiSeries(\n",
    "        regressor          = LGBMRegressor(random_state=123, verbose=-1),\n",
    "        lags               = 10,\n",
    "        encoding           = 'ordinal',\n",
    "        transformer_series = StandardScaler(),\n",
    "        transformer_exog   = StandardScaler(),\n",
    "        weight_func        = None,\n",
    "        series_weights     = None,\n",
    "        differentiation    = None,\n",
    "        dropna_from_series = True,\n",
    "    )\n",
    "\n",
    "(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    X_train_encoding,\n",
    "    X_test_encoding\n",
    ") = forecaster._train_test_split_one_step_ahead(\n",
    "        series             = series_dict,\n",
    "        #exog               = exog_dict,\n",
    "        initial_train_size = initial_train_size,\n",
    "    )\n",
    "\n",
    "metrics_one_step_ahead, predictions_one_step_ahead = _predict_and_calculate_metrics_multiseries_one_step_ahead(\n",
    "    forecaster=forecaster,\n",
    "    series=series_dict,\n",
    "    X_train = X_train,\n",
    "    y_train= y_train,\n",
    "    X_train_encoding = X_train_encoding,\n",
    "    X_test = X_test,\n",
    "    y_test = y_test,\n",
    "    X_test_encoding = X_test_encoding,\n",
    "    levels = levels,\n",
    "    metrics = metrics,\n",
    "    add_aggregated_metric = True\n",
    ")\n",
    "\n",
    "metrics_one_step_ahead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['id_1000', 'id_1001', 'id_1002', 'id_1003', 'id_1004'],\n",
       "       dtype=object)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecaster.encoder.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/varios/skforecast/skforecast/model_selection_multiseries/model_selection_multiseries.py:2349: UserWarning: One-step-ahead predictions are used for faster model comparison, but they may not fully represent multi-step prediction performance. It is recommended to backtest the final model for a more accurate multi-step performance estimate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RangeIndex(start=0, stop=5, step=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'levels': [['item_1', 'item_2', 'item_3'],\n",
       "  ['item_1', 'item_2', 'item_3'],\n",
       "  ['item_1', 'item_2', 'item_3'],\n",
       "  ['item_1', 'item_2', 'item_3'],\n",
       "  ['item_1', 'item_2', 'item_3']],\n",
       " 'lags': [array([1, 2, 3]),\n",
       "  array([1, 2, 3, 4, 5]),\n",
       "  array([1, 2, 3, 4, 5]),\n",
       "  array([1, 2, 3]),\n",
       "  array([1, 2, 3])],\n",
       " 'params': [{'alpha': 766.6289057556013},\n",
       "  {'alpha': 0.4279898484823994},\n",
       "  {'alpha': 0.2252709077935534},\n",
       "  {'alpha': 15.094374246471325},\n",
       "  {'alpha': 2.031835829826598}],\n",
       " 'mean_absolute_error__average': [2.487682902584588,\n",
       "  2.5778104346448623,\n",
       "  2.5779063732830942,\n",
       "  2.599406545255343,\n",
       "  2.605166414875337],\n",
       " 'mean_absolute_error__weighted_average': [2.487682902584588,\n",
       "  2.5778104346448623,\n",
       "  2.5779063732830947,\n",
       "  2.599406545255343,\n",
       "  2.6051664148753373],\n",
       " 'mean_absolute_error__pooling': [2.4876829025845875,\n",
       "  2.5778104346448623,\n",
       "  2.5779063732830947,\n",
       "  2.599406545255343,\n",
       "  2.6051664148753373],\n",
       " 'mean_absolute_percentage_error__average': [0.13537962851907534,\n",
       "  0.14171211559040905,\n",
       "  0.1417181361315976,\n",
       "  0.1425099620058197,\n",
       "  0.14287737387127633],\n",
       " 'mean_absolute_percentage_error__weighted_average': [0.13537962851907534,\n",
       "  0.14171211559040905,\n",
       "  0.14171813613159756,\n",
       "  0.14250996200581972,\n",
       "  0.14287737387127633],\n",
       " 'mean_absolute_percentage_error__pooling': [0.13537962851907534,\n",
       "  0.14171211559040905,\n",
       "  0.14171813613159756,\n",
       "  0.14250996200581975,\n",
       "  0.14287737387127633],\n",
       " 'mean_absolute_scaled_error__average': [0.9807885628114613,\n",
       "  0.9887040054273549,\n",
       "  0.9887272793513265,\n",
       "  0.9982897158009892,\n",
       "  0.999726922014544],\n",
       " 'mean_absolute_scaled_error__weighted_average': [0.9807885628114613,\n",
       "  0.9887040054273548,\n",
       "  0.9887272793513265,\n",
       "  0.9982897158009892,\n",
       "  0.9997269220145439],\n",
       " 'mean_absolute_scaled_error__pooling': [0.994386675351447,\n",
       "  1.0309527259247835,\n",
       "  1.0309910949992809,\n",
       "  1.039045301850066,\n",
       "  1.0413476602398484],\n",
       " 'alpha': [766.6289057556013,\n",
       "  0.4279898484823994,\n",
       "  0.2252709077935534,\n",
       "  15.094374246471325,\n",
       "  2.031835829826598]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from skforecast.model_selection_multiseries import bayesian_search_forecaster_multiseries\n",
    "\n",
    "series_item_sales = fetch_dataset(name=\"items_sales\", verbose=False)\n",
    "exog_item_sales = pd.DataFrame({'day_of_week': series_item_sales.index.dayofweek}, index = series_item_sales.index)\n",
    "\n",
    "levels = [\"item_1\", \"item_2\", \"item_3\"]\n",
    "exog_features = ['day_of_week']\n",
    "\n",
    "\n",
    "metrics = ['mean_absolute_error', mean_absolute_percentage_error, mean_absolute_scaled_error]\n",
    "forecaster = ForecasterAutoregMultiSeries(\n",
    "            regressor          = Ridge(random_state=123),\n",
    "            lags               = 3,\n",
    "            encoding           = 'ordinal',\n",
    "            transformer_series = StandardScaler(),\n",
    "            transformer_exog   = StandardScaler(),\n",
    "            weight_func        = None,\n",
    "            series_weights     = None,\n",
    "            differentiation    = None,\n",
    "            dropna_from_series = False,\n",
    "        )\n",
    "\n",
    "initial_train_size = 1000\n",
    "levels = [\"item_1\", \"item_2\", \"item_3\"]\n",
    "\n",
    "def search_space(trial):\n",
    "    search_space  = {\n",
    "        'alpha': trial.suggest_float('alpha', 1e-3, 1e3, log=True),\n",
    "        'lags': trial.suggest_categorical('lags', [3, 5]),\n",
    "    }\n",
    "    \n",
    "    return search_space\n",
    "\n",
    "\n",
    "results, best_trial = bayesian_search_forecaster_multiseries(\n",
    "    forecaster         = forecaster,\n",
    "    series             = series_item_sales,\n",
    "    exog               = exog_item_sales,\n",
    "    search_space       = search_space,\n",
    "    n_trials           = 5,\n",
    "    metric             = metrics,\n",
    "    initial_train_size = initial_train_size,\n",
    "    levels             = levels,\n",
    "    method             = 'one_step_ahead',\n",
    "    aggregate_metric   = [\"average\", \"weighted_average\", \"pooling\"],\n",
    "    return_best        = False,\n",
    "    n_jobs             = 'auto',\n",
    "    verbose            = False,\n",
    "    show_progress      = False\n",
    ")\n",
    "\n",
    "print(results.index)\n",
    "results.to_dict(orient='list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/varios/skforecast/skforecast/model_selection_multiseries/model_selection_multiseries.py:2349: UserWarning: One-step-ahead predictions are used for faster model comparison, but they may not fully represent multi-step prediction performance. It is recommended to backtest the final model for a more accurate multi-step performance estimate.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def test_output_bayesian_search_forecaster_multiseries_ForecasterAutoregMultiSeries_one_step_ahead():\n",
    "    \"\"\"\n",
    "    Test output of bayesian_search_forecaster_multiseries when forecaster is ForecasterAutoregMultiSeries\n",
    "    and method is one_step_ahead.\n",
    "    \"\"\"\n",
    "    metrics = ['mean_absolute_error', mean_absolute_percentage_error, mean_absolute_scaled_error]\n",
    "    forecaster = ForecasterAutoregMultiSeries(\n",
    "            regressor          = Ridge(random_state=123),\n",
    "            lags               = 3,\n",
    "            encoding           = 'ordinal',\n",
    "            transformer_series = StandardScaler(),\n",
    "            transformer_exog   = StandardScaler(),\n",
    "            weight_func        = None,\n",
    "            series_weights     = None,\n",
    "            differentiation    = None,\n",
    "            dropna_from_series = False,\n",
    "        )\n",
    "\n",
    "    initial_train_size = 1000\n",
    "    levels = [\"item_1\", \"item_2\", \"item_3\"]\n",
    "\n",
    "    def search_space(trial):\n",
    "        search_space  = {\n",
    "            'alpha': trial.suggest_float('alpha', 1e-3, 1e3, log=True),\n",
    "            'lags': trial.suggest_categorical('lags', [3, 5]),\n",
    "        }\n",
    "\n",
    "        return search_space\n",
    "\n",
    "    results, _ = bayesian_search_forecaster_multiseries(\n",
    "        forecaster         = forecaster,\n",
    "        series             = series_item_sales,\n",
    "        exog               = exog_item_sales,\n",
    "        search_space       = search_space,\n",
    "        n_trials           = 5,\n",
    "        metric             = metrics,\n",
    "        levels             = levels,\n",
    "        initial_train_size = initial_train_size,\n",
    "        method             = 'one_step_ahead',\n",
    "        aggregate_metric   = [\"average\", \"weighted_average\", \"pooling\"],\n",
    "        return_best        = False,\n",
    "        n_jobs             = 'auto',\n",
    "        verbose            = False,\n",
    "        show_progress      = False\n",
    "    )\n",
    "\n",
    "    expected_results = pd.DataFrame(\n",
    "        {\n",
    "            \"levels\": [\n",
    "                [\"item_1\", \"item_2\", \"item_3\"],\n",
    "                [\"item_1\", \"item_2\", \"item_3\"],\n",
    "                [\"item_1\", \"item_2\", \"item_3\"],\n",
    "                [\"item_1\", \"item_2\", \"item_3\"],\n",
    "                [\"item_1\", \"item_2\", \"item_3\"],\n",
    "            ],\n",
    "            \"lags\": [\n",
    "                np.array([1, 2, 3]),\n",
    "                np.array([1, 2, 3, 4, 5]),\n",
    "                np.array([1, 2, 3, 4, 5]),\n",
    "                np.array([1, 2, 3]),\n",
    "                np.array([1, 2, 3]),\n",
    "            ],\n",
    "            \"params\": [\n",
    "                {\"alpha\": 766.6289057556013},\n",
    "                {\"alpha\": 0.4279898484823994},\n",
    "                {\"alpha\": 0.2252709077935534},\n",
    "                {\"alpha\": 15.094374246471325},\n",
    "                {\"alpha\": 2.031835829826598},\n",
    "            ],\n",
    "            \"mean_absolute_error__average\": [\n",
    "                2.487682902584588,\n",
    "                2.5778104346448623,\n",
    "                2.5779063732830942,\n",
    "                2.599406545255343,\n",
    "                2.605166414875337,\n",
    "            ],\n",
    "            \"mean_absolute_error__weighted_average\": [\n",
    "                2.487682902584588,\n",
    "                2.5778104346448623,\n",
    "                2.5779063732830947,\n",
    "                2.599406545255343,\n",
    "                2.6051664148753373,\n",
    "            ],\n",
    "            \"mean_absolute_error__pooling\": [\n",
    "                2.4876829025845875,\n",
    "                2.5778104346448623,\n",
    "                2.5779063732830947,\n",
    "                2.599406545255343,\n",
    "                2.6051664148753373,\n",
    "            ],\n",
    "            \"mean_absolute_percentage_error__average\": [\n",
    "                0.13537962851907534,\n",
    "                0.14171211559040905,\n",
    "                0.1417181361315976,\n",
    "                0.1425099620058197,\n",
    "                0.14287737387127633,\n",
    "            ],\n",
    "            \"mean_absolute_percentage_error__weighted_average\": [\n",
    "                0.13537962851907534,\n",
    "                0.14171211559040905,\n",
    "                0.14171813613159756,\n",
    "                0.14250996200581972,\n",
    "                0.14287737387127633,\n",
    "            ],\n",
    "            \"mean_absolute_percentage_error__pooling\": [\n",
    "                0.13537962851907534,\n",
    "                0.14171211559040905,\n",
    "                0.14171813613159756,\n",
    "                0.14250996200581975,\n",
    "                0.14287737387127633,\n",
    "            ],\n",
    "            \"mean_absolute_scaled_error__average\": [\n",
    "                0.9807885628114613,\n",
    "                0.9887040054273549,\n",
    "                0.9887272793513265,\n",
    "                0.9982897158009892,\n",
    "                0.999726922014544,\n",
    "            ],\n",
    "            \"mean_absolute_scaled_error__weighted_average\": [\n",
    "                0.9807885628114613,\n",
    "                0.9887040054273548,\n",
    "                0.9887272793513265,\n",
    "                0.9982897158009892,\n",
    "                0.9997269220145439,\n",
    "            ],\n",
    "            \"mean_absolute_scaled_error__pooling\": [\n",
    "                0.994386675351447,\n",
    "                1.0309527259247835,\n",
    "                1.0309910949992809,\n",
    "                1.039045301850066,\n",
    "                1.0413476602398484,\n",
    "            ],\n",
    "            \"alpha\": [\n",
    "                766.6289057556013,\n",
    "                0.4279898484823994,\n",
    "                0.2252709077935534,\n",
    "                15.094374246471325,\n",
    "                2.031835829826598,\n",
    "            ],\n",
    "        },\n",
    "        index=pd.RangeIndex(start=0, stop=5, step=1),\n",
    "    )\n",
    "\n",
    "    pd.testing.assert_frame_equal(results, expected_results)\n",
    "\n",
    "test_output_bayesian_search_forecaster_multiseries_ForecasterAutoregMultiSeries_one_step_ahead()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_output_grid_search_forecaster_multiseries_ForecasterAutoregMultiSeries_one_step_ahead_series_is_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 191\u001b[0m\n\u001b[1;32m     52\u001b[0m     expected_results \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[1;32m     53\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlevels\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m     54\u001b[0m             [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid_1000\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid_1001\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid_1002\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid_1003\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid_1004\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    186\u001b[0m         index \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mRangeIndex(start\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, stop\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m, step\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    187\u001b[0m     )\n\u001b[1;32m    189\u001b[0m     pd\u001b[38;5;241m.\u001b[39mtesting\u001b[38;5;241m.\u001b[39massert_frame_equal(results, expected_results)\n\u001b[0;32m--> 191\u001b[0m \u001b[43mtest_output_grid_search_forecaster_multiseries_ForecasterAutoregMultiSeries_one_step_ahead_series_is_dict\u001b[49m()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_output_grid_search_forecaster_multiseries_ForecasterAutoregMultiSeries_one_step_ahead_series_is_dict' is not defined"
     ]
    }
   ],
   "source": [
    "series_dict = joblib.load(\"/home/ubuntu/varios/skforecast/skforecast/model_selection_multiseries/tests/fixture_sample_multi_series.joblib\")\n",
    "exog_dict = joblib.load(\"/home/ubuntu/varios/skforecast/skforecast/model_selection_multiseries/tests/fixture_sample_multi_series_exog.joblib\")\n",
    "end_train = \"2016-07-31 23:59:00\"\n",
    "initial_train_size = 213\n",
    "\n",
    "def test_output_bayesian_search_forecaster_multiseries_ForecasterAutoregMultiSeries_one_step_ahead_series_is_dict():\n",
    "    \"\"\"\n",
    "    Test output of grid_search_forecaster_multiseries in ForecasterAutoregMultiSeriesCustom\n",
    "    with mocked (mocked done in Skforecast v0.5.0)\n",
    "    \"\"\"\n",
    "    metrics = ['mean_absolute_error', mean_absolute_percentage_error, mean_absolute_scaled_error]\n",
    "    forecaster = ForecasterAutoregMultiSeries(\n",
    "            regressor          = LGBMRegressor(random_state=678, verbose=-1),\n",
    "            lags               = 3,\n",
    "            encoding           = 'ordinal',\n",
    "            transformer_series = StandardScaler(),\n",
    "            transformer_exog   = StandardScaler(),\n",
    "            weight_func        = None,\n",
    "            series_weights     = None,\n",
    "            differentiation    = None,\n",
    "            dropna_from_series = False,\n",
    "        )\n",
    "    steps = 10\n",
    "    initial_train_size = 213\n",
    "    levels = [\"id_1000\", \"id_1001\", \"id_1002\", \"id_1003\", \"id_1004\"]\n",
    "    param_grid = {\n",
    "            \"n_estimators\": [5, 10],\n",
    "            \"max_depth\": [2, 3]\n",
    "        }\n",
    "    lags_grid = [3, 5]\n",
    "\n",
    "    results = grid_search_forecaster_multiseries(\n",
    "        forecaster         = forecaster,\n",
    "        series             = series_dict,\n",
    "        exog               = exog_dict,\n",
    "        param_grid         = param_grid,\n",
    "        lags_grid          = lags_grid,\n",
    "        steps              = steps,\n",
    "        refit              = False,\n",
    "        metric             = metrics,\n",
    "        initial_train_size = initial_train_size,\n",
    "        method             = 'one_step_ahead',\n",
    "        aggregate_metric   = [\"average\", \"weighted_average\", \"pooling\"],\n",
    "        levels            = levels,\n",
    "        fixed_train_size   = False,\n",
    "        return_best        = False,\n",
    "        n_jobs             = 'auto',\n",
    "        verbose            = False,\n",
    "        show_progress      = False\n",
    "    )\n",
    "    \n",
    "    expected_results = pd.DataFrame({\n",
    "        \"levels\": [\n",
    "            [\"id_1000\", \"id_1001\", \"id_1002\", \"id_1003\", \"id_1004\"],\n",
    "            [\"id_1000\", \"id_1001\", \"id_1002\", \"id_1003\", \"id_1004\"],\n",
    "            [\"id_1000\", \"id_1001\", \"id_1002\", \"id_1003\", \"id_1004\"],\n",
    "            [\"id_1000\", \"id_1001\", \"id_1002\", \"id_1003\", \"id_1004\"],\n",
    "            [\"id_1000\", \"id_1001\", \"id_1002\", \"id_1003\", \"id_1004\"],\n",
    "            [\"id_1000\", \"id_1001\", \"id_1002\", \"id_1003\", \"id_1004\"],\n",
    "            [\"id_1000\", \"id_1001\", \"id_1002\", \"id_1003\", \"id_1004\"],\n",
    "            [\"id_1000\", \"id_1001\", \"id_1002\", \"id_1003\", \"id_1004\"],\n",
    "        ],\n",
    "        \"lags\": [\n",
    "            np.array([1, 2, 3, 4, 5]),\n",
    "            np.array([1, 2, 3]),\n",
    "            np.array([1, 2, 3]),\n",
    "            np.array([1, 2, 3, 4, 5]),\n",
    "            np.array([1, 2, 3, 4, 5]),\n",
    "            np.array([1, 2, 3]),\n",
    "            np.array([1, 2, 3]),\n",
    "            np.array([1, 2, 3, 4, 5]),\n",
    "        ],\n",
    "        \"lags_label\": [\n",
    "            np.array([1, 2, 3, 4, 5]),\n",
    "            np.array([1, 2, 3]),\n",
    "            np.array([1, 2, 3]),\n",
    "            np.array([1, 2, 3, 4, 5]),\n",
    "            np.array([1, 2, 3, 4, 5]),\n",
    "            np.array([1, 2, 3]),\n",
    "            np.array([1, 2, 3]),\n",
    "            np.array([1, 2, 3, 4, 5]),\n",
    "        ],\n",
    "        \"params\": [\n",
    "            {\"max_depth\": 3, \"n_estimators\": 10},\n",
    "            {\"max_depth\": 3, \"n_estimators\": 10},\n",
    "            {\"max_depth\": 2, \"n_estimators\": 10},\n",
    "            {\"max_depth\": 2, \"n_estimators\": 10},\n",
    "            {\"max_depth\": 3, \"n_estimators\": 5},\n",
    "            {\"max_depth\": 3, \"n_estimators\": 5},\n",
    "            {\"max_depth\": 2, \"n_estimators\": 5},\n",
    "            {\"max_depth\": 2, \"n_estimators\": 5},\n",
    "        ],\n",
    "        \"mean_absolute_error__average\": [\n",
    "            595.4248731239852,\n",
    "            601.61658409234,\n",
    "            641.5971327961081,\n",
    "            643.5830924971917,\n",
    "            677.9145593017354,\n",
    "            687.1976066932838,\n",
    "            709.8383108516048,\n",
    "            712.5538939535741,\n",
    "        ],\n",
    "        \"mean_absolute_error__weighted_average\": [\n",
    "            601.0754794775827,\n",
    "            602.8512611773792,\n",
    "            637.9906397322952,\n",
    "            635.3319731010223,\n",
    "            669.4535161312964,\n",
    "            674.4638410667131,\n",
    "            694.4718207943295,\n",
    "            695.1809840497659,\n",
    "        ],\n",
    "        \"mean_absolute_error__pooling\": [\n",
    "            601.0754794775827,\n",
    "            602.8512611773791,\n",
    "            637.9906397322952,\n",
    "            635.3319731010222,\n",
    "            669.4535161312965,\n",
    "            674.4638410667131,\n",
    "            694.4718207943295,\n",
    "            695.1809840497659,\n",
    "        ],\n",
    "        \"mean_absolute_percentage_error__average\": [\n",
    "            1.13122611897686e16,\n",
    "            1.1653837498770236e16,\n",
    "            1.1977069509022024e16,\n",
    "            1.2092182501085004e16,\n",
    "            1.2255524771350234e16,\n",
    "            1.2487020718197592e16,\n",
    "            1.3255138678699688e16,\n",
    "            1.320416830274058e16,\n",
    "        ],\n",
    "        \"mean_absolute_percentage_error__weighted_average\": [\n",
    "            1.6602167501530896e16,\n",
    "            1.7103473739202362e16,\n",
    "            1.757785740892441e16,\n",
    "            1.7746800217419718e16,\n",
    "            1.7986525563708256e16,\n",
    "            1.832627501087992e16,\n",
    "            1.945358482341537e16,\n",
    "            1.9378779379561716e16,\n",
    "        ],\n",
    "        \"mean_absolute_percentage_error__pooling\": [\n",
    "            1.6602167501530896e16,\n",
    "            1.7103473739202362e16,\n",
    "            1.7577857408924412e16,\n",
    "            1.7746800217419718e16,\n",
    "            1.7986525563708258e16,\n",
    "            1.832627501087992e16,\n",
    "            1.9453584823415372e16,\n",
    "            1.9378779379561716e16,\n",
    "        ],\n",
    "        \"mean_absolute_scaled_error__average\": [\n",
    "            1.338257547877582,\n",
    "            1.3458574988611296,\n",
    "            1.418344242255843,\n",
    "            1.4196630001824362,\n",
    "            1.502472367026163,\n",
    "            1.516064192858667,\n",
    "            1.5547477191379595,\n",
    "            1.5594122630466858,\n",
    "        ],\n",
    "        \"mean_absolute_scaled_error__weighted_average\": [\n",
    "            1.6314647598931409,\n",
    "            1.627988835703755,\n",
    "            1.720233806106665,\n",
    "            1.7212080197022548,\n",
    "            1.8204941416870104,\n",
    "            1.8231712390456873,\n",
    "            1.8766737381944514,\n",
    "            1.8860125959513818,\n",
    "        ],\n",
    "        \"mean_absolute_scaled_error__pooling\": [\n",
    "            1.4086529286833727,\n",
    "            1.4224992984312164,\n",
    "            1.505414844206229,\n",
    "            1.4889348761536338,\n",
    "            1.5689005596025196,\n",
    "            1.5914777035729348,\n",
    "            1.6386889129680593,\n",
    "            1.6291942735674578,\n",
    "        ],\n",
    "        \"max_depth\": [3, 3, 2, 2, 3, 3, 2, 2],\n",
    "        \"n_estimators\": [10, 10, 10, 10, 5, 5, 5, 5],\n",
    "        },\n",
    "        index = pd.RangeIndex(start=0, stop=8, step=1)\n",
    "    )\n",
    "\n",
    "    pd.testing.assert_frame_equal(results, expected_results)\n",
    "\n",
    "test_output_grid_search_forecaster_multiseries_ForecasterAutoregMultiSeries_one_step_ahead_series_is_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skforecast_py10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c78d62c1713fdacd99ef7c429003c7324b36fbb551fb8b6860a7ea73e9338235"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
