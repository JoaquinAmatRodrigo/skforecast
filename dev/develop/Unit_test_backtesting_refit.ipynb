{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bb89911",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-22T10:33:31.967668Z",
     "start_time": "2022-02-22T10:33:31.965379Z"
    }
   },
   "source": [
    "# Backtesting with fixed training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8dbf8341-1321-4643-a3b1-0d70cc9bb589",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(1, str(Path.cwd().parent.parent))\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61df40db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T15:24:29.162950Z",
     "start_time": "2022-02-25T15:24:29.099080Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All mocked backtesting are done in skforecast 0.4.2\n",
    "# ==============================================================================\n",
    "import skforecast\n",
    "skforecast.__version__ == '0.4.2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d190c061",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T15:24:31.653292Z",
     "start_time": "2022-02-25T15:24:31.644872Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip uninstall skforecast -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd88a96c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T15:24:32.773737Z",
     "start_time": "2022-02-25T15:24:32.007832Z"
    }
   },
   "outputs": [],
   "source": [
    "# Unit test __init__\n",
    "# ==============================================================================\n",
    "import pytest\n",
    "from pytest import approx\n",
    "from typing import Union, Tuple, Optional, Any\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import logging\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import mean_squared_error \n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from skforecast.model_selection import backtesting_forecaster\n",
    "from skforecast.model_selection.model_selection import _get_metric\n",
    "from skforecast.model_selection.model_selection import _backtesting_forecaster_refit\n",
    "from skforecast.ForecasterAutoreg import ForecasterAutoreg\n",
    "from skforecast.ForecasterAutoregCustom import ForecasterAutoregCustom\n",
    "from skforecast.ForecasterAutoregMultiOutput import ForecasterAutoregMultiOutput\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb4fd29",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## _Backtesting_forecaster_refit fixed_train_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c048884d",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba010866",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T14:07:24.265722Z",
     "start_time": "2022-02-23T14:07:24.232786Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def _backtesting_forecaster_refit(\n",
    "    forecaster,\n",
    "    y: pd.Series,\n",
    "    steps: int,\n",
    "    metric: Union[str, callable],\n",
    "    initial_train_size: int,\n",
    "    exog: Optional[Union[pd.Series, pd.DataFrame]]=None,\n",
    "    interval: Optional[list]=None,\n",
    "    n_boot: int=500,\n",
    "    random_state: int=123,\n",
    "    in_sample_residuals: bool=True,\n",
    "    verbose: bool=False,\n",
    "    set_out_sample_residuals: Any='deprecated'\n",
    ") -> Tuple[np.array, pd.DataFrame]:\n",
    "    '''\n",
    "    Backtesting of forecaster model with a re-fitting strategy. A copy of the  \n",
    "    original forecaster is created so it is not modified during the process.\n",
    "    \n",
    "    In each iteration:\n",
    "        - Fit forecaster with the training set.\n",
    "        - A number of `steps` ahead are predicted.\n",
    "        - The training set increases with `steps` observations.\n",
    "        - The model is re-fitted using the new training set.\n",
    "\n",
    "    In order to apply backtesting with re-fit, an initial training set must be\n",
    "    available, otherwise it would not be possible to increase the training set \n",
    "    after each iteration. `initial_train_size` must be provided.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    forecaster : ForecasterAutoreg, ForecasterAutoregCustom, ForecasterAutoregMultiOutput\n",
    "        Forecaster model.\n",
    "        \n",
    "    y : pandas Series\n",
    "        Training time series values. \n",
    "    \n",
    "    initial_train_size: int\n",
    "        Number of samples in the initial train split. The backtest forecaster is\n",
    "        trained using the first `initial_train_size` observations.\n",
    "        \n",
    "    steps : int\n",
    "        Number of steps to predict.\n",
    "        \n",
    "    metric : str, callable\n",
    "        Metric used to quantify the goodness of fit of the model.\n",
    "        \n",
    "        If string:\n",
    "            {'mean_squared_error', 'mean_absolute_error', 'mean_absolute_percentage_error'}\n",
    "\n",
    "        It callable:\n",
    "            Function with arguments y_true, y_pred that returns a float.\n",
    "        \n",
    "    exog :panda Series, pandas DataFrame, default `None`\n",
    "        Exogenous variable/s included as predictor/s. Must have the same\n",
    "        number of observations as `y` and should be aligned so that y[i] is\n",
    "        regressed on exog[i].\n",
    "\n",
    "    interval: list, default `None`\n",
    "        Confidence of the prediction interval estimated. Sequence of percentiles\n",
    "        to compute, which must be between 0 and 100 inclusive. If `None`, no\n",
    "        intervals are estimated. Only available for forecaster of type ForecasterAutoreg\n",
    "        and ForecasterAutoregCustom.\n",
    "            \n",
    "    n_boot: int, default `500`\n",
    "        Number of bootstrapping iterations used to estimate prediction\n",
    "        intervals.\n",
    "\n",
    "    random_state: int, default 123\n",
    "        Sets a seed to the random generator, so that boot intervals are always \n",
    "        deterministic.\n",
    "\n",
    "    in_sample_residuals: bool, default `True`\n",
    "        If `True`, residuals from the training data are used as proxy of\n",
    "        prediction error to create prediction intervals. If `False`, out_sample_residuals\n",
    "        are used if they are already stored inside the forecaster.\n",
    "\n",
    "    set_out_sample_residuals: 'deprecated'\n",
    "        Deprecated since version 0.4.2, will be removed on version 0.5.0.\n",
    "            \n",
    "    verbose : bool, default `False`\n",
    "        Print number of folds and index of training and validation sets used for backtesting.\n",
    "\n",
    "    Returns \n",
    "    -------\n",
    "    metric_value: numpy ndarray shape (1,)\n",
    "        Value of the metric.\n",
    "\n",
    "    backtest_predictions: pandas Dataframe\n",
    "        Value of predictions and their estimated interval if `interval` is not `None`.\n",
    "            column pred = predictions.\n",
    "            column lower_bound = lower bound of the interval.\n",
    "            column upper_bound = upper bound interval of the interval.\n",
    "\n",
    "    '''\n",
    "    \n",
    "    forecaster = deepcopy(forecaster)\n",
    "    if isinstance(metric, str):\n",
    "        metric = _get_metric(metric=metric)\n",
    "    backtest_predictions = []\n",
    "    \n",
    "    folds = int(np.ceil((len(y) - initial_train_size) / steps))\n",
    "    remainder = (len(y) - initial_train_size) % steps\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Information of backtesting process\")\n",
    "        print(f\"----------------------------------\")\n",
    "        print(f\"Number of observations used for initial training: {initial_train_size}\")\n",
    "        print(f\"Number of observations used for backtesting: {len(y) - initial_train_size}\")\n",
    "        print(f\"    Number of folds: {folds}\")\n",
    "        print(f\"    Number of steps per fold: {steps}\")\n",
    "        if remainder != 0:\n",
    "            print(f\"    Last fold only includes {remainder} observations.\")\n",
    "        print(\"\")\n",
    "        for i in range(folds):\n",
    "            train_size = initial_train_size + i * steps\n",
    "            print(f\"Data partition in fold: {i}\")\n",
    "            if i < folds - 1:\n",
    "                print(f\"    Training:   {y.index[0]} -- {y.index[train_size - 1]}\")\n",
    "                print(f\"    Validation: {y.index[train_size]} -- {y.index[train_size + steps - 1]}\")\n",
    "            else:\n",
    "                print(f\"    Training:   {y.index[0]} -- {y.index[train_size - 1]}\")\n",
    "                print(f\"    Validation: {y.index[train_size]} -- {y.index[-1]}\")\n",
    "        print(\"\")\n",
    "        \n",
    "    if folds > 50:\n",
    "        print(\n",
    "            f\"Forecaster will be fit {folds} times. This can take substantial amounts of time. \"\n",
    "            f\"If not feasible, try with `refit = False`. \\n\"\n",
    "        )\n",
    "\n",
    "    for i in range(folds):\n",
    "        # In each iteration (except the last one) the model is fitted before\n",
    "        # making predictions. The train size increases by `steps` in each iteration.\n",
    "        train_size = initial_train_size + i * steps\n",
    "        if exog is not None:\n",
    "            next_window_exog = exog.iloc[train_size:train_size + steps, ]\n",
    "\n",
    "        if interval is None:\n",
    "\n",
    "            if i < folds - 1:\n",
    "                if exog is None:\n",
    "                    forecaster.fit(y=y.iloc[:train_size])\n",
    "                    pred = forecaster.predict(steps=steps)\n",
    "                else:\n",
    "                    forecaster.fit(y=y.iloc[:train_size], exog=exog.iloc[:train_size, ])\n",
    "                    pred = forecaster.predict(steps=steps,exog=next_window_exog)\n",
    "            else:    \n",
    "                if remainder == 0:\n",
    "                    if exog is None:\n",
    "                        forecaster.fit(y=y.iloc[:train_size])\n",
    "                        pred = forecaster.predict(steps=steps)\n",
    "                    else:\n",
    "                        forecaster.fit(y=y.iloc[:train_size], exog=exog.iloc[:train_size, ])\n",
    "                        pred = forecaster.predict(steps=steps, exog=next_window_exog)\n",
    "                else:\n",
    "                    # Only the remaining steps need to be predicted\n",
    "                    steps = remainder\n",
    "                    if exog is None:\n",
    "                        forecaster.fit(y=y.iloc[:train_size])\n",
    "                        pred = forecaster.predict(steps=steps)\n",
    "                    else:\n",
    "                        forecaster.fit(y=y.iloc[:train_size], exog=exog.iloc[:train_size, ])\n",
    "                        pred = forecaster.predict(steps=steps, exog=next_window_exog)\n",
    "        else:\n",
    "\n",
    "            if i < folds - 1:\n",
    "                if exog is None:\n",
    "                    forecaster.fit(y=y.iloc[:train_size])\n",
    "                    pred = forecaster.predict_interval(\n",
    "                                steps        = steps,\n",
    "                                interval     = interval,\n",
    "                                n_boot       = n_boot,\n",
    "                                random_state = random_state,\n",
    "                                in_sample_residuals = in_sample_residuals\n",
    "                            )\n",
    "                else:\n",
    "                    forecaster.fit(y=y.iloc[:train_size], exog=exog.iloc[:train_size, ])\n",
    "                    pred = forecaster.predict_interval(\n",
    "                                steps        = steps,\n",
    "                                exog         = next_window_exog,\n",
    "                                interval     = interval,\n",
    "                                n_boot       = n_boot,\n",
    "                                random_state = random_state,\n",
    "                                in_sample_residuals = in_sample_residuals\n",
    "                           )\n",
    "            else:    \n",
    "                if remainder == 0:\n",
    "                    if exog is None:\n",
    "                        forecaster.fit(y=y.iloc[:train_size])\n",
    "                        pred = forecaster.predict_interval(\n",
    "                                steps        = steps,\n",
    "                                interval     = interval,\n",
    "                                n_boot       = n_boot,\n",
    "                                random_state = random_state,\n",
    "                                in_sample_residuals = in_sample_residuals\n",
    "                            )\n",
    "                    else:\n",
    "                        forecaster.fit(y=y.iloc[:train_size], exog=exog.iloc[:train_size, ])\n",
    "                        pred = forecaster.predict_interval(\n",
    "                                steps        = steps,\n",
    "                                exog         = next_window_exog,\n",
    "                                interval     = interval,\n",
    "                                n_boot       = n_boot,\n",
    "                                random_state = random_state,\n",
    "                                in_sample_residuals = in_sample_residuals\n",
    "                           )\n",
    "                else:\n",
    "                    # Only the remaining steps need to be predicted\n",
    "                    steps = remainder\n",
    "                    if exog is None:\n",
    "                        forecaster.fit(y=y.iloc[:train_size])\n",
    "                        pred = forecaster.predict_interval(\n",
    "                                steps        = steps,\n",
    "                                interval     = interval,\n",
    "                                n_boot       = n_boot,\n",
    "                                random_state = random_state,\n",
    "                                in_sample_residuals = in_sample_residuals\n",
    "                            )\n",
    "                    else:\n",
    "                        forecaster.fit(y=y.iloc[:train_size], exog=exog.iloc[:train_size, ])\n",
    "                        pred = forecaster.predict_interval(\n",
    "                                steps        = steps,\n",
    "                                exog         = next_window_exog,\n",
    "                                interval     = interval,\n",
    "                                n_boot       = n_boot,\n",
    "                                random_state = random_state,\n",
    "                                in_sample_residuals = in_sample_residuals\n",
    "                           )\n",
    "\n",
    "        backtest_predictions.append(pred)\n",
    "    \n",
    "    backtest_predictions = pd.concat(backtest_predictions)\n",
    "    if isinstance(backtest_predictions, pd.Series):\n",
    "            backtest_predictions = pd.DataFrame(backtest_predictions)\n",
    "\n",
    "    metric_value = metric(\n",
    "                    y_true = y.iloc[initial_train_size: initial_train_size + len(backtest_predictions)],\n",
    "                    y_pred = backtest_predictions['pred']\n",
    "                   )\n",
    "\n",
    "    return np.array([metric_value]), backtest_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3ded8f01",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T14:13:41.750716Z",
     "start_time": "2022-02-23T14:13:41.629909Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y = pd.Series(np.arange(40))\n",
    "forecaster = ForecasterAutoreg(\n",
    "                regressor = RandomForestRegressor(random_state=123),\n",
    "                lags      = 3 \n",
    "             )\n",
    "forecaster.fit(y=y)\n",
    "\n",
    "n_backtest = 15\n",
    "y_train = y[:-n_backtest]\n",
    "y_backtest = y[-n_backtest:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "232b83ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T14:35:08.169729Z",
     "start_time": "2022-02-23T14:35:08.152491Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 4 3\n"
     ]
    }
   ],
   "source": [
    "folds = int(np.ceil((len(y) - len(y_train)) / 4))\n",
    "remainder = (len(y) - len(y_train)) % 4\n",
    "print(len(y_train), folds, remainder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "724a467d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T14:13:56.225986Z",
     "start_time": "2022-02-23T14:13:55.664681Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 25\n",
      "Number of observations used for backtesting: 15\n",
      "    Number of folds: 4\n",
      "    Number of steps per fold: 4\n",
      "    Last fold only includes 3 observations.\n",
      "\n",
      "Data partition in fold: 0\n",
      "    Training:   0 -- 24\n",
      "    Validation: 25 -- 28\n",
      "Data partition in fold: 1\n",
      "    Training:   0 -- 28\n",
      "    Validation: 29 -- 32\n",
      "Data partition in fold: 2\n",
      "    Training:   0 -- 32\n",
      "    Validation: 33 -- 36\n",
      "Data partition in fold: 3\n",
      "    Training:   0 -- 36\n",
      "    Validation: 37 -- 39\n",
      "\n",
      "[9.85436667]      pred\n",
      "25  23.33\n",
      "26  23.33\n",
      "27  23.33\n",
      "28  23.33\n",
      "29  27.52\n",
      "30  27.52\n",
      "31  27.52\n",
      "32  27.52\n",
      "33  31.53\n",
      "34  31.53\n",
      "35  31.53\n",
      "36  31.53\n",
      "37  35.43\n",
      "38  35.43\n",
      "39  35.43\n"
     ]
    }
   ],
   "source": [
    "metric, predictions_backtest = backtesting_forecaster(\n",
    "                                    forecaster = forecaster,\n",
    "                                    y          = y,\n",
    "                                    initial_train_size = len(y_train),\n",
    "                                    steps      = 4,\n",
    "                                    metric     = 'mean_squared_error',\n",
    "                                    refit      = True,\n",
    "                                    verbose    = True\n",
    "                               )\n",
    "\n",
    "# print(metric, predictions_backtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09278c2",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3a8b314c",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "###  New"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09762a0c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T11:35:43.749044Z",
     "start_time": "2022-02-25T11:35:43.704362Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def _backtesting_forecaster_refit_n(\n",
    "    forecaster,\n",
    "    y: pd.Series,\n",
    "    steps: int,\n",
    "    metric: Union[str, callable],\n",
    "    initial_train_size: int,\n",
    "    fixed_train_size: bool=False,\n",
    "    exog: Optional[Union[pd.Series, pd.DataFrame]]=None,\n",
    "    interval: Optional[list]=None,\n",
    "    n_boot: int=500,\n",
    "    random_state: int=123,\n",
    "    in_sample_residuals: bool=True,\n",
    "    verbose: bool=False,\n",
    "    set_out_sample_residuals: Any='deprecated'\n",
    ") -> Tuple[np.array, pd.DataFrame]:\n",
    "    '''\n",
    "    Backtesting of forecaster model with a re-fitting strategy. A copy of the  \n",
    "    original forecaster is created so it is not modified during the process.\n",
    "    \n",
    "    In each iteration:\n",
    "        - Fit forecaster with the training set.\n",
    "        - A number of `steps` ahead are predicted.\n",
    "        - The training set increases with `steps` observations.\n",
    "        - The model is re-fitted using the new training set.\n",
    "\n",
    "    In order to apply backtesting with re-fit, an initial training set must be\n",
    "    available, otherwise it would not be possible to increase the training set \n",
    "    after each iteration. `initial_train_size` must be provided.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    forecaster : ForecasterAutoreg, ForecasterAutoregCustom, ForecasterAutoregMultiOutput\n",
    "        Forecaster model.\n",
    "        \n",
    "    y : pandas Series\n",
    "        Training time series values. \n",
    "    \n",
    "    initial_train_size: int\n",
    "        Number of samples in the initial train split. The backtest forecaster is\n",
    "        trained using the first `initial_train_size` observations.\n",
    "        \n",
    "    fixed_train_size: bool, default `False`\n",
    "        If True, train size doesn't increases but moves by `steps` in each iteration.\n",
    "        \n",
    "    steps : int\n",
    "        Number of steps to predict.\n",
    "        \n",
    "    metric : str, callable\n",
    "        Metric used to quantify the goodness of fit of the model.\n",
    "        \n",
    "        If string:\n",
    "            {'mean_squared_error', 'mean_absolute_error', 'mean_absolute_percentage_error'}\n",
    "\n",
    "        It callable:\n",
    "            Function with arguments y_true, y_pred that returns a float.\n",
    "        \n",
    "    exog :panda Series, pandas DataFrame, default `None`\n",
    "        Exogenous variable/s included as predictor/s. Must have the same\n",
    "        number of observations as `y` and should be aligned so that y[i] is\n",
    "        regressed on exog[i].\n",
    "\n",
    "    interval: list, default `None`\n",
    "        Confidence of the prediction interval estimated. Sequence of percentiles\n",
    "        to compute, which must be between 0 and 100 inclusive. If `None`, no\n",
    "        intervals are estimated. Only available for forecaster of type ForecasterAutoreg\n",
    "        and ForecasterAutoregCustom.\n",
    "            \n",
    "    n_boot: int, default `500`\n",
    "        Number of bootstrapping iterations used to estimate prediction\n",
    "        intervals.\n",
    "\n",
    "    random_state: int, default 123\n",
    "        Sets a seed to the random generator, so that boot intervals are always \n",
    "        deterministic.\n",
    "\n",
    "    in_sample_residuals: bool, default `True`\n",
    "        If `True`, residuals from the training data are used as proxy of\n",
    "        prediction error to create prediction intervals. If `False`, out_sample_residuals\n",
    "        are used if they are already stored inside the forecaster.\n",
    "\n",
    "    set_out_sample_residuals: 'deprecated'\n",
    "        Deprecated since version 0.4.2, will be removed on version 0.5.0.\n",
    "            \n",
    "    verbose : bool, default `False`\n",
    "        Print number of folds and index of training and validation sets used for backtesting.\n",
    "\n",
    "    Returns \n",
    "    -------\n",
    "    metric_value: numpy ndarray shape (1,)\n",
    "        Value of the metric.\n",
    "\n",
    "    backtest_predictions: pandas Dataframe\n",
    "        Value of predictions and their estimated interval if `interval` is not `None`.\n",
    "            column pred = predictions.\n",
    "            column lower_bound = lower bound of the interval.\n",
    "            column upper_bound = upper bound interval of the interval.\n",
    "\n",
    "    '''\n",
    "    forecaster = deepcopy(forecaster)\n",
    "    if isinstance(metric, str):\n",
    "        metric = _get_metric(metric=metric)\n",
    "    backtest_predictions = []\n",
    "    \n",
    "    folds = int(np.ceil((len(y) - initial_train_size) / steps))\n",
    "    remainder = (len(y) - initial_train_size) % steps\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Information of backtesting process\")\n",
    "        print(f\"----------------------------------\")\n",
    "        print(f\"Number of observations used for initial training: {initial_train_size}\")\n",
    "        print(f\"Number of observations used for backtesting: {len(y) - initial_train_size}\")\n",
    "        print(f\"    Number of folds: {folds}\")\n",
    "        print(f\"    Number of steps per fold: {steps}\")\n",
    "        if remainder != 0:\n",
    "            print(f\"    Last fold only includes {remainder} observations.\")\n",
    "        print(\"\")\n",
    "        for i in range(folds):\n",
    "            if fixed_train_size:\n",
    "                # The train size doesn't increase but moves by `steps` in each iteration.\n",
    "                train_idx_start = i * steps\n",
    "                train_idx_end = initial_train_size + i * steps\n",
    "            else:\n",
    "                # The train size increases by `steps` in each iteration.\n",
    "                train_idx_start = 0\n",
    "                train_idx_end = initial_train_size + i * steps\n",
    "            print(f\"Data partition in fold: {i}\")\n",
    "            if i < folds - 1:\n",
    "                print(f\"    Training:   {y.index[train_idx_start]} -- {y.index[train_idx_end - 1]}\")\n",
    "                print(f\"    Validation: {y.index[train_idx_end]} -- {y.index[train_idx_end + steps - 1]}\")\n",
    "            else:\n",
    "                print(f\"    Training:   {y.index[train_idx_start]} -- {y.index[train_idx_end - 1]}\")\n",
    "                print(f\"    Validation: {y.index[train_idx_end]} -- {y.index[-1]}\")\n",
    "        print(\"\")\n",
    "        \n",
    "    if folds > 50:\n",
    "        print(\n",
    "            f\"Forecaster will be fit {folds} times. This can take substantial amounts of time. \"\n",
    "            f\"If not feasible, try with `refit = False`. \\n\"\n",
    "        )\n",
    "    \n",
    "    for i in range(folds):\n",
    "        # In each iteration (except the last one) the model is fitted before making predictions.\n",
    "        if fixed_train_size:\n",
    "            # The train size doesn't increases but moves by `steps` in each iteration.\n",
    "            train_idx_start = i * steps\n",
    "            train_idx_end = initial_train_size + i * steps\n",
    "        else:\n",
    "            # The train size increases by `steps` in each iteration.\n",
    "            train_idx_start = 0\n",
    "            train_idx_end = initial_train_size + i * steps\n",
    "            \n",
    "        if exog is not None:\n",
    "            next_window_exog = exog.iloc[train_idx_end:train_idx_end + steps, ]\n",
    "\n",
    "        if interval is None:\n",
    "\n",
    "            if i < folds - 1:\n",
    "                if exog is None:\n",
    "                    forecaster.fit(y=y.iloc[train_idx_start:train_idx_end])\n",
    "                    pred = forecaster.predict(steps=steps)\n",
    "                else:\n",
    "                    forecaster.fit(\n",
    "                        y = y.iloc[train_idx_start:train_idx_end], \n",
    "                        exog = exog.iloc[train_idx_start:train_idx_end, ]\n",
    "                    )\n",
    "                    pred = forecaster.predict(steps=steps, exog=next_window_exog)\n",
    "            else:    \n",
    "                if remainder == 0:\n",
    "                    if exog is None:\n",
    "                        forecaster.fit(y=y.iloc[train_idx_start:train_idx_end])\n",
    "                        pred = forecaster.predict(steps=steps)\n",
    "                    else:\n",
    "                        forecaster.fit(\n",
    "                            y = y.iloc[train_idx_start:train_idx_end], \n",
    "                            exog = exog.iloc[train_idx_start:train_idx_end, ]\n",
    "                        )\n",
    "                        pred = forecaster.predict(steps=steps, exog=next_window_exog)\n",
    "                else:\n",
    "                    # Only the remaining steps need to be predicted\n",
    "                    steps = remainder\n",
    "                    if exog is None:\n",
    "                        forecaster.fit(y=y.iloc[train_idx_start:train_idx_end])\n",
    "                        pred = forecaster.predict(steps=steps)\n",
    "                    else:\n",
    "                        forecaster.fit(\n",
    "                            y = y.iloc[train_idx_start:train_idx_end], \n",
    "                            exog = exog.iloc[train_idx_start:train_idx_end, ]\n",
    "                        )\n",
    "                        pred = forecaster.predict(steps=steps, exog=next_window_exog)\n",
    "        else:\n",
    "\n",
    "            if i < folds - 1:\n",
    "                if exog is None:\n",
    "                    forecaster.fit(y=y.iloc[train_idx_start:train_idx_end])\n",
    "                    pred = forecaster.predict_interval(\n",
    "                                steps        = steps,\n",
    "                                interval     = interval,\n",
    "                                n_boot       = n_boot,\n",
    "                                random_state = random_state,\n",
    "                                in_sample_residuals = in_sample_residuals\n",
    "                            )\n",
    "                else:\n",
    "                    forecaster.fit(\n",
    "                        y = y.iloc[train_idx_start:train_idx_end], \n",
    "                        exog = exog.iloc[train_idx_start:train_idx_end, ]\n",
    "                    )\n",
    "                    pred = forecaster.predict_interval(\n",
    "                                steps        = steps,\n",
    "                                exog         = next_window_exog,\n",
    "                                interval     = interval,\n",
    "                                n_boot       = n_boot,\n",
    "                                random_state = random_state,\n",
    "                                in_sample_residuals = in_sample_residuals\n",
    "                           )\n",
    "            else:    \n",
    "                if remainder == 0:\n",
    "                    if exog is None:\n",
    "                        forecaster.fit(y=y.iloc[train_idx_start:train_idx_end])\n",
    "                        pred = forecaster.predict_interval(\n",
    "                                steps        = steps,\n",
    "                                interval     = interval,\n",
    "                                n_boot       = n_boot,\n",
    "                                random_state = random_state,\n",
    "                                in_sample_residuals = in_sample_residuals\n",
    "                            )\n",
    "                    else:\n",
    "                        forecaster.fit(\n",
    "                            y = y.iloc[train_idx_start:train_idx_end], \n",
    "                            exog = exog.iloc[train_idx_start:train_idx_end, ]\n",
    "                        )\n",
    "                        pred = forecaster.predict_interval(\n",
    "                                steps        = steps,\n",
    "                                exog         = next_window_exog,\n",
    "                                interval     = interval,\n",
    "                                n_boot       = n_boot,\n",
    "                                random_state = random_state,\n",
    "                                in_sample_residuals = in_sample_residuals\n",
    "                           )\n",
    "                else:\n",
    "                    # Only the remaining steps need to be predicted\n",
    "                    steps = remainder\n",
    "                    if exog is None:\n",
    "                        forecaster.fit(y=y.iloc[train_idx_start:train_idx_end])\n",
    "                        pred = forecaster.predict_interval(\n",
    "                                steps        = steps,\n",
    "                                interval     = interval,\n",
    "                                n_boot       = n_boot,\n",
    "                                random_state = random_state,\n",
    "                                in_sample_residuals = in_sample_residuals\n",
    "                            )\n",
    "                    else:\n",
    "                        forecaster.fit(\n",
    "                            y = y.iloc[train_idx_start:train_idx_end], \n",
    "                            exog = exog.iloc[train_idx_start:train_idx_end, ]\n",
    "                        )\n",
    "                        pred = forecaster.predict_interval(\n",
    "                                steps        = steps,\n",
    "                                exog         = next_window_exog,\n",
    "                                interval     = interval,\n",
    "                                n_boot       = n_boot,\n",
    "                                random_state = random_state,\n",
    "                                in_sample_residuals = in_sample_residuals\n",
    "                           )\n",
    "\n",
    "        backtest_predictions.append(pred)\n",
    "    \n",
    "    backtest_predictions = pd.concat(backtest_predictions)\n",
    "    if isinstance(backtest_predictions, pd.Series):\n",
    "        backtest_predictions = pd.DataFrame(backtest_predictions)\n",
    "\n",
    "    metric_value = metric(\n",
    "                    y_true = y.iloc[initial_train_size: initial_train_size + len(backtest_predictions)],\n",
    "                    y_pred = backtest_predictions['pred']\n",
    "                   )\n",
    "\n",
    "    return metric_value, backtest_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "a630dcb0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T20:14:05.365626Z",
     "start_time": "2022-02-24T20:14:05.171411Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y = pd.Series(np.arange(40))\n",
    "forecaster = ForecasterAutoreg(\n",
    "                regressor = RandomForestRegressor(random_state=123),\n",
    "                lags      = 3 \n",
    "             )\n",
    "forecaster.fit(y=y)\n",
    "\n",
    "n_backtest = 15\n",
    "y_train = y[:-n_backtest]\n",
    "y_backtest = y[-n_backtest:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "cc0db542",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T20:14:07.198072Z",
     "start_time": "2022-02-24T20:14:06.508642Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 25\n",
      "Number of observations used for backtesting: 15\n",
      "    Number of folds: 4\n",
      "    Number of steps per fold: 4\n",
      "    Last fold only includes 3 observations.\n",
      "\n",
      "Data partition in fold: 0\n",
      "    Training:   0 -- 24\n",
      "    Validation: 25 -- 28\n",
      "Data partition in fold: 1\n",
      "    Training:   4 -- 28\n",
      "    Validation: 29 -- 32\n",
      "Data partition in fold: 2\n",
      "    Training:   8 -- 32\n",
      "    Validation: 33 -- 36\n",
      "Data partition in fold: 3\n",
      "    Training:   12 -- 36\n",
      "    Validation: 37 -- 39\n",
      "\n",
      "[10.59823333]      pred\n",
      "25  23.33\n",
      "26  23.33\n",
      "27  23.33\n",
      "28  23.33\n",
      "29  27.33\n",
      "30  27.33\n",
      "31  27.33\n",
      "32  27.33\n",
      "33  31.33\n",
      "34  31.33\n",
      "35  31.33\n",
      "36  31.33\n",
      "37  35.33\n",
      "38  35.33\n",
      "39  35.33\n"
     ]
    }
   ],
   "source": [
    "metric, predictions_backtest = _backtesting_forecaster_refit_n(\n",
    "                                    forecaster = forecaster,\n",
    "                                    y          = y,\n",
    "                                    initial_train_size = len(y_train),\n",
    "                                    fixed_train_size = True,\n",
    "                                    steps      = 4,\n",
    "                                    metric     = 'mean_squared_error',\n",
    "                                    verbose    = True\n",
    "                               )\n",
    "\n",
    "print(metric, predictions_backtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a4f502",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1ee0d9b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T11:53:14.210659Z",
     "start_time": "2022-02-24T11:53:13.933956Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.69646919 0.28613933 0.22685145 0.55131477 0.71946897 0.42310646\n",
      " 0.9807642  0.68482974 0.4809319  0.39211752 0.34317802 0.72904971\n",
      " 0.43857224 0.0596779  0.39804426 0.73799541 0.18249173 0.17545176\n",
      " 0.53155137 0.53182759 0.63440096 0.84943179 0.72445532 0.61102351\n",
      " 0.72244338 0.32295891 0.36178866 0.22826323 0.29371405 0.63097612\n",
      " 0.09210494 0.43370117 0.43086276 0.4936851  0.42583029 0.31226122\n",
      " 0.42635131 0.89338916 0.94416002 0.50183668 0.62395295 0.1156184\n",
      " 0.31728548 0.41482621 0.86630916 0.25045537 0.48303426 0.98555979\n",
      " 0.51948512 0.61289453]\n",
      "[0.12062867 0.8263408  0.60306013 0.54506801 0.34276383 0.30412079\n",
      " 0.41702221 0.68130077 0.87545684 0.51042234 0.66931378 0.58593655\n",
      " 0.6249035  0.67468905 0.84234244 0.08319499 0.76368284 0.24366637\n",
      " 0.19422296 0.57245696 0.09571252 0.88532683 0.62724897 0.72341636\n",
      " 0.01612921 0.59443188 0.55678519 0.15895964 0.15307052 0.69552953\n",
      " 0.31876643 0.6919703  0.55438325 0.38895057 0.92513249 0.84167\n",
      " 0.35739757 0.04359146 0.30476807 0.39818568 0.70495883 0.99535848\n",
      " 0.35591487 0.76254781 0.59317692 0.6917018  0.15112745 0.39887629\n",
      " 0.2408559  0.34345601]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.51312815, 0.66662455, 0.10590849, 0.13089495, 0.32198061,\n",
       "       0.66156434, 0.84650623, 0.55325734, 0.85445249, 0.38483781,\n",
       "       0.3167879 , 0.35426468, 0.17108183, 0.82911263, 0.33867085,\n",
       "       0.55237008, 0.57855147, 0.52153306, 0.00268806, 0.98834542,\n",
       "       0.90534158, 0.20763586, 0.29248941, 0.52001015, 0.90191137,\n",
       "       0.98363088, 0.25754206, 0.56435904, 0.80696868, 0.39437005,\n",
       "       0.73107304, 0.16106901, 0.60069857, 0.86586446, 0.98352161,\n",
       "       0.07936579, 0.42834727, 0.20454286, 0.45063649, 0.54776357,\n",
       "       0.09332671, 0.29686078, 0.92758424, 0.56900373, 0.457412  ,\n",
       "       0.75352599, 0.74186215, 0.04857903, 0.7086974 , 0.83924335])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fixtures Testing Backtesting\n",
    "# ==============================================================================\n",
    "np.random.seed(123)\n",
    "y_rnd = np.random.rand(50)\n",
    "print(y_rnd)\n",
    "exog_rnd = np.random.rand(50)\n",
    "print(exog_rnd)\n",
    "out_sample_residuals_rnd = np.random.rand(50)\n",
    "out_sample_residuals_rnd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2743b0ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T15:24:47.208975Z",
     "start_time": "2022-02-25T15:24:47.188627Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fixtures Testing Backtesting\n",
    "# ==============================================================================\n",
    "y = pd.Series(\n",
    "    np.array([0.69646919, 0.28613933, 0.22685145, 0.55131477, 0.71946897,\n",
    "              0.42310646, 0.9807642 , 0.68482974, 0.4809319 , 0.39211752,\n",
    "              0.34317802, 0.72904971, 0.43857224, 0.0596779 , 0.39804426,\n",
    "              0.73799541, 0.18249173, 0.17545176, 0.53155137, 0.53182759,\n",
    "              0.63440096, 0.84943179, 0.72445532, 0.61102351, 0.72244338,\n",
    "              0.32295891, 0.36178866, 0.22826323, 0.29371405, 0.63097612,\n",
    "              0.09210494, 0.43370117, 0.43086276, 0.4936851 , 0.42583029,\n",
    "              0.31226122, 0.42635131, 0.89338916, 0.94416002, 0.50183668,\n",
    "              0.62395295, 0.1156184 , 0.31728548, 0.41482621, 0.86630916,\n",
    "              0.25045537, 0.48303426, 0.98555979, 0.51948512, 0.61289453]))\n",
    "\n",
    "exog = pd.Series(\n",
    "    np.array([0.12062867, 0.8263408 , 0.60306013, 0.54506801, 0.34276383,\n",
    "              0.30412079, 0.41702221, 0.68130077, 0.87545684, 0.51042234,\n",
    "              0.66931378, 0.58593655, 0.6249035 , 0.67468905, 0.84234244,\n",
    "              0.08319499, 0.76368284, 0.24366637, 0.19422296, 0.57245696,\n",
    "              0.09571252, 0.88532683, 0.62724897, 0.72341636, 0.01612921,\n",
    "              0.59443188, 0.55678519, 0.15895964, 0.15307052, 0.69552953,\n",
    "              0.31876643, 0.6919703 , 0.55438325, 0.38895057, 0.92513249,\n",
    "              0.84167   , 0.35739757, 0.04359146, 0.30476807, 0.39818568,\n",
    "              0.70495883, 0.99535848, 0.35591487, 0.76254781, 0.59317692,\n",
    "              0.6917018 , 0.15112745, 0.39887629, 0.2408559 , 0.34345601]), \n",
    "    name='exog')\n",
    "\n",
    "out_sample_residuals = pd.Series(\n",
    "    np.array([0.51312815, 0.66662455, 0.10590849, 0.13089495, 0.32198061,\n",
    "              0.66156434, 0.84650623, 0.55325734, 0.85445249, 0.38483781,\n",
    "              0.3167879 , 0.35426468, 0.17108183, 0.82911263, 0.33867085,\n",
    "              0.55237008, 0.57855147, 0.52153306, 0.00268806, 0.98834542,\n",
    "              0.90534158, 0.20763586, 0.29248941, 0.52001015, 0.90191137,\n",
    "              0.98363088, 0.25754206, 0.56435904, 0.80696868, 0.39437005,\n",
    "              0.73107304, 0.16106901, 0.60069857, 0.86586446, 0.98352161,\n",
    "              0.07936579, 0.42834727, 0.20454286, 0.45063649, 0.54776357,\n",
    "              0.09332671, 0.29686078, 0.92758424, 0.56900373, 0.457412  ,\n",
    "              0.75352599, 0.74186215, 0.04857903, 0.7086974 , 0.83924335]),\n",
    "    name='out_sample_residuals')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e035e8",
   "metadata": {},
   "source": [
    "### Mocked backtesting No interval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76762685",
   "metadata": {},
   "source": [
    "#### No interval no exog no remainder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a274f7c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T08:44:41.980783Z",
     "start_time": "2022-02-24T08:44:41.895305Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 38\n",
      "Number of observations used for backtesting: 12\n",
      "    Number of folds: 3\n",
      "    Number of steps per fold: 4\n",
      "\n",
      "Data partition in fold: 0\n",
      "    Training:   0 -- 37\n",
      "    Validation: 38 -- 41\n",
      "Data partition in fold: 1\n",
      "    Training:   0 -- 41\n",
      "    Validation: 42 -- 45\n",
      "Data partition in fold: 2\n",
      "    Training:   0 -- 45\n",
      "    Validation: 46 -- 49\n",
      "\n",
      "[0.06598803]\n",
      "0.06598802629306816\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.55717779, 0.43355138, 0.54969767, 0.52945466, 0.38969292,\n",
       "       0.52778339, 0.49152015, 0.4841678 , 0.4076433 , 0.50904672,\n",
       "       0.50249462, 0.49232817])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mocked backtesting no exog no remainder\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterAutoreg(\n",
    "                regressor = LinearRegression(),\n",
    "                lags      = 3 \n",
    "             )\n",
    "forecaster.fit(y=y)\n",
    "\n",
    "n_backtest = 12\n",
    "y_train = y[:-n_backtest]\n",
    "y_backtest = y[-n_backtest:]\n",
    "\n",
    "metric, backtest_predictions = _backtesting_forecaster_refit(\n",
    "                                    forecaster = forecaster,\n",
    "                                    y          = y,\n",
    "                                    initial_train_size = len(y_train),\n",
    "                                    steps      = 4,\n",
    "                                    metric     = 'mean_squared_error',\n",
    "                                    verbose    = True\n",
    "                               )\n",
    "\n",
    "print(metric)\n",
    "metric_value = get_metric('mean_squared_error')(\n",
    "                    y_true = y.iloc[len(y_train) : len(y_train) + len(backtest_predictions)],\n",
    "                    y_pred = backtest_predictions['pred']\n",
    "                   )\n",
    "print(metric_value)\n",
    "backtest_predictions.pred.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b2d4bf4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T09:06:11.407126Z",
     "start_time": "2022-02-24T09:06:11.385182Z"
    }
   },
   "outputs": [],
   "source": [
    "metric_mocked_no_exog_no_remainder = np.array(0.06598802629306816)\n",
    "assert metric_mocked_no_exog_no_remainder == metric\n",
    "backtest_predictions_mocked_no_exog_no_remainder = pd.DataFrame({'pred':np.array([0.55717779, 0.43355138, 0.54969767,\n",
    "                                                                                  0.52945466, 0.38969292, 0.52778339,\n",
    "                                                                                  0.49152015, 0.4841678 , 0.4076433 ,\n",
    "                                                                                  0.50904672, 0.50249462, 0.49232817])\n",
    "                                                                }, index=np.arange(38, 50))\n",
    "pd.testing.assert_frame_equal(backtest_predictions, backtest_predictions_mocked_no_exog_no_remainder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592b65ea",
   "metadata": {},
   "source": [
    "#### No interval no exog yes remainder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "985ecf0f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T09:08:38.187365Z",
     "start_time": "2022-02-24T09:08:38.138465Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 38\n",
      "Number of observations used for backtesting: 12\n",
      "    Number of folds: 3\n",
      "    Number of steps per fold: 5\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Data partition in fold: 0\n",
      "    Training:   0 -- 37\n",
      "    Validation: 38 -- 42\n",
      "Data partition in fold: 1\n",
      "    Training:   0 -- 42\n",
      "    Validation: 43 -- 47\n",
      "Data partition in fold: 2\n",
      "    Training:   0 -- 47\n",
      "    Validation: 48 -- 49\n",
      "\n",
      "[0.06916732]\n",
      "0.06916732087926723\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.55717779, 0.43355138, 0.54969767, 0.52945466, 0.48308861,\n",
       "       0.5096801 , 0.49519677, 0.47997916, 0.49177914, 0.495797  ,\n",
       "       0.57738724, 0.44370472])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mocked backtesting no exog yes remainder\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterAutoreg(\n",
    "                regressor = LinearRegression(),\n",
    "                lags      = 3 \n",
    "             )\n",
    "forecaster.fit(y=y)\n",
    "\n",
    "n_backtest = 12\n",
    "y_train = y[:-n_backtest]\n",
    "y_backtest = y[-n_backtest:]\n",
    "\n",
    "metric, backtest_predictions = _backtesting_forecaster_refit(\n",
    "                                    forecaster = forecaster,\n",
    "                                    y          = y,\n",
    "                                    initial_train_size = len(y_train),\n",
    "                                    steps      = 5,\n",
    "                                    metric     = 'mean_squared_error',\n",
    "                                    verbose    = True\n",
    "                               )\n",
    "\n",
    "print(metric)\n",
    "metric_value = get_metric('mean_squared_error')(\n",
    "                    y_true = y.iloc[len(y_train) : len(y_train) + len(backtest_predictions)],\n",
    "                    y_pred = backtest_predictions['pred']\n",
    "                   )\n",
    "print(metric_value)\n",
    "backtest_predictions.pred.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12db1c87",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T09:08:40.783432Z",
     "start_time": "2022-02-24T09:08:40.770465Z"
    }
   },
   "outputs": [],
   "source": [
    "metric_mocked_no_exog_yes_remainder = np.array(0.06916732087926723)\n",
    "assert metric_mocked_no_exog_yes_remainder == metric\n",
    "backtest_predictions_mocked_no_exog_yes_remainder = pd.DataFrame({'pred':np.array([0.55717779, 0.43355138, 0.54969767,\n",
    "                                                                                   0.52945466, 0.48308861, 0.5096801 ,\n",
    "                                                                                   0.49519677, 0.47997916, 0.49177914,\n",
    "                                                                                   0.495797  , 0.57738724, 0.44370472])\n",
    "                                                                 }, index=np.arange(38, 50))\n",
    "pd.testing.assert_frame_equal(backtest_predictions, backtest_predictions_mocked_no_exog_yes_remainder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814946fc",
   "metadata": {},
   "source": [
    "#### No interval yes exog no remainder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bd6d7c6c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T09:08:47.873071Z",
     "start_time": "2022-02-24T09:08:47.794282Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 38\n",
      "Number of observations used for backtesting: 12\n",
      "    Number of folds: 3\n",
      "    Number of steps per fold: 4\n",
      "\n",
      "Data partition in fold: 0\n",
      "    Training:   0 -- 37\n",
      "    Validation: 38 -- 41\n",
      "Data partition in fold: 1\n",
      "    Training:   0 -- 41\n",
      "    Validation: 42 -- 45\n",
      "Data partition in fold: 2\n",
      "    Training:   0 -- 45\n",
      "    Validation: 46 -- 49\n",
      "\n",
      "[0.05663345]\n",
      "0.05663345135204598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JESCOBARO\\Anaconda3\\envs\\skforecast\\lib\\site-packages\\skforecast\\utils\\utils.py:344: UserWarning: `exog` has DatetimeIndex index but no frequency. The index is overwritten with a RangeIndex.\n",
      "  ('`exog` has DatetimeIndex index but no frequency. The index is '\n",
      "C:\\Users\\JESCOBARO\\Anaconda3\\envs\\skforecast\\lib\\site-packages\\skforecast\\utils\\utils.py:344: UserWarning: `exog` has DatetimeIndex index but no frequency. The index is overwritten with a RangeIndex.\n",
      "  ('`exog` has DatetimeIndex index but no frequency. The index is '\n",
      "C:\\Users\\JESCOBARO\\Anaconda3\\envs\\skforecast\\lib\\site-packages\\skforecast\\utils\\utils.py:344: UserWarning: `exog` has DatetimeIndex index but no frequency. The index is overwritten with a RangeIndex.\n",
      "  ('`exog` has DatetimeIndex index but no frequency. The index is '\n",
      "C:\\Users\\JESCOBARO\\Anaconda3\\envs\\skforecast\\lib\\site-packages\\skforecast\\utils\\utils.py:344: UserWarning: `exog` has DatetimeIndex index but no frequency. The index is overwritten with a RangeIndex.\n",
      "  ('`exog` has DatetimeIndex index but no frequency. The index is '\n",
      "C:\\Users\\JESCOBARO\\Anaconda3\\envs\\skforecast\\lib\\site-packages\\skforecast\\utils\\utils.py:344: UserWarning: `exog` has DatetimeIndex index but no frequency. The index is overwritten with a RangeIndex.\n",
      "  ('`exog` has DatetimeIndex index but no frequency. The index is '\n",
      "C:\\Users\\JESCOBARO\\Anaconda3\\envs\\skforecast\\lib\\site-packages\\skforecast\\utils\\utils.py:344: UserWarning: `exog` has DatetimeIndex index but no frequency. The index is overwritten with a RangeIndex.\n",
      "  ('`exog` has DatetimeIndex index but no frequency. The index is '\n",
      "C:\\Users\\JESCOBARO\\Anaconda3\\envs\\skforecast\\lib\\site-packages\\skforecast\\utils\\utils.py:344: UserWarning: `exog` has DatetimeIndex index but no frequency. The index is overwritten with a RangeIndex.\n",
      "  ('`exog` has DatetimeIndex index but no frequency. The index is '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.59059622, 0.47257504, 0.53024098, 0.46163343, 0.42295275,\n",
       "       0.46286083, 0.43618422, 0.43552906, 0.48687517, 0.55455072,\n",
       "       0.55577332, 0.53943402])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mocked backtesting yes exog no remainder\n",
    "# ==============================================================================\n",
    "assert len(y) == len(exog)\n",
    "forecaster = ForecasterAutoreg(\n",
    "                regressor = LinearRegression(),\n",
    "                lags      = 3 \n",
    "             )\n",
    "forecaster.fit(y=y, exog=exog)\n",
    "\n",
    "n_backtest = 12\n",
    "y_train = y[:-n_backtest]\n",
    "y_backtest = y[-n_backtest:]\n",
    "\n",
    "metric, backtest_predictions = _backtesting_forecaster_refit(\n",
    "                                    forecaster = forecaster,\n",
    "                                    y          = y,\n",
    "                                    exog       = exog,\n",
    "                                    initial_train_size = len(y_train),\n",
    "                                    steps      = 4,\n",
    "                                    metric     = 'mean_squared_error',\n",
    "                                    verbose    = True\n",
    "                               )\n",
    "\n",
    "print(metric)\n",
    "metric_value = get_metric('mean_squared_error')(\n",
    "                    y_true = y.iloc[len(y_train) : len(y_train) + len(backtest_predictions)],\n",
    "                    y_pred = backtest_predictions['pred']\n",
    "                   )\n",
    "print(metric_value)\n",
    "backtest_predictions.pred.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b6c6c118",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T09:08:54.793124Z",
     "start_time": "2022-02-24T09:08:54.777500Z"
    }
   },
   "outputs": [],
   "source": [
    "metric_mocked_yes_exog_no_remainder = np.array(0.05663345135204598)\n",
    "assert metric_mocked_yes_exog_no_remainder == metric\n",
    "backtest_predictions_mocked_yes_exog_no_remainder = pd.DataFrame({'pred':np.array([0.59059622, 0.47257504, 0.53024098, \n",
    "                                                                                   0.46163343, 0.42295275, 0.46286083,\n",
    "                                                                                   0.43618422, 0.43552906, 0.48687517,\n",
    "                                                                                   0.55455072, 0.55577332, 0.53943402]\n",
    "                                                                                 )\n",
    "                                                                 }, index=np.arange(38, 50))\n",
    "pd.testing.assert_frame_equal(backtest_predictions, backtest_predictions_mocked_yes_exog_no_remainder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b920bacf",
   "metadata": {},
   "source": [
    "#### No interval yes exog yes remainder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "399e2be4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T09:08:59.805300Z",
     "start_time": "2022-02-24T09:08:59.747010Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 38\n",
      "Number of observations used for backtesting: 12\n",
      "    Number of folds: 3\n",
      "    Number of steps per fold: 5\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Data partition in fold: 0\n",
      "    Training:   0 -- 37\n",
      "    Validation: 38 -- 42\n",
      "Data partition in fold: 1\n",
      "    Training:   0 -- 42\n",
      "    Validation: 43 -- 47\n",
      "Data partition in fold: 2\n",
      "    Training:   0 -- 47\n",
      "    Validation: 48 -- 49\n",
      "\n",
      "[0.06172396]\n",
      "0.061723961096013524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JESCOBARO\\Anaconda3\\envs\\skforecast\\lib\\site-packages\\skforecast\\utils\\utils.py:344: UserWarning: `exog` has DatetimeIndex index but no frequency. The index is overwritten with a RangeIndex.\n",
      "  ('`exog` has DatetimeIndex index but no frequency. The index is '\n",
      "C:\\Users\\JESCOBARO\\Anaconda3\\envs\\skforecast\\lib\\site-packages\\skforecast\\utils\\utils.py:344: UserWarning: `exog` has DatetimeIndex index but no frequency. The index is overwritten with a RangeIndex.\n",
      "  ('`exog` has DatetimeIndex index but no frequency. The index is '\n",
      "C:\\Users\\JESCOBARO\\Anaconda3\\envs\\skforecast\\lib\\site-packages\\skforecast\\utils\\utils.py:344: UserWarning: `exog` has DatetimeIndex index but no frequency. The index is overwritten with a RangeIndex.\n",
      "  ('`exog` has DatetimeIndex index but no frequency. The index is '\n",
      "C:\\Users\\JESCOBARO\\Anaconda3\\envs\\skforecast\\lib\\site-packages\\skforecast\\utils\\utils.py:344: UserWarning: `exog` has DatetimeIndex index but no frequency. The index is overwritten with a RangeIndex.\n",
      "  ('`exog` has DatetimeIndex index but no frequency. The index is '\n",
      "C:\\Users\\JESCOBARO\\Anaconda3\\envs\\skforecast\\lib\\site-packages\\skforecast\\utils\\utils.py:344: UserWarning: `exog` has DatetimeIndex index but no frequency. The index is overwritten with a RangeIndex.\n",
      "  ('`exog` has DatetimeIndex index but no frequency. The index is '\n",
      "C:\\Users\\JESCOBARO\\Anaconda3\\envs\\skforecast\\lib\\site-packages\\skforecast\\utils\\utils.py:344: UserWarning: `exog` has DatetimeIndex index but no frequency. The index is overwritten with a RangeIndex.\n",
      "  ('`exog` has DatetimeIndex index but no frequency. The index is '\n",
      "C:\\Users\\JESCOBARO\\Anaconda3\\envs\\skforecast\\lib\\site-packages\\skforecast\\utils\\utils.py:344: UserWarning: `exog` has DatetimeIndex index but no frequency. The index is overwritten with a RangeIndex.\n",
      "  ('`exog` has DatetimeIndex index but no frequency. The index is '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.59059622, 0.47257504, 0.53024098, 0.46163343, 0.50035119,\n",
       "       0.43595809, 0.4349167 , 0.42381237, 0.55165332, 0.53442833,\n",
       "       0.65361802, 0.51297419])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mocked backtesting yes exog no remainder\n",
    "# ==============================================================================\n",
    "assert len(y) == len(exog)\n",
    "forecaster = ForecasterAutoreg(\n",
    "                regressor = LinearRegression(),\n",
    "                lags      = 3 \n",
    "             )\n",
    "forecaster.fit(y=y, exog=exog)\n",
    "\n",
    "n_backtest = 12\n",
    "y_train = y[:-n_backtest]\n",
    "y_backtest = y[-n_backtest:]\n",
    "\n",
    "metric, backtest_predictions = _backtesting_forecaster_refit(\n",
    "                                    forecaster = forecaster,\n",
    "                                    y          = y,\n",
    "                                    exog       = exog,\n",
    "                                    initial_train_size = len(y_train),\n",
    "                                    steps      = 5,\n",
    "                                    metric     = 'mean_squared_error',\n",
    "                                    verbose    = True\n",
    "                               )\n",
    "\n",
    "print(metric)\n",
    "metric_value = get_metric('mean_squared_error')(\n",
    "                    y_true = y.iloc[len(y_train) : len(y_train) + len(backtest_predictions)],\n",
    "                    y_pred = backtest_predictions['pred']\n",
    "                   )\n",
    "print(metric_value)\n",
    "backtest_predictions.pred.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4b091dbb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T09:09:01.562263Z",
     "start_time": "2022-02-24T09:09:01.547334Z"
    }
   },
   "outputs": [],
   "source": [
    "metric_mocked_yes_exog_yes_remainder = np.array(0.061723961096013524)\n",
    "assert metric_mocked_yes_exog_yes_remainder == metric\n",
    "backtest_predictions_mocked_yes_exog_yes_remainder = pd.DataFrame({'pred':np.array([0.59059622, 0.47257504, 0.53024098,\n",
    "                                                                                    0.46163343, 0.50035119, 0.43595809,\n",
    "                                                                                    0.4349167 , 0.42381237, 0.55165332,\n",
    "                                                                                    0.53442833, 0.65361802, 0.51297419]\n",
    "                                                                                  )\n",
    "                                                                 }, index=np.arange(38, 50))\n",
    "pd.testing.assert_frame_equal(backtest_predictions, backtest_predictions_mocked_yes_exog_yes_remainder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d32c32",
   "metadata": {},
   "source": [
    "### Interval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d43426",
   "metadata": {},
   "source": [
    "#### Interval no exog no remainder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e65db2e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T09:51:17.284164Z",
     "start_time": "2022-02-24T09:51:16.234686Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 38\n",
      "Number of observations used for backtesting: 12\n",
      "    Number of folds: 3\n",
      "    Number of steps per fold: 4\n",
      "\n",
      "Data partition in fold: 0\n",
      "    Training:   0 -- 37\n",
      "    Validation: 38 -- 41\n",
      "Data partition in fold: 1\n",
      "    Training:   0 -- 41\n",
      "    Validation: 42 -- 45\n",
      "Data partition in fold: 2\n",
      "    Training:   0 -- 45\n",
      "    Validation: 46 -- 49\n",
      "\n",
      "[0.06598803]\n",
      "0.06598802629306816\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.19882822, 0.08272406, 0.18106389, 0.18777395, 0.03520425,\n",
       "       0.12926384, 0.0495347 , 0.04527341, 0.0113795 , 0.13676538,\n",
       "       0.12478441, 0.06814153])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mocked backtesting interval no exog no remainder\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterAutoreg(\n",
    "                regressor = LinearRegression(),\n",
    "                lags      = 3 \n",
    "             )\n",
    "forecaster.fit(y=y)\n",
    "\n",
    "n_backtest = 12\n",
    "y_train = y[:-n_backtest]\n",
    "y_backtest = y[-n_backtest:]\n",
    "\n",
    "metric, backtest_predictions = _backtesting_forecaster_refit(\n",
    "                                    forecaster = forecaster,\n",
    "                                    y          = y,\n",
    "                                    initial_train_size = len(y_train),\n",
    "                                    steps      = 4,\n",
    "                                    metric     = 'mean_squared_error',\n",
    "                                    interval   = [5, 95],\n",
    "                                    n_boot     = 500,\n",
    "                                    random_state = 123,\n",
    "                                    verbose    = True\n",
    "                               )\n",
    "\n",
    "print(metric)\n",
    "metric_value = get_metric('mean_squared_error')(\n",
    "                    y_true = y.iloc[len(y_train) : len(y_train) + len(backtest_predictions)],\n",
    "                    y_pred = backtest_predictions['pred']\n",
    "                   )\n",
    "print(metric_value)\n",
    "backtest_predictions.pred.values\n",
    "backtest_predictions.lower_bound.values\n",
    "# backtest_predictions.upper_bound.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "eef4cb4e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T09:51:17.441746Z",
     "start_time": "2022-02-24T09:51:17.428779Z"
    }
   },
   "outputs": [],
   "source": [
    "metric_mocked_interval_no_exog_no_remainder = np.array(0.06598802629306816)\n",
    "assert metric_mocked_interval_no_exog_no_remainder == metric\n",
    "\n",
    "backtest_predictions_mocked_interval_no_exog_no_remainder = pd.DataFrame({\n",
    "    'pred':np.array([0.55717779, 0.43355138, 0.54969767, 0.52945466, 0.38969292, 0.52778339, \n",
    "                     0.49152015, 0.4841678, 0.4076433, 0.50904672, 0.50249462, 0.49232817]),\n",
    "    'lower_bound':np.array([0.19882822, 0.08272406, 0.18106389, 0.18777395, 0.03520425, 0.12926384,\n",
    "                            0.0495347 , 0.04527341, 0.0113795 , 0.13676538, 0.12478441, 0.06814153]),\n",
    "    'upper_bound':np.array([0.95368172, 0.81704742, 0.93685716, 0.9407976 , 0.78486946, 0.93084605,\n",
    "                            0.84533191, 0.90255909, 0.80099612, 0.88747244, 0.88292664, 0.88718366])                                                                 \n",
    "                                                                         }, index=np.arange(38, 50))\n",
    "\n",
    "pd.testing.assert_frame_equal(backtest_predictions, backtest_predictions_mocked_interval_no_exog_no_remainder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd796f65",
   "metadata": {},
   "source": [
    "#### Interval no exog yes remainder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cf2786aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T09:51:31.863416Z",
     "start_time": "2022-02-24T09:51:30.761556Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 38\n",
      "Number of observations used for backtesting: 12\n",
      "    Number of folds: 3\n",
      "    Number of steps per fold: 5\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Data partition in fold: 0\n",
      "    Training:   0 -- 37\n",
      "    Validation: 38 -- 42\n",
      "Data partition in fold: 1\n",
      "    Training:   0 -- 42\n",
      "    Validation: 43 -- 47\n",
      "Data partition in fold: 2\n",
      "    Training:   0 -- 47\n",
      "    Validation: 48 -- 49\n",
      "\n",
      "[0.06916732]\n",
      "0.06916732087926723\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.95368172, 0.81704742, 0.93685716, 0.9407976 , 0.85396419,\n",
       "       0.86172991, 0.88313129, 0.82354636, 0.93875053, 0.86176335,\n",
       "       0.96037185, 0.84205069])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mocked backtesting interval no exog no remainder\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterAutoreg(\n",
    "                regressor = LinearRegression(),\n",
    "                lags      = 3 \n",
    "             )\n",
    "forecaster.fit(y=y)\n",
    "\n",
    "n_backtest = 12\n",
    "y_train = y[:-n_backtest]\n",
    "y_backtest = y[-n_backtest:]\n",
    "\n",
    "metric, backtest_predictions = _backtesting_forecaster_refit(\n",
    "                                    forecaster = forecaster,\n",
    "                                    y          = y,\n",
    "                                    initial_train_size = len(y_train),\n",
    "                                    steps      = 5,\n",
    "                                    metric     = 'mean_squared_error',\n",
    "                                    interval   = [5, 95],\n",
    "                                    n_boot     = 500,\n",
    "                                    random_state = 123,\n",
    "                                    verbose    = True\n",
    "                               )\n",
    "\n",
    "print(metric)\n",
    "metric_value = get_metric('mean_squared_error')(\n",
    "                    y_true = y.iloc[len(y_train) : len(y_train) + len(backtest_predictions)],\n",
    "                    y_pred = backtest_predictions['pred']\n",
    "                   )\n",
    "print(metric_value)\n",
    "backtest_predictions.pred.values\n",
    "backtest_predictions.lower_bound.values\n",
    "backtest_predictions.upper_bound.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d31801a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T09:51:32.004991Z",
     "start_time": "2022-02-24T09:51:31.993024Z"
    }
   },
   "outputs": [],
   "source": [
    "metric_mocked_interval_no_exog_yes_remainder = np.array(0.06916732087926723)\n",
    "assert metric_mocked_interval_no_exog_yes_remainder == metric\n",
    "\n",
    "backtest_predictions_mocked_interval_no_exog_yes_remainder = pd.DataFrame({\n",
    "    'pred':np.array([0.55717779, 0.43355138, 0.54969767, 0.52945466, 0.48308861, 0.5096801 , \n",
    "                     0.49519677, 0.47997916, 0.49177914, 0.495797  , 0.57738724, 0.44370472]),\n",
    "    'lower_bound':np.array([0.19882822, 0.08272406, 0.18106389, 0.18777395, 0.1238825 , 0.06681772,\n",
    "                            0.09795868, 0.08383945, 0.10160946, 0.08917676, 0.23321023, 0.08685352]),\n",
    "    'upper_bound':np.array([0.95368172, 0.81704742, 0.93685716, 0.9407976 , 0.85396419, 0.86172991,\n",
    "                            0.88313129, 0.82354636, 0.93875053, 0.86176335, 0.96037185, 0.84205069])                                                                 \n",
    "                                                                }, index=np.arange(38, 50))\n",
    "\n",
    "pd.testing.assert_frame_equal(backtest_predictions, backtest_predictions_mocked_interval_no_exog_yes_remainder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e760ea",
   "metadata": {},
   "source": [
    "#### Interval yes exgo no remainder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "54c40232",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T09:51:38.053167Z",
     "start_time": "2022-02-24T09:51:36.961812Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JESCOBARO\\Anaconda3\\envs\\skforecast\\lib\\site-packages\\skforecast\\utils\\utils.py:344: UserWarning: `exog` has DatetimeIndex index but no frequency. The index is overwritten with a RangeIndex.\n",
      "  ('`exog` has DatetimeIndex index but no frequency. The index is '\n",
      "C:\\Users\\JESCOBARO\\Anaconda3\\envs\\skforecast\\lib\\site-packages\\skforecast\\utils\\utils.py:344: UserWarning: `exog` has DatetimeIndex index but no frequency. The index is overwritten with a RangeIndex.\n",
      "  ('`exog` has DatetimeIndex index but no frequency. The index is '\n",
      "C:\\Users\\JESCOBARO\\Anaconda3\\envs\\skforecast\\lib\\site-packages\\skforecast\\utils\\utils.py:344: UserWarning: `exog` has DatetimeIndex index but no frequency. The index is overwritten with a RangeIndex.\n",
      "  ('`exog` has DatetimeIndex index but no frequency. The index is '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 38\n",
      "Number of observations used for backtesting: 12\n",
      "    Number of folds: 3\n",
      "    Number of steps per fold: 4\n",
      "\n",
      "Data partition in fold: 0\n",
      "    Training:   0 -- 37\n",
      "    Validation: 38 -- 41\n",
      "Data partition in fold: 1\n",
      "    Training:   0 -- 41\n",
      "    Validation: 42 -- 45\n",
      "Data partition in fold: 2\n",
      "    Training:   0 -- 45\n",
      "    Validation: 46 -- 49\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JESCOBARO\\Anaconda3\\envs\\skforecast\\lib\\site-packages\\skforecast\\utils\\utils.py:344: UserWarning: `exog` has DatetimeIndex index but no frequency. The index is overwritten with a RangeIndex.\n",
      "  ('`exog` has DatetimeIndex index but no frequency. The index is '\n",
      "C:\\Users\\JESCOBARO\\Anaconda3\\envs\\skforecast\\lib\\site-packages\\skforecast\\utils\\utils.py:344: UserWarning: `exog` has DatetimeIndex index but no frequency. The index is overwritten with a RangeIndex.\n",
      "  ('`exog` has DatetimeIndex index but no frequency. The index is '\n",
      "C:\\Users\\JESCOBARO\\Anaconda3\\envs\\skforecast\\lib\\site-packages\\skforecast\\utils\\utils.py:344: UserWarning: `exog` has DatetimeIndex index but no frequency. The index is overwritten with a RangeIndex.\n",
      "  ('`exog` has DatetimeIndex index but no frequency. The index is '\n",
      "C:\\Users\\JESCOBARO\\Anaconda3\\envs\\skforecast\\lib\\site-packages\\skforecast\\utils\\utils.py:344: UserWarning: `exog` has DatetimeIndex index but no frequency. The index is overwritten with a RangeIndex.\n",
      "  ('`exog` has DatetimeIndex index but no frequency. The index is '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.05663345]\n",
      "0.05663345135204598\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.95777604, 0.88685543, 0.90755063, 0.87811336, 0.8225198 ,\n",
       "       0.81894689, 0.81179723, 0.84420112, 0.89407425, 0.93903702,\n",
       "       0.91748574, 0.93705358])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mocked backtesting interval yes exog no remainder\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterAutoreg(\n",
    "                regressor = LinearRegression(),\n",
    "                lags      = 3 \n",
    "             )\n",
    "forecaster.fit(y=y, exog=exog)\n",
    "\n",
    "n_backtest = 12\n",
    "y_train = y[:-n_backtest]\n",
    "y_backtest = y[-n_backtest:]\n",
    "\n",
    "metric, backtest_predictions = _backtesting_forecaster_refit(\n",
    "                                    forecaster = forecaster,\n",
    "                                    y          = y,\n",
    "                                    exog       = exog,\n",
    "                                    initial_train_size = len(y_train),\n",
    "                                    steps      = 4,\n",
    "                                    metric     = 'mean_squared_error',\n",
    "                                    interval   = [5, 95],\n",
    "                                    n_boot     = 500,\n",
    "                                    random_state = 123,\n",
    "                                    verbose    = True\n",
    "                               )\n",
    "\n",
    "print(metric)\n",
    "metric_value = get_metric('mean_squared_error')(\n",
    "                    y_true = y.iloc[len(y_train) : len(y_train) + len(backtest_predictions)],\n",
    "                    y_pred = backtest_predictions['pred']\n",
    "                   )\n",
    "print(metric_value)\n",
    "backtest_predictions.pred.values\n",
    "# backtest_predictions.lower_bound.values\n",
    "backtest_predictions.upper_bound.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ff7a7a56",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T09:51:38.213093Z",
     "start_time": "2022-02-24T09:51:38.184171Z"
    }
   },
   "outputs": [],
   "source": [
    "metric_mocked_interval_yes_exog_no_remainder = np.array(0.05663345135204598)\n",
    "assert metric_mocked_interval_yes_exog_no_remainder == metric\n",
    "\n",
    "backtest_predictions_mocked_interval_yes_exog_no_remainder = pd.DataFrame({\n",
    "    'pred':np.array([0.59059622, 0.47257504, 0.53024098, 0.46163343, 0.42295275, 0.46286083,\n",
    "                     0.43618422, 0.43552906, 0.48687517, 0.55455072, 0.55577332, 0.53943402]),\n",
    "    'lower_bound':np.array([0.24619375, 0.10545295, 0.13120713, 0.08044217, 0.07440334, 0.11331854,\n",
    "                            0.01436362, 0.02747413, 0.14867238, 0.19834047, 0.19884259, 0.16964474]),\n",
    "    'upper_bound':np.array([0.95777604, 0.88685543, 0.90755063, 0.87811336, 0.8225198 , 0.81894689,\n",
    "                            0.81179723, 0.84420112, 0.89407425, 0.93903702, 0.91748574, 0.93705358])                                                                 \n",
    "                                                                         }, index=np.arange(38, 50))\n",
    "\n",
    "pd.testing.assert_frame_equal(backtest_predictions, backtest_predictions_mocked_interval_yes_exog_no_remainder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2942a07",
   "metadata": {},
   "source": [
    "#### Interval yes exog yes remainder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fe7127ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T09:51:44.592799Z",
     "start_time": "2022-02-24T09:51:43.403575Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JESCOBARO\\Anaconda3\\envs\\skforecast\\lib\\site-packages\\skforecast\\utils\\utils.py:344: UserWarning: `exog` has DatetimeIndex index but no frequency. The index is overwritten with a RangeIndex.\n",
      "  ('`exog` has DatetimeIndex index but no frequency. The index is '\n",
      "C:\\Users\\JESCOBARO\\Anaconda3\\envs\\skforecast\\lib\\site-packages\\skforecast\\utils\\utils.py:344: UserWarning: `exog` has DatetimeIndex index but no frequency. The index is overwritten with a RangeIndex.\n",
      "  ('`exog` has DatetimeIndex index but no frequency. The index is '\n",
      "C:\\Users\\JESCOBARO\\Anaconda3\\envs\\skforecast\\lib\\site-packages\\skforecast\\utils\\utils.py:344: UserWarning: `exog` has DatetimeIndex index but no frequency. The index is overwritten with a RangeIndex.\n",
      "  ('`exog` has DatetimeIndex index but no frequency. The index is '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 38\n",
      "Number of observations used for backtesting: 12\n",
      "    Number of folds: 3\n",
      "    Number of steps per fold: 5\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Data partition in fold: 0\n",
      "    Training:   0 -- 37\n",
      "    Validation: 38 -- 42\n",
      "Data partition in fold: 1\n",
      "    Training:   0 -- 42\n",
      "    Validation: 43 -- 47\n",
      "Data partition in fold: 2\n",
      "    Training:   0 -- 47\n",
      "    Validation: 48 -- 49\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JESCOBARO\\Anaconda3\\envs\\skforecast\\lib\\site-packages\\skforecast\\utils\\utils.py:344: UserWarning: `exog` has DatetimeIndex index but no frequency. The index is overwritten with a RangeIndex.\n",
      "  ('`exog` has DatetimeIndex index but no frequency. The index is '\n",
      "C:\\Users\\JESCOBARO\\Anaconda3\\envs\\skforecast\\lib\\site-packages\\skforecast\\utils\\utils.py:344: UserWarning: `exog` has DatetimeIndex index but no frequency. The index is overwritten with a RangeIndex.\n",
      "  ('`exog` has DatetimeIndex index but no frequency. The index is '\n",
      "C:\\Users\\JESCOBARO\\Anaconda3\\envs\\skforecast\\lib\\site-packages\\skforecast\\utils\\utils.py:344: UserWarning: `exog` has DatetimeIndex index but no frequency. The index is overwritten with a RangeIndex.\n",
      "  ('`exog` has DatetimeIndex index but no frequency. The index is '\n",
      "C:\\Users\\JESCOBARO\\Anaconda3\\envs\\skforecast\\lib\\site-packages\\skforecast\\utils\\utils.py:344: UserWarning: `exog` has DatetimeIndex index but no frequency. The index is overwritten with a RangeIndex.\n",
      "  ('`exog` has DatetimeIndex index but no frequency. The index is '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.06172396]\n",
      "0.061723961096013524\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.95777604, 0.88685543, 0.90755063, 0.87811336, 0.86891022,\n",
       "       0.74808834, 0.80296989, 0.77919033, 0.97680126, 0.8877086 ,\n",
       "       1.07608747, 0.90555785])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mocked backtesting interval yes exog yes remainder\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterAutoreg(\n",
    "                regressor = LinearRegression(),\n",
    "                lags      = 3 \n",
    "             )\n",
    "forecaster.fit(y=y, exog=exog)\n",
    "\n",
    "n_backtest = 12\n",
    "y_train = y[:-n_backtest]\n",
    "y_backtest = y[-n_backtest:]\n",
    "\n",
    "metric, backtest_predictions = _backtesting_forecaster_refit(\n",
    "                                    forecaster = forecaster,\n",
    "                                    y          = y,\n",
    "                                    exog       = exog,\n",
    "                                    initial_train_size = len(y_train),\n",
    "                                    steps      = 5,\n",
    "                                    metric     = 'mean_squared_error',\n",
    "                                    interval   = [5, 95],\n",
    "                                    n_boot     = 500,\n",
    "                                    random_state = 123,\n",
    "                                    verbose    = True\n",
    "                               )\n",
    "\n",
    "print(metric)\n",
    "metric_value = get_metric('mean_squared_error')(\n",
    "                    y_true = y.iloc[len(y_train) : len(y_train) + len(backtest_predictions)],\n",
    "                    y_pred = backtest_predictions['pred']\n",
    "                   )\n",
    "print(metric_value)\n",
    "backtest_predictions.pred.values\n",
    "backtest_predictions.lower_bound.values\n",
    "backtest_predictions.upper_bound.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4371b58b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T09:51:44.766336Z",
     "start_time": "2022-02-24T09:51:44.737415Z"
    }
   },
   "outputs": [],
   "source": [
    "metric_mocked_interval_yes_exog_yes_remainder = np.array(0.061723961096013524)\n",
    "assert metric_mocked_interval_yes_exog_yes_remainder == metric\n",
    "\n",
    "backtest_predictions_mocked_interval_yes_exog_yes_remainder = pd.DataFrame({\n",
    "    'pred':np.array([0.59059622, 0.47257504, 0.53024098, 0.46163343, 0.50035119, 0.43595809,\n",
    "                     0.4349167 , 0.42381237, 0.55165332, 0.53442833, 0.65361802, 0.51297419]),\n",
    "    'lower_bound':np.array([0.24619375, 0.10545295, 0.13120713, 0.08044217, 0.13725077, 0.08041239,\n",
    "                            0.05015513, 0.07677812, 0.17434611, 0.16051962, 0.29167326, 0.15775686]),\n",
    "    'upper_bound':np.array([0.95777604, 0.88685543, 0.90755063, 0.87811336, 0.86891022, 0.74808834,\n",
    "                            0.80296989, 0.77919033, 0.97680126, 0.8877086 , 1.07608747, 0.90555785])                                                                 \n",
    "                                                                         }, index=np.arange(38, 50))\n",
    "\n",
    "pd.testing.assert_frame_equal(backtest_predictions, backtest_predictions_mocked_interval_yes_exog_yes_remainder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06005b6d",
   "metadata": {},
   "source": [
    "### Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195c6f96",
   "metadata": {},
   "source": [
    "####  No interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "51aea1e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T09:18:04.425370Z",
     "start_time": "2022-02-25T09:18:04.397835Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fixtures _backtesting_forecaster_refit No exog No remainder (skforecast==0.4.2)\n",
    "# ==============================================================================\n",
    "metric_mocked_no_exog_no_remainder = 0.06598802629306816\n",
    "backtest_predictions_mocked_no_exog_no_remainder = pd.DataFrame({\n",
    "    'pred':np.array([0.55717779, 0.43355138, 0.54969767, 0.52945466, 0.38969292, 0.52778339,\n",
    "                     0.49152015, 0.4841678 , 0.4076433 , 0.50904672, 0.50249462, 0.49232817])\n",
    "                                                                }, index=np.arange(38, 50))\n",
    "\n",
    "# Fixtures _backtesting_forecaster_refit No exog Yes remainder (skforecast==0.4.2)\n",
    "# ==============================================================================\n",
    "metric_mocked_no_exog_yes_remainder = 0.06916732087926723\n",
    "backtest_predictions_mocked_no_exog_yes_remainder = pd.DataFrame({\n",
    "    'pred':np.array([0.55717779, 0.43355138, 0.54969767, 0.52945466, 0.48308861, 0.5096801 ,\n",
    "                    0.49519677, 0.47997916, 0.49177914, 0.495797  , 0.57738724, 0.44370472])\n",
    "                                                                 }, index=np.arange(38, 50))\n",
    "\n",
    "# Fixtures _backtesting_forecaster_refit Yes exog No remainder (skforecast==0.4.2)\n",
    "# ==============================================================================\n",
    "metric_mocked_yes_exog_no_remainder = 0.05663345135204598\n",
    "backtest_predictions_mocked_yes_exog_no_remainder = pd.DataFrame({\n",
    "    'pred':np.array([0.59059622, 0.47257504, 0.53024098, 0.46163343, 0.42295275, 0.46286083,\n",
    "                     0.43618422, 0.43552906, 0.48687517, 0.55455072, 0.55577332, 0.53943402])\n",
    "                                                                 }, index=np.arange(38, 50))\n",
    "\n",
    "# Fixtures _backtesting_forecaster_refit Yes exog Yes remainder (skforecast==0.4.2)\n",
    "# ==============================================================================\n",
    "metric_mocked_yes_exog_yes_remainder = 0.061723961096013524\n",
    "backtest_predictions_mocked_yes_exog_yes_remainder = pd.DataFrame({\n",
    "    'pred':np.array([0.59059622, 0.47257504, 0.53024098, 0.46163343, 0.50035119, 0.43595809,\n",
    "                     0.4349167 , 0.42381237, 0.55165332, 0.53442833, 0.65361802, 0.51297419])\n",
    "                                                                 }, index=np.arange(38, 50))\n",
    "\n",
    "\n",
    "def test_output_backtesting_forecaster_refit_no_exog_no_remainder_with_mocked():\n",
    "    '''\n",
    "    Test output of _backtesting_forecaster_refit with backtesting mocked, interval no.\n",
    "    Regressor is LinearRegression with lags=3, Series y is mocked, no exog, \n",
    "    12 observations to backtest, steps=4 (no remainder), metric='mean_squared_error'\n",
    "    '''\n",
    "    forecaster = ForecasterAutoreg(regressor=LinearRegression(), lags=3)\n",
    "\n",
    "    n_backtest = 12\n",
    "    y_train = y[:-n_backtest]\n",
    "\n",
    "    metric, backtest_predictions = _backtesting_forecaster_refit(\n",
    "                                        forecaster          = forecaster,\n",
    "                                        y                   = y,\n",
    "                                        exog                = None,\n",
    "                                        initial_train_size  = len(y_train),\n",
    "                                        steps               = 4,\n",
    "                                        metric              = 'mean_squared_error',\n",
    "                                        interval            = None,\n",
    "                                        n_boot              = 500,\n",
    "                                        random_state        = 123,\n",
    "                                        in_sample_residuals = True,\n",
    "                                        verbose             = False\n",
    "                                   )\n",
    "    expected_metric = metric_mocked_no_exog_no_remainder\n",
    "    expected_backtest_predictions = backtest_predictions_mocked_no_exog_no_remainder\n",
    "    assert expected_metric == approx(metric)\n",
    "    pd.testing.assert_frame_equal(expected_backtest_predictions, backtest_predictions)\n",
    "\n",
    "\n",
    "def test_output_backtesting_forecaster_refit_no_exog_yes_remainder_with_mocked():\n",
    "    '''\n",
    "    Test output of _backtesting_forecaster_refit with backtesting mocked, interval no.\n",
    "    Regressor is LinearRegression with lags=3, Series y is mocked, no exog, \n",
    "    12 observations to backtest, steps=5 (2 remainder), metric='mean_squared_error'\n",
    "    '''\n",
    "    forecaster = ForecasterAutoreg(regressor=LinearRegression(), lags=3)\n",
    "\n",
    "    n_backtest = 12\n",
    "    y_train = y[:-n_backtest]\n",
    "\n",
    "    metric, backtest_predictions = _backtesting_forecaster_refit(\n",
    "                                        forecaster          = forecaster,\n",
    "                                        y                   = y,\n",
    "                                        exog                = None,\n",
    "                                        initial_train_size  = len(y_train),\n",
    "                                        steps               = 5,\n",
    "                                        metric              = 'mean_squared_error',\n",
    "                                        interval            = None,\n",
    "                                        n_boot              = 500,\n",
    "                                        random_state        = 123,\n",
    "                                        in_sample_residuals = True,\n",
    "                                        verbose             = False\n",
    "                                   )\n",
    "    expected_metric = metric_mocked_no_exog_yes_remainder\n",
    "    expected_backtest_predictions = backtest_predictions_mocked_no_exog_yes_remainder\n",
    "    assert expected_metric == approx(metric)\n",
    "    pd.testing.assert_frame_equal(expected_backtest_predictions, backtest_predictions)\n",
    "\n",
    "\n",
    "def test_output_backtesting_forecaster_refit_yes_exog_no_remainder_with_mocked():\n",
    "    '''\n",
    "    Test output of _backtesting_forecaster_refit with backtesting mocked, interval no.\n",
    "    Regressor is LinearRegression with lags=3, Series y is mocked, exog is mocked, \n",
    "    12 observations to backtest, steps=4 (no remainder), metric='mean_squared_error'\n",
    "    '''\n",
    "    forecaster = ForecasterAutoreg(regressor=LinearRegression(), lags=3)\n",
    "\n",
    "    n_backtest = 12\n",
    "    y_train = y[:-n_backtest]\n",
    "\n",
    "    metric, backtest_predictions = _backtesting_forecaster_refit(\n",
    "                                        forecaster          = forecaster,\n",
    "                                        y                   = y,\n",
    "                                        exog                = exog,\n",
    "                                        initial_train_size  = len(y_train),\n",
    "                                        steps               = 4,\n",
    "                                        metric              = 'mean_squared_error',\n",
    "                                        interval            = None,\n",
    "                                        n_boot              = 500,\n",
    "                                        random_state        = 123,\n",
    "                                        in_sample_residuals = True,\n",
    "                                        verbose             = False\n",
    "                                   )\n",
    "    expected_metric = metric_mocked_yes_exog_no_remainder\n",
    "    expected_backtest_predictions = backtest_predictions_mocked_yes_exog_no_remainder\n",
    "    assert expected_metric == approx(metric)\n",
    "    pd.testing.assert_frame_equal(expected_backtest_predictions, backtest_predictions)\n",
    "\n",
    "\n",
    "def test_output_backtesting_forecaster_refit_yes_exog_yes_remainder_with_mocked():\n",
    "    '''\n",
    "    Test output of _backtesting_forecaster_refit with backtesting mocked, interval no.\n",
    "    Regressor is LinearRegression with lags=3, Series y is mocked, exog is mocked, \n",
    "    12 observations to backtest, steps=5 (2 remainder), metric='mean_squared_error'\n",
    "    '''\n",
    "    forecaster = ForecasterAutoreg(regressor=LinearRegression(), lags=3)\n",
    "\n",
    "    n_backtest = 12\n",
    "    y_train = y[:-n_backtest]\n",
    "\n",
    "    metric, backtest_predictions = _backtesting_forecaster_refit(\n",
    "                                        forecaster          = forecaster,\n",
    "                                        y                   = y,\n",
    "                                        exog                = exog,\n",
    "                                        initial_train_size  = len(y_train),\n",
    "                                        steps               = 5,\n",
    "                                        metric              = 'mean_squared_error',\n",
    "                                        interval            = None,\n",
    "                                        n_boot              = 500,\n",
    "                                        random_state        = 123,\n",
    "                                        in_sample_residuals = True,\n",
    "                                        verbose             = False\n",
    "                                   )\n",
    "    expected_metric = metric_mocked_yes_exog_yes_remainder\n",
    "    expected_backtest_predictions = backtest_predictions_mocked_yes_exog_yes_remainder\n",
    "    assert expected_metric == approx(metric)\n",
    "    pd.testing.assert_frame_equal(expected_backtest_predictions, backtest_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "897503b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T09:18:06.681302Z",
     "start_time": "2022-02-25T09:18:06.589516Z"
    }
   },
   "outputs": [],
   "source": [
    "test_output_backtesting_forecaster_refit_no_exog_no_remainder_with_mocked()\n",
    "test_output_backtesting_forecaster_refit_no_exog_yes_remainder_with_mocked()\n",
    "test_output_backtesting_forecaster_refit_yes_exog_no_remainder_with_mocked()\n",
    "test_output_backtesting_forecaster_refit_yes_exog_yes_remainder_with_mocked()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c31075",
   "metadata": {},
   "source": [
    "#### Interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ad78b3e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T09:18:35.642957Z",
     "start_time": "2022-02-25T09:18:35.609435Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fixtures _backtesting_forecaster_refit Interval No exog No remainder (skforecast==0.4.2)\n",
    "# ==============================================================================\n",
    "metric_mocked_interval_no_exog_no_remainder = 0.0659880262930681\n",
    "backtest_predictions_mocked_interval_no_exog_no_remainder = pd.DataFrame({\n",
    "    'pred':np.array([0.55717779, 0.43355138, 0.54969767, 0.52945466, 0.38969292, 0.52778339, \n",
    "                     0.49152015, 0.4841678, 0.4076433, 0.50904672, 0.50249462, 0.49232817]),\n",
    "    'lower_bound':np.array([0.19882822, 0.08272406, 0.18106389, 0.18777395, 0.03520425, 0.12926384,\n",
    "                            0.0495347 , 0.04527341, 0.0113795 , 0.13676538, 0.12478441, 0.06814153]),\n",
    "    'upper_bound':np.array([0.95368172, 0.81704742, 0.93685716, 0.9407976 , 0.78486946, 0.93084605,\n",
    "                            0.84533191, 0.90255909, 0.80099612, 0.88747244, 0.88292664, 0.88718366])                                                                 \n",
    "                                                                         }, index=np.arange(38, 50))\n",
    "\n",
    "# Fixtures _backtesting_forecaster_refit Interval No exog Yes remainder (skforecast==0.4.2)\n",
    "# ==============================================================================\n",
    "metric_mocked_interval_no_exog_yes_remainder = 0.06916732087926723\n",
    "backtest_predictions_mocked_interval_no_exog_yes_remainder = pd.DataFrame({\n",
    "    'pred':np.array([0.55717779, 0.43355138, 0.54969767, 0.52945466, 0.48308861, 0.5096801 , \n",
    "                     0.49519677, 0.47997916, 0.49177914, 0.495797  , 0.57738724, 0.44370472]),\n",
    "    'lower_bound':np.array([0.19882822, 0.08272406, 0.18106389, 0.18777395, 0.1238825 , 0.06681772,\n",
    "                            0.09795868, 0.08383945, 0.10160946, 0.08917676, 0.23321023, 0.08685352]),\n",
    "    'upper_bound':np.array([0.95368172, 0.81704742, 0.93685716, 0.9407976 , 0.85396419, 0.86172991,\n",
    "                            0.88313129, 0.82354636, 0.93875053, 0.86176335, 0.96037185, 0.84205069])                                                                 \n",
    "                                                                }, index=np.arange(38, 50))\n",
    "\n",
    "# Fixtures _backtesting_forecaster_refit Interval Yes exog No remainder (skforecast==0.4.2)\n",
    "# ==============================================================================\n",
    "metric_mocked_interval_yes_exog_no_remainder = 0.05663345135204598\n",
    "backtest_predictions_mocked_interval_yes_exog_no_remainder = pd.DataFrame({\n",
    "    'pred':np.array([0.59059622, 0.47257504, 0.53024098, 0.46163343, 0.42295275, 0.46286083,\n",
    "                     0.43618422, 0.43552906, 0.48687517, 0.55455072, 0.55577332, 0.53943402]),\n",
    "    'lower_bound':np.array([0.24619375, 0.10545295, 0.13120713, 0.08044217, 0.07440334, 0.11331854,\n",
    "                            0.01436362, 0.02747413, 0.14867238, 0.19834047, 0.19884259, 0.16964474]),\n",
    "    'upper_bound':np.array([0.95777604, 0.88685543, 0.90755063, 0.87811336, 0.8225198 , 0.81894689,\n",
    "                            0.81179723, 0.84420112, 0.89407425, 0.93903702, 0.91748574, 0.93705358])                                                                 \n",
    "                                                                         }, index=np.arange(38, 50))\n",
    "\n",
    "# Fixtures _backtesting_forecaster_refit Interval Yes exog Yes remainder (skforecast==0.4.2)\n",
    "# ==============================================================================\n",
    "metric_mocked_interval_yes_exog_yes_remainder = 0.061723961096013524\n",
    "backtest_predictions_mocked_interval_yes_exog_yes_remainder = pd.DataFrame({\n",
    "    'pred':np.array([0.59059622, 0.47257504, 0.53024098, 0.46163343, 0.50035119, 0.43595809,\n",
    "                     0.4349167 , 0.42381237, 0.55165332, 0.53442833, 0.65361802, 0.51297419]),\n",
    "    'lower_bound':np.array([0.24619375, 0.10545295, 0.13120713, 0.08044217, 0.13725077, 0.08041239,\n",
    "                            0.05015513, 0.07677812, 0.17434611, 0.16051962, 0.29167326, 0.15775686]),\n",
    "    'upper_bound':np.array([0.95777604, 0.88685543, 0.90755063, 0.87811336, 0.86891022, 0.74808834,\n",
    "                            0.80296989, 0.77919033, 0.97680126, 0.8877086 , 1.07608747, 0.90555785])                                                                 \n",
    "                                                                         }, index=np.arange(38, 50))\n",
    "\n",
    "\n",
    "def test_output_backtesting_forecaster_refit_interval_no_exog_no_remainder_with_mocked():\n",
    "    '''\n",
    "    Test output of _backtesting_forecaster_refit with backtesting mocked, interval yes.\n",
    "    Regressor is LinearRegression with lags=3, Series y is mocked, no exog, \n",
    "    12 observations to backtest, steps=4 (no remainder), metric='mean_squared_error',\n",
    "    'in_sample_residuals = True'\n",
    "    '''\n",
    "    forecaster = ForecasterAutoreg(regressor=LinearRegression(), lags=3)\n",
    "\n",
    "    n_backtest = 12\n",
    "    y_train = y[:-n_backtest]\n",
    "\n",
    "    metric, backtest_predictions = _backtesting_forecaster_refit(\n",
    "                                        forecaster          = forecaster,\n",
    "                                        y                   = y,\n",
    "                                        exog                = None,\n",
    "                                        initial_train_size  = len(y_train),\n",
    "                                        steps               = 4,\n",
    "                                        metric              = 'mean_squared_error',\n",
    "                                        interval            = [5, 95],\n",
    "                                        n_boot              = 500,\n",
    "                                        random_state        = 123,\n",
    "                                        in_sample_residuals = True,\n",
    "                                        verbose             = False\n",
    "                                   ) \n",
    "    expected_metric = metric_mocked_interval_no_exog_no_remainder\n",
    "    expected_backtest_predictions = backtest_predictions_mocked_interval_no_exog_no_remainder\n",
    "    assert expected_metric == approx(metric)\n",
    "    pd.testing.assert_frame_equal(expected_backtest_predictions, backtest_predictions)\n",
    "\n",
    "\n",
    "def test_output_backtesting_forecaster_refit_interval_no_exog_yes_remainder_with_mocked():\n",
    "    '''\n",
    "    Test output of _backtesting_forecaster_refit with backtesting mocked, interval yes. \n",
    "    Regressor is LinearRegression with lags=3, Series y is mocked, no exog, \n",
    "    12 observations to backtest, steps=5 (2 remainder), metric='mean_squared_error',\n",
    "    'in_sample_residuals = True'\n",
    "    '''\n",
    "    forecaster = ForecasterAutoreg(regressor=LinearRegression(), lags=3)\n",
    "\n",
    "    n_backtest = 12\n",
    "    y_train = y[:-n_backtest]\n",
    "\n",
    "    metric, backtest_predictions = _backtesting_forecaster_refit(\n",
    "                                        forecaster          = forecaster,\n",
    "                                        y                   = y,\n",
    "                                        exog                = None,\n",
    "                                        initial_train_size  = len(y_train),\n",
    "                                        steps               = 5,\n",
    "                                        metric              = 'mean_squared_error',\n",
    "                                        interval            = [5, 95],\n",
    "                                        n_boot              = 500,\n",
    "                                        random_state        = 123,\n",
    "                                        in_sample_residuals = True,\n",
    "                                        verbose             = False\n",
    "    )\n",
    "    expected_metric = metric_mocked_interval_no_exog_yes_remainder\n",
    "    expected_backtest_predictions = backtest_predictions_mocked_interval_no_exog_yes_remainder\n",
    "    assert expected_metric == approx(metric)\n",
    "    pd.testing.assert_frame_equal(expected_backtest_predictions, backtest_predictions)\n",
    "\n",
    "\n",
    "def test_output_backtesting_forecaster_refit_interval_yes_exog_no_remainder_with_mocked():\n",
    "    '''\n",
    "    Test output of _backtesting_forecaster_refit with backtesting mocked, interval yes.\n",
    "    Regressor is LinearRegression with lags=3, Series y is mocked, exog is mocked, \n",
    "    12 observations to backtest, steps=4 (no remainder), metric='mean_squared_error',\n",
    "    'in_sample_residuals = True'\n",
    "    '''\n",
    "    forecaster = ForecasterAutoreg(regressor=LinearRegression(), lags=3)\n",
    "\n",
    "    n_backtest = 12\n",
    "    y_train = y[:-n_backtest]\n",
    "\n",
    "    metric, backtest_predictions = _backtesting_forecaster_refit(\n",
    "                                        forecaster          = forecaster,\n",
    "                                        y                   = y,\n",
    "                                        exog                = exog,\n",
    "                                        initial_train_size  = len(y_train),\n",
    "                                        steps               = 4,\n",
    "                                        metric              = 'mean_squared_error',\n",
    "                                        interval            = [5, 95],\n",
    "                                        n_boot              = 500,\n",
    "                                        random_state        = 123,\n",
    "                                        in_sample_residuals = True,\n",
    "                                        verbose             = False\n",
    "                                   )\n",
    "    expected_metric = metric_mocked_interval_yes_exog_no_remainder\n",
    "    expected_backtest_predictions = backtest_predictions_mocked_interval_yes_exog_no_remainder\n",
    "    assert expected_metric == approx(metric)\n",
    "    pd.testing.assert_frame_equal(expected_backtest_predictions, backtest_predictions)\n",
    "\n",
    "\n",
    "def test_output_backtesting_forecaster_refit_interval_yes_exog_yes_remainder_with_mocked():\n",
    "    '''\n",
    "    Test output of _backtesting_forecaster_refit with backtesting mocked, interval yes. \n",
    "    Regressor is LinearRegression with lags=3, Series y is mocked, exog is mocked, \n",
    "    12 observations to backtest, steps=5 (2 remainder), metric='mean_squared_error',\n",
    "    'in_sample_residuals = True'\n",
    "    '''\n",
    "    forecaster = ForecasterAutoreg(regressor=LinearRegression(), lags=3)\n",
    "\n",
    "    n_backtest = 12\n",
    "    y_train = y[:-n_backtest]\n",
    "\n",
    "    metric, backtest_predictions = _backtesting_forecaster_refit(\n",
    "                                        forecaster          = forecaster,\n",
    "                                        y                   = y,\n",
    "                                        exog                = exog,\n",
    "                                        initial_train_size  = len(y_train),\n",
    "                                        steps               = 5,\n",
    "                                        metric              = 'mean_squared_error',\n",
    "                                        interval            = [5, 95],\n",
    "                                        n_boot              = 500,\n",
    "                                        random_state        = 123,\n",
    "                                        in_sample_residuals = True,\n",
    "                                        verbose             = False\n",
    "                                   )\n",
    "    expected_metric = metric_mocked_interval_yes_exog_yes_remainder\n",
    "    expected_backtest_predictions = backtest_predictions_mocked_interval_yes_exog_yes_remainder\n",
    "    assert expected_metric == approx(metric)\n",
    "    pd.testing.assert_frame_equal(expected_backtest_predictions, backtest_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cedea31d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T09:18:39.758118Z",
     "start_time": "2022-02-25T09:18:36.404599Z"
    }
   },
   "outputs": [],
   "source": [
    "test_output_backtesting_forecaster_refit_interval_no_exog_no_remainder_with_mocked()\n",
    "test_output_backtesting_forecaster_refit_interval_no_exog_yes_remainder_with_mocked()\n",
    "test_output_backtesting_forecaster_refit_interval_yes_exog_no_remainder_with_mocked()\n",
    "test_output_backtesting_forecaster_refit_interval_yes_exog_yes_remainder_with_mocked()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f349ff3",
   "metadata": {},
   "source": [
    "#### Interval in_sample_residuals = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2dcbebde",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T15:24:50.761270Z",
     "start_time": "2022-02-25T15:24:50.736296Z"
    }
   },
   "outputs": [],
   "source": [
    "forecaster = ForecasterAutoreg(\n",
    "                regressor = LinearRegression(),\n",
    "                lags      = 3\n",
    "             )\n",
    "forecaster.fit(y=y)\n",
    "forecaster.set_out_sample_residuals(residuals=out_sample_residuals, append=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6d9e282b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T15:24:51.163312Z",
     "start_time": "2022-02-25T15:24:51.143479Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.513128\n",
       "1    0.666625\n",
       "Name: out_sample_residuals, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecaster.out_sample_residuals.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7ad3a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1268b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a044a634",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff94cec9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T15:26:17.178228Z",
     "start_time": "2022-02-25T15:26:16.249975Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06598802629306816\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.55717779, 0.43355138, 0.54969767, 0.52945466, 0.38969292,\n",
       "       0.52778339, 0.49152015, 0.4841678 , 0.4076433 , 0.50904672,\n",
       "       0.50249462, 0.49232817])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0.63654358, 0.62989756, 0.67156167, 0.70363265, 0.46905871,\n",
       "       0.73507276, 0.64554988, 0.64183541, 0.48700909, 0.68845988,\n",
       "       0.63865297, 0.60684242])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([1.54070487, 1.5131313 , 1.56749058, 1.62564968, 1.37322   ,\n",
       "       1.61930035, 1.54870568, 1.55335041, 1.39117037, 1.56935123,\n",
       "       1.51973211, 1.50300901])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Mocked backtesting interval no exog no remainder out_sample_residuals\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterAutoreg(\n",
    "                regressor = LinearRegression(),\n",
    "                lags      = 3\n",
    "             )\n",
    "forecaster.fit(y=y)\n",
    "forecaster.set_out_sample_residuals(residuals=out_sample_residuals, append=False)\n",
    "\n",
    "n_backtest = 12\n",
    "y_train = y[:-n_backtest]\n",
    "y_backtest = y[-n_backtest:]\n",
    "\n",
    "metric, backtest_predictions = _backtesting_forecaster_refit(\n",
    "                                        forecaster          = forecaster,\n",
    "                                        y                   = y,\n",
    "                                        exog                = None,\n",
    "                                        initial_train_size  = len(y_train),\n",
    "                                        steps               = 4,\n",
    "                                        metric              = 'mean_squared_error',\n",
    "                                        interval            = [5, 95],\n",
    "                                        n_boot              = 500,\n",
    "                                        random_state        = 123,\n",
    "                                        in_sample_residuals = False,\n",
    "                                        verbose             = False\n",
    "                                   )\n",
    "\n",
    "metric = _get_metric('mean_squared_error')(\n",
    "                    y_true = y.iloc[len(y_train) : len(y_train) + len(backtest_predictions)],\n",
    "                    y_pred = backtest_predictions['pred']\n",
    "                   )\n",
    "print(metric)\n",
    "display(backtest_predictions.pred.values)\n",
    "display(backtest_predictions.lower_bound.values)\n",
    "display(backtest_predictions.upper_bound.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1ff10d48",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T15:29:26.672876Z",
     "start_time": "2022-02-25T15:29:26.651074Z"
    }
   },
   "outputs": [],
   "source": [
    "metric_mocked_interval_out_sample_residuals_no_exog_no_remainder = 0.06598802629306816\n",
    "assert metric_mocked_interval_out_sample_residuals_no_exog_no_remainder == metric\n",
    "\n",
    "backtest_predictions_mocked_interval_out_sample_residuals_no_exog_no_remainder = pd.DataFrame({\n",
    "    'pred':np.array([0.55717779, 0.43355138, 0.54969767, 0.52945466, 0.38969292, 0.52778339, \n",
    "                     0.49152015, 0.4841678 , 0.4076433 , 0.50904672, 0.50249462, 0.49232817]),\n",
    "    'lower_bound':np.array([0.63654358, 0.62989756, 0.67156167, 0.70363265, 0.46905871, 0.73507276, \n",
    "                            0.64554988, 0.64183541, 0.48700909, 0.68845988, 0.63865297, 0.60684242]),\n",
    "    'upper_bound':np.array([1.54070487, 1.5131313 , 1.56749058, 1.62564968, 1.37322   , 1.61930035, \n",
    "                            1.54870568, 1.55335041, 1.39117037, 1.56935123, 1.51973211, 1.50300901])                                                                \n",
    "                                                                         }, index=np.arange(38, 50))\n",
    "\n",
    "pd.testing.assert_frame_equal(backtest_predictions, backtest_predictions_mocked_interval_out_sample_residuals_no_exog_no_remainder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5693f7d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T15:30:46.325183Z",
     "start_time": "2022-02-25T15:30:46.304445Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fixtures _backtesting_forecaster_refit No exog No remainder (skforecast==0.4.2)\n",
    "# ==============================================================================\n",
    "metric_mocked_interval_out_sample_residuals_no_exog_no_remainder = 0.06598802629306816\n",
    "backtest_predictions_mocked_interval_out_sample_residuals_no_exog_no_remainder = pd.DataFrame({\n",
    "    'pred':np.array([0.55717779, 0.43355138, 0.54969767, 0.52945466, 0.38969292, 0.52778339, \n",
    "                     0.49152015, 0.4841678 , 0.4076433 , 0.50904672, 0.50249462, 0.49232817]),\n",
    "    'lower_bound':np.array([0.63654358, 0.62989756, 0.67156167, 0.70363265, 0.46905871, 0.73507276, \n",
    "                            0.64554988, 0.64183541, 0.48700909, 0.68845988, 0.63865297, 0.60684242]),\n",
    "    'upper_bound':np.array([1.54070487, 1.5131313 , 1.56749058, 1.62564968, 1.37322   , 1.61930035, \n",
    "                            1.54870568, 1.55335041, 1.39117037, 1.56935123, 1.51973211, 1.50300901])                                                                \n",
    "                                                                         }, index=np.arange(38, 50))\n",
    "\n",
    "\n",
    "def test_output_backtesting_forecaster_refit_interval_out_sample_residuals_no_exog_no_remainder_with_mocked():\n",
    "    '''\n",
    "    Test output of _backtesting_forecaster_refit with backtesting mocked, interval yes.\n",
    "    Regressor is LinearRegression with lags=3, Series y is mocked, no exog, \n",
    "    12 observations to backtest, steps=4 (no remainder), metric='mean_squared_error',\n",
    "    'in_sample_residuals = False'\n",
    "    '''\n",
    "    forecaster = ForecasterAutoreg(regressor=LinearRegression(), lags=3)\n",
    "    forecaster.set_out_sample_residuals(residuals=out_sample_residuals, append=False)\n",
    "\n",
    "    n_backtest = 12\n",
    "    y_train = y[:-n_backtest]\n",
    "\n",
    "    metric, backtest_predictions = _backtesting_forecaster_refit(\n",
    "                                        forecaster          = forecaster,\n",
    "                                        y                   = y,\n",
    "                                        exog                = None,\n",
    "                                        initial_train_size  = len(y_train),\n",
    "                                        steps               = 4,\n",
    "                                        metric              = 'mean_squared_error',\n",
    "                                        interval            = [5, 95],\n",
    "                                        n_boot              = 500,\n",
    "                                        random_state        = 123,\n",
    "                                        in_sample_residuals = False,\n",
    "                                        verbose             = False\n",
    "                                   ) \n",
    "    expected_metric = metric_mocked_interval_out_sample_residuals_no_exog_no_remainder\n",
    "    expected_backtest_predictions = backtest_predictions_mocked_interval_out_sample_residuals_no_exog_no_remainder\n",
    "    assert expected_metric == approx(metric)\n",
    "    pd.testing.assert_frame_equal(expected_backtest_predictions, backtest_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "84da93ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T15:30:48.129362Z",
     "start_time": "2022-02-25T15:30:47.206289Z"
    }
   },
   "outputs": [],
   "source": [
    "test_output_backtesting_forecaster_refit_interval_out_sample_residuals_no_exog_no_remainder_with_mocked()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0411934",
   "metadata": {},
   "source": [
    "#### Calleable metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4e00d883",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T09:21:12.330938Z",
     "start_time": "2022-02-25T09:21:12.287434Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 38\n",
      "Number of observations used for backtesting: 12\n",
      "    Number of folds: 3\n",
      "    Number of steps per fold: 4\n",
      "\n",
      "Data partition in fold: 0\n",
      "    Training:   0 -- 37\n",
      "    Validation: 38 -- 41\n",
      "Data partition in fold: 1\n",
      "    Training:   0 -- 41\n",
      "    Validation: 42 -- 45\n",
      "Data partition in fold: 2\n",
      "    Training:   0 -- 45\n",
      "    Validation: 46 -- 49\n",
      "\n",
      "0.005283745900436151\n",
      "0.005283745900436151\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.55717779, 0.43355138, 0.54969767, 0.52945466, 0.38969292,\n",
       "       0.52778339, 0.49152015, 0.4841678 , 0.4076433 , 0.50904672,\n",
       "       0.50249462, 0.49232817])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mocked backtesting no exog no remainder my metric calleable\n",
    "# ==============================================================================\n",
    "def my_metric(y_true, y_pred):\n",
    "    '''\n",
    "    Calleable metric\n",
    "    '''\n",
    "    metric = ((y_true - y_pred)/len(y_true)).mean()\n",
    "    \n",
    "    return metric\n",
    "    \n",
    "forecaster = ForecasterAutoreg(\n",
    "                regressor = LinearRegression(),\n",
    "                lags      = 3 \n",
    "             )\n",
    "forecaster.fit(y=y)\n",
    "\n",
    "n_backtest = 12\n",
    "y_train = y[:-n_backtest]\n",
    "y_backtest = y[-n_backtest:]\n",
    "\n",
    "metric, backtest_predictions = _backtesting_forecaster_refit(\n",
    "                                    forecaster = forecaster,\n",
    "                                    y          = y,\n",
    "                                    initial_train_size = len(y_train),\n",
    "                                    steps      = 4,\n",
    "                                    metric     = my_metric,\n",
    "                                    verbose    = True\n",
    "                               )\n",
    "\n",
    "print(metric)\n",
    "\n",
    "metric_value = my_metric(\n",
    "                    y_true = y.iloc[len(y_train) : len(y_train) + len(backtest_predictions)],\n",
    "                    y_pred = backtest_predictions['pred']\n",
    "                   )\n",
    "print(metric_value)\n",
    "backtest_predictions.pred.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a1f8238a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T09:21:13.413174Z",
     "start_time": "2022-02-25T09:21:13.395078Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fixtures _backtesting_forecaster_refit No exog No remainder (skforecast==0.4.2)\n",
    "# ==============================================================================\n",
    "my_metric_mocked_no_exog_no_remainder = 0.005283745900436151\n",
    "assert my_metric_mocked_no_exog_no_remainder == metric\n",
    "my_metric_backtest_predictions_mocked_no_exog_no_remainder = pd.DataFrame({\n",
    "    'pred':np.array([0.55717779, 0.43355138, 0.54969767, 0.52945466, 0.38969292, 0.52778339,\n",
    "                     0.49152015, 0.4841678 , 0.4076433 , 0.50904672, 0.50249462, 0.49232817])\n",
    "                                                                }, index=np.arange(38, 50))\n",
    "pd.testing.assert_frame_equal(backtest_predictions, my_metric_backtest_predictions_mocked_no_exog_no_remainder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc32709f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T09:21:15.397652Z",
     "start_time": "2022-02-25T09:21:15.380348Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fixtures _backtesting_forecaster_refit No exog No remainder (skforecast==0.4.2)\n",
    "# ==============================================================================\n",
    "my_metric_mocked_no_exog_no_remainder = 0.005283745900436151\n",
    "my_metric_backtest_predictions_mocked_no_exog_no_remainder = pd.DataFrame({\n",
    "    'pred':np.array([0.55717779, 0.43355138, 0.54969767, 0.52945466, 0.38969292, 0.52778339,\n",
    "                     0.49152015, 0.4841678 , 0.4076433 , 0.50904672, 0.50249462, 0.49232817])\n",
    "                                                                }, index=np.arange(38, 50))\n",
    "\n",
    "\n",
    "def my_metric(y_true, y_pred):\n",
    "    '''\n",
    "    Calleable metric\n",
    "    '''\n",
    "    metric = ((y_true - y_pred)/len(y_true)).mean()\n",
    "    \n",
    "    return metric\n",
    "\n",
    "def test_calleable_metric_backtesting_forecaster_refit_no_exog_no_remainder_with_mocked():\n",
    "    '''\n",
    "    Test calleable metric in _backtesting_forecaster_refit with backtesting mocked, interval no. \n",
    "    Regressor is LinearRegression with lags=3, Series y is mocked, no exog, \n",
    "    12 observations to backtest, steps=4 (no remainder), metric='mean_squared_error'\n",
    "    '''\n",
    "    forecaster = ForecasterAutoreg(regressor=LinearRegression(), lags=3)\n",
    "\n",
    "    n_backtest = 12\n",
    "    y_train = y[:-n_backtest]\n",
    "\n",
    "    metric, backtest_predictions = _backtesting_forecaster_refit(\n",
    "                                        forecaster          = forecaster,\n",
    "                                        y                   = y,\n",
    "                                        exog                = None,\n",
    "                                        initial_train_size  = len(y_train),\n",
    "                                        steps               = 4,\n",
    "                                        metric              = my_metric,\n",
    "                                        interval            = None,\n",
    "                                        n_boot              = 500,\n",
    "                                        random_state        = 123,\n",
    "                                        in_sample_residuals = True,\n",
    "                                        verbose             = False\n",
    "                                   )\n",
    "    expected_metric = my_metric_mocked_no_exog_no_remainder\n",
    "    expected_backtest_predictions = my_metric_backtest_predictions_mocked_no_exog_no_remainder\n",
    "    assert expected_metric == approx(metric)\n",
    "    pd.testing.assert_frame_equal(expected_backtest_predictions, backtest_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ea6c452b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T09:21:16.281672Z",
     "start_time": "2022-02-25T09:21:16.251370Z"
    }
   },
   "outputs": [],
   "source": [
    "test_calleable_metric_backtesting_forecaster_refit_no_exog_no_remainder_with_mocked()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929d5901",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T10:26:09.639247Z",
     "start_time": "2022-02-24T10:26:09.434606Z"
    }
   },
   "source": [
    "#### Fixed train size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7aa9490",
   "metadata": {},
   "source": [
    "**Mocked backtesting no exog no remainder fixed train size**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "48273d31",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T10:27:24.133579Z",
     "start_time": "2022-02-25T10:27:24.068263Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 38\n",
      "Number of observations used for backtesting: 4\n",
      "    Number of folds: 1\n",
      "    Number of steps per fold: 4\n",
      "\n",
      "Data partition in fold: 0\n",
      "    Training:   0 -- 37\n",
      "    Validation: 38 -- 41\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 38\n",
      "Number of observations used for backtesting: 4\n",
      "    Number of folds: 1\n",
      "    Number of steps per fold: 4\n",
      "\n",
      "Data partition in fold: 0\n",
      "    Training:   4 -- 41\n",
      "    Validation: 42 -- 45\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 38\n",
      "Number of observations used for backtesting: 4\n",
      "    Number of folds: 1\n",
      "    Number of steps per fold: 4\n",
      "\n",
      "Data partition in fold: 0\n",
      "    Training:   8 -- 45\n",
      "    Validation: 46 -- 49\n",
      "\n",
      "0.06720844584333846\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.55717779, 0.43355138, 0.54969767, 0.52945466, 0.34597367,\n",
       "       0.50223873, 0.47833829, 0.46082257, 0.37810191, 0.49508366,\n",
       "       0.48808014, 0.47323313])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mocked backtesting no exog no remainder fixed train size\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterAutoreg(\n",
    "                regressor = LinearRegression(),\n",
    "                lags      = 3 \n",
    "             )\n",
    "forecaster.fit(y=y)\n",
    "\n",
    "n_backtest = 12\n",
    "y_train = y[:-n_backtest]\n",
    "y_backtest = y[-n_backtest:]\n",
    "\n",
    "initial_train_size = len(y_train)\n",
    "steps = 4\n",
    "folds = int(np.ceil((len(y) - initial_train_size) / steps))\n",
    "\n",
    "metric_all = []\n",
    "backtest_predictions_all = pd.DataFrame()\n",
    "for i in range(folds):\n",
    "    train_idx_i = 0 + i * steps\n",
    "    train_idx_f = initial_train_size + i * steps\n",
    "    y_complete = y[train_idx_i:train_idx_f+steps]\n",
    "    y_train = y[train_idx_i:train_idx_f]\n",
    "    \n",
    "    metric, backtest_predictions = _backtesting_forecaster_refit(\n",
    "                                            forecaster          = forecaster,\n",
    "                                            y                   = y_complete,\n",
    "                                            exog                = None,\n",
    "                                            initial_train_size  = len(y_train),\n",
    "                                            steps               = steps,\n",
    "                                            metric              = 'mean_squared_error',\n",
    "                                            interval            = None,\n",
    "                                            n_boot              = 500,\n",
    "                                            random_state        = 123,\n",
    "                                            in_sample_residuals = True,\n",
    "                                            verbose             = True\n",
    "                                       )\n",
    "    backtest_predictions_all = pd.concat([backtest_predictions_all, backtest_predictions])\n",
    "\n",
    "metric = _get_metric('mean_squared_error')(\n",
    "                    y_true = y.iloc[len(y_train) : len(y_train) + len(backtest_predictions_all)],\n",
    "                    y_pred = backtest_predictions_all['pred']\n",
    "                   )\n",
    "print(metric)\n",
    "backtest_predictions_all.pred.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f358ccc7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T10:27:24.884706Z",
     "start_time": "2022-02-25T10:27:24.868684Z"
    }
   },
   "outputs": [],
   "source": [
    "metric_mocked_fixed_train_no_exog_no_remainder = 0.06720844584333846\n",
    "assert metric_mocked_fixed_train_no_exog_no_remainder == metric\n",
    "backtest_predictions_mocked_fixed_train_no_exog_no_remainder = pd.DataFrame({\n",
    "    'pred':np.array([0.55717779, 0.43355138, 0.54969767, 0.52945466, 0.34597367, 0.50223873,\n",
    "                     0.47833829, 0.46082257, 0.37810191, 0.49508366, 0.48808014, 0.47323313])\n",
    "                                                                }, index=np.arange(38, 50))\n",
    "pd.testing.assert_frame_equal(backtest_predictions_all, backtest_predictions_mocked_fixed_train_no_exog_no_remainder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e229e4",
   "metadata": {},
   "source": [
    "**Mocked backtesting no exog yes remainder fixed train size**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "73b085c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T10:27:36.198458Z",
     "start_time": "2022-02-25T10:27:36.138213Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 38\n",
      "Number of observations used for backtesting: 5\n",
      "    Number of folds: 1\n",
      "    Number of steps per fold: 5\n",
      "\n",
      "Data partition in fold: 0\n",
      "    Training:   0 -- 37\n",
      "    Validation: 38 -- 42\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 38\n",
      "Number of observations used for backtesting: 5\n",
      "    Number of folds: 1\n",
      "    Number of steps per fold: 5\n",
      "\n",
      "Data partition in fold: 0\n",
      "    Training:   5 -- 42\n",
      "    Validation: 43 -- 47\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 38\n",
      "Number of observations used for backtesting: 2\n",
      "    Number of folds: 1\n",
      "    Number of steps per fold: 5\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Data partition in fold: 0\n",
      "    Training:   10 -- 47\n",
      "    Validation: 48 -- 49\n",
      "\n",
      "0.07217085374372428\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.55717779, 0.43355138, 0.54969767, 0.52945466, 0.48308861,\n",
       "       0.4909399 , 0.47942107, 0.46025344, 0.46649132, 0.47061725,\n",
       "       0.57603136, 0.41480551])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mocked backtesting no exog yes remainder fixed train size\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterAutoreg(\n",
    "                regressor = LinearRegression(),\n",
    "                lags      = 3 \n",
    "             )\n",
    "forecaster.fit(y=y)\n",
    "\n",
    "n_backtest = 12\n",
    "y_train = y[:-n_backtest]\n",
    "y_backtest = y[-n_backtest:]\n",
    "\n",
    "initial_train_size = len(y_train)\n",
    "steps = 5\n",
    "folds = int(np.ceil((len(y) - initial_train_size) / steps))\n",
    "\n",
    "metric_all = []\n",
    "backtest_predictions_all = pd.DataFrame()\n",
    "for i in range(folds):\n",
    "    train_idx_i = 0 + i * steps\n",
    "    train_idx_f = initial_train_size + i * steps\n",
    "    \n",
    "    if train_idx_f+steps < len(y):\n",
    "        y_complete = y[train_idx_i:train_idx_f+steps]\n",
    "    else:\n",
    "        y_complete = y[train_idx_i:]\n",
    "        \n",
    "    y_train = y[train_idx_i:train_idx_f]\n",
    "    \n",
    "    metric, backtest_predictions = _backtesting_forecaster_refit(\n",
    "                                            forecaster          = forecaster,\n",
    "                                            y                   = y_complete,\n",
    "                                            exog                = None,\n",
    "                                            initial_train_size  = len(y_train),\n",
    "                                            steps               = steps,\n",
    "                                            metric              = 'mean_squared_error',\n",
    "                                            interval            = None,\n",
    "                                            n_boot              = 500,\n",
    "                                            random_state        = 123,\n",
    "                                            in_sample_residuals = True,\n",
    "                                            verbose             = True\n",
    "                                       )\n",
    "    backtest_predictions_all = pd.concat([backtest_predictions_all, backtest_predictions])\n",
    "\n",
    "metric = _get_metric('mean_squared_error')(\n",
    "                    y_true = y.iloc[len(y_train) : len(y_train) + len(backtest_predictions_all)],\n",
    "                    y_pred = backtest_predictions_all['pred']\n",
    "                   )\n",
    "print(metric)\n",
    "backtest_predictions_all.pred.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0b20a7ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T10:28:11.121233Z",
     "start_time": "2022-02-25T10:28:11.105134Z"
    }
   },
   "outputs": [],
   "source": [
    "metric_mocked_fixed_train_no_exog_yes_remainder = 0.07217085374372428\n",
    "assert metric_mocked_fixed_train_no_exog_yes_remainder == metric\n",
    "backtest_predictions_mocked_fixed_train_no_exog_yes_remainder = pd.DataFrame({\n",
    "    'pred':np.array([0.55717779, 0.43355138, 0.54969767, 0.52945466, 0.48308861, 0.4909399 , \n",
    "                     0.47942107, 0.46025344, 0.46649132, 0.47061725, 0.57603136, 0.41480551])\n",
    "                                                                }, index=np.arange(38, 50))\n",
    "pd.testing.assert_frame_equal(backtest_predictions_all, backtest_predictions_mocked_fixed_train_no_exog_yes_remainder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12a157e",
   "metadata": {},
   "source": [
    "**Mocked backtesting Yes exog No remainder fixed train size**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f80264c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T10:30:04.975387Z",
     "start_time": "2022-02-25T10:30:04.925982Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 38\n",
      "Number of observations used for backtesting: 4\n",
      "    Number of folds: 1\n",
      "    Number of steps per fold: 4\n",
      "\n",
      "Data partition in fold: 0\n",
      "    Training:   0 -- 37\n",
      "    Validation: 38 -- 41\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 38\n",
      "Number of observations used for backtesting: 4\n",
      "    Number of folds: 1\n",
      "    Number of steps per fold: 4\n",
      "\n",
      "Data partition in fold: 0\n",
      "    Training:   4 -- 41\n",
      "    Validation: 42 -- 45\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 38\n",
      "Number of observations used for backtesting: 4\n",
      "    Number of folds: 1\n",
      "    Number of steps per fold: 4\n",
      "\n",
      "Data partition in fold: 0\n",
      "    Training:   8 -- 45\n",
      "    Validation: 46 -- 49\n",
      "\n",
      "0.05758244401484334\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.59059622, 0.47257504, 0.53024098, 0.46163343, 0.37689967,\n",
       "       0.44267729, 0.42642836, 0.41604275, 0.45047245, 0.53784704,\n",
       "       0.53726274, 0.51516772])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mocked backtesting yes exog no remainder fixed train size\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterAutoreg(\n",
    "                regressor = LinearRegression(),\n",
    "                lags      = 3 \n",
    "             )\n",
    "forecaster.fit(y=y, exog=exog)\n",
    "\n",
    "n_backtest = 12\n",
    "y_train = y[:-n_backtest]\n",
    "y_backtest = y[-n_backtest:]\n",
    "\n",
    "initial_train_size = len(y_train)\n",
    "steps = 4\n",
    "folds = int(np.ceil((len(y) - initial_train_size) / steps))\n",
    "\n",
    "backtest_predictions_all = pd.DataFrame()\n",
    "for i in range(folds):\n",
    "    train_idx_i = 0 + i * steps\n",
    "    train_idx_f = initial_train_size + i * steps\n",
    "    y_complete = y[train_idx_i:train_idx_f+steps]\n",
    "    exog_complete = exog[train_idx_i:train_idx_f+steps]\n",
    "    y_train = y[train_idx_i:train_idx_f]\n",
    "    \n",
    "    metric, backtest_predictions = _backtesting_forecaster_refit(\n",
    "                                            forecaster          = forecaster,\n",
    "                                            y                   = y_complete,\n",
    "                                            exog                = exog_complete,\n",
    "                                            initial_train_size  = len(y_train),\n",
    "                                            steps               = steps,\n",
    "                                            metric              = 'mean_squared_error',\n",
    "                                            interval            = None,\n",
    "                                            n_boot              = 500,\n",
    "                                            random_state        = 123,\n",
    "                                            in_sample_residuals = True,\n",
    "                                            verbose             = True\n",
    "                                       )\n",
    "    backtest_predictions_all = pd.concat([backtest_predictions_all, backtest_predictions])\n",
    "\n",
    "metric = _get_metric('mean_squared_error')(\n",
    "                    y_true = y.iloc[len(y_train) : len(y_train) + len(backtest_predictions_all)],\n",
    "                    y_pred = backtest_predictions_all['pred']\n",
    "                   )\n",
    "print(metric)\n",
    "backtest_predictions_all.pred.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "94563a67",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T10:30:22.766082Z",
     "start_time": "2022-02-25T10:30:22.750116Z"
    }
   },
   "outputs": [],
   "source": [
    "metric_mocked_fixed_train_yes_exog_no_remainder = 0.05758244401484334\n",
    "assert metric_mocked_fixed_train_yes_exog_no_remainder == metric\n",
    "backtest_predictions_mocked_fixed_train_yes_exog_no_remainder = pd.DataFrame({\n",
    "    'pred':np.array([0.59059622, 0.47257504, 0.53024098, 0.46163343, 0.37689967, 0.44267729, \n",
    "                     0.42642836, 0.41604275, 0.45047245, 0.53784704, 0.53726274, 0.51516772])\n",
    "                                                                }, index=np.arange(38, 50))\n",
    "pd.testing.assert_frame_equal(backtest_predictions_all, backtest_predictions_mocked_fixed_train_yes_exog_no_remainder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ee2e25",
   "metadata": {},
   "source": [
    "**Mocked backtesting Yes exog Yes remainder fixed train size**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b69178bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T10:32:26.007211Z",
     "start_time": "2022-02-25T10:32:25.942763Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 38\n",
      "Number of observations used for backtesting: 5\n",
      "    Number of folds: 1\n",
      "    Number of steps per fold: 5\n",
      "\n",
      "Data partition in fold: 0\n",
      "    Training:   0 -- 37\n",
      "    Validation: 38 -- 42\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 38\n",
      "Number of observations used for backtesting: 5\n",
      "    Number of folds: 1\n",
      "    Number of steps per fold: 5\n",
      "\n",
      "Data partition in fold: 0\n",
      "    Training:   5 -- 42\n",
      "    Validation: 43 -- 47\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 38\n",
      "Number of observations used for backtesting: 2\n",
      "    Number of folds: 1\n",
      "    Number of steps per fold: 5\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Data partition in fold: 0\n",
      "    Training:   10 -- 47\n",
      "    Validation: 48 -- 49\n",
      "\n",
      "0.06425019123005545\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.59059622, 0.47257504, 0.53024098, 0.46163343, 0.50035119,\n",
       "       0.41975558, 0.4256614 , 0.41176005, 0.52357817, 0.509974  ,\n",
       "       0.65354628, 0.48210726])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mocked backtesting yes exog yes remainder fixed train size\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterAutoreg(\n",
    "                regressor = LinearRegression(),\n",
    "                lags      = 3 \n",
    "             )\n",
    "forecaster.fit(y=y, exog=exog)\n",
    "\n",
    "n_backtest = 12\n",
    "y_train = y[:-n_backtest]\n",
    "y_backtest = y[-n_backtest:]\n",
    "\n",
    "initial_train_size = len(y_train)\n",
    "steps = 5\n",
    "folds = int(np.ceil((len(y) - initial_train_size) / steps))\n",
    "\n",
    "backtest_predictions_all = pd.DataFrame()\n",
    "for i in range(folds):\n",
    "    train_idx_i = 0 + i * steps\n",
    "    train_idx_f = initial_train_size + i * steps\n",
    "    y_complete = y[train_idx_i:train_idx_f+steps]\n",
    "    exog_complete = exog[train_idx_i:train_idx_f+steps]\n",
    "    y_train = y[train_idx_i:train_idx_f]\n",
    "    \n",
    "    metric, backtest_predictions = _backtesting_forecaster_refit(\n",
    "                                            forecaster          = forecaster,\n",
    "                                            y                   = y_complete,\n",
    "                                            exog                = exog_complete,\n",
    "                                            initial_train_size  = len(y_train),\n",
    "                                            steps               = steps,\n",
    "                                            metric              = 'mean_squared_error',\n",
    "                                            interval            = None,\n",
    "                                            n_boot              = 500,\n",
    "                                            random_state        = 123,\n",
    "                                            in_sample_residuals = True,\n",
    "                                            verbose             = True\n",
    "                                       )\n",
    "    backtest_predictions_all = pd.concat([backtest_predictions_all, backtest_predictions])\n",
    "\n",
    "metric = _get_metric('mean_squared_error')(\n",
    "                    y_true = y.iloc[len(y_train) : len(y_train) + len(backtest_predictions_all)],\n",
    "                    y_pred = backtest_predictions_all['pred']\n",
    "                   )\n",
    "print(metric)\n",
    "backtest_predictions_all.pred.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9182a352",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T10:33:04.216246Z",
     "start_time": "2022-02-25T10:33:04.200113Z"
    }
   },
   "outputs": [],
   "source": [
    "metric_mocked_fixed_train_yes_exog_yes_remainder = 0.06425019123005545\n",
    "assert metric_mocked_fixed_train_yes_exog_yes_remainder == metric\n",
    "backtest_predictions_mocked_fixed_train_yes_exog_yes_remainder = pd.DataFrame({\n",
    "    'pred':np.array([0.59059622, 0.47257504, 0.53024098, 0.46163343, 0.50035119, 0.41975558, \n",
    "                     0.4256614 , 0.41176005, 0.52357817, 0.509974  , 0.65354628, 0.48210726])\n",
    "                                                                }, index=np.arange(38, 50))\n",
    "pd.testing.assert_frame_equal(backtest_predictions_all, backtest_predictions_mocked_fixed_train_yes_exog_yes_remainder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b60bf1b",
   "metadata": {},
   "source": [
    "##### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "aa0f2401",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T10:36:29.714262Z",
     "start_time": "2022-02-25T10:36:29.685286Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fixtures _backtesting_forecaster_refit fixed_train_size No exog No remainder (skforecast==0.4.2)\n",
    "# ==============================================================================\n",
    "metric_mocked_fixed_train_no_exog_no_remainder = 0.06720844584333846\n",
    "backtest_predictions_mocked_fixed_train_no_exog_no_remainder = pd.DataFrame({\n",
    "    'pred':np.array([0.55717779, 0.43355138, 0.54969767, 0.52945466, 0.34597367, 0.50223873,\n",
    "                     0.47833829, 0.46082257, 0.37810191, 0.49508366, 0.48808014, 0.47323313])\n",
    "                                                                }, index=np.arange(38, 50))\n",
    "\n",
    "# Fixtures _backtesting_forecaster_refit fixed_train_size No exog Yes remainder (skforecast==0.4.2)\n",
    "# ==============================================================================\n",
    "metric_mocked_fixed_train_no_exog_yes_remainder = 0.07217085374372428\n",
    "backtest_predictions_mocked_fixed_train_no_exog_yes_remainder = pd.DataFrame({\n",
    "    'pred':np.array([0.55717779, 0.43355138, 0.54969767, 0.52945466, 0.48308861, 0.4909399 , \n",
    "                     0.47942107, 0.46025344, 0.46649132, 0.47061725, 0.57603136, 0.41480551])\n",
    "                                                                }, index=np.arange(38, 50))\n",
    "\n",
    "# Fixtures _backtesting_forecaster_refit fixed_train_size Yes exog No remainder (skforecast==0.4.2)\n",
    "# ==============================================================================\n",
    "metric_mocked_fixed_train_yes_exog_no_remainder = 0.05758244401484334\n",
    "backtest_predictions_mocked_fixed_train_yes_exog_no_remainder = pd.DataFrame({\n",
    "    'pred':np.array([0.59059622, 0.47257504, 0.53024098, 0.46163343, 0.37689967, 0.44267729, \n",
    "                     0.42642836, 0.41604275, 0.45047245, 0.53784704, 0.53726274, 0.51516772])\n",
    "                                                                }, index=np.arange(38, 50))\n",
    "\n",
    "# Fixtures _backtesting_forecaster_refit fixed_train_size Yes exog Yes remainder (skforecast==0.4.2)\n",
    "# ==============================================================================\n",
    "metric_mocked_fixed_train_yes_exog_yes_remainder = 0.06425019123005545\n",
    "backtest_predictions_mocked_fixed_train_yes_exog_yes_remainder = pd.DataFrame({\n",
    "    'pred':np.array([0.59059622, 0.47257504, 0.53024098, 0.46163343, 0.50035119, 0.41975558, \n",
    "                     0.4256614 , 0.41176005, 0.52357817, 0.509974  , 0.65354628, 0.48210726])\n",
    "                                                                }, index=np.arange(38, 50))\n",
    "\n",
    "\n",
    "def test_output_backtesting_forecaster_refit_fixed_train_size_no_exog_no_remainder_with_mocked():\n",
    "    '''\n",
    "    Test output of _backtesting_forecaster_refit with backtesting mocked, interval no.\n",
    "    Regressor is LinearRegression with lags=3, Series y is mocked, no exog, \n",
    "    12 observations to backtest, steps=4 (no remainder), metric='mean_squared_error',\n",
    "    fixed_train_size=True\n",
    "    '''\n",
    "    forecaster = ForecasterAutoreg(regressor=LinearRegression(), lags=3)\n",
    "\n",
    "    n_backtest = 12\n",
    "    y_train = y[:-n_backtest]\n",
    "\n",
    "    metric, backtest_predictions = _backtesting_forecaster_refit(\n",
    "                                        forecaster          = forecaster,\n",
    "                                        y                   = y,\n",
    "                                        exog                = None,\n",
    "                                        initial_train_size  = len(y_train),\n",
    "                                        fixed_train_size    = True,\n",
    "                                        steps               = 4,\n",
    "                                        metric              = 'mean_squared_error',\n",
    "                                        interval            = None,\n",
    "                                        n_boot              = 500,\n",
    "                                        random_state        = 123,\n",
    "                                        in_sample_residuals = True,\n",
    "                                        verbose             = False\n",
    "                                   )\n",
    "    expected_metric = metric_mocked_fixed_train_no_exog_no_remainder\n",
    "    expected_backtest_predictions = backtest_predictions_mocked_fixed_train_no_exog_no_remainder\n",
    "    assert expected_metric == approx(metric)\n",
    "    pd.testing.assert_frame_equal(expected_backtest_predictions, backtest_predictions)\n",
    "\n",
    "\n",
    "def test_output_backtesting_forecaster_refit_fixed_train_size_no_exog_yes_remainder_with_mocked():\n",
    "    '''\n",
    "    Test output of _backtesting_forecaster_refit with backtesting mocked, interval no.\n",
    "    Regressor is LinearRegression with lags=3, Series y is mocked, no exog, \n",
    "    12 observations to backtest, steps=5 (2 remainder), metric='mean_squared_error',\n",
    "    fixed_train_size=True\n",
    "    '''\n",
    "    forecaster = ForecasterAutoreg(regressor=LinearRegression(), lags=3)\n",
    "\n",
    "    n_backtest = 12\n",
    "    y_train = y[:-n_backtest]\n",
    "\n",
    "    metric, backtest_predictions = _backtesting_forecaster_refit(\n",
    "                                        forecaster          = forecaster,\n",
    "                                        y                   = y,\n",
    "                                        exog                = None,\n",
    "                                        initial_train_size  = len(y_train),\n",
    "                                        fixed_train_size    = True,\n",
    "                                        steps               = 5,\n",
    "                                        metric              = 'mean_squared_error',\n",
    "                                        interval            = None,\n",
    "                                        n_boot              = 500,\n",
    "                                        random_state        = 123,\n",
    "                                        in_sample_residuals = True,\n",
    "                                        verbose             = False\n",
    "                                   )\n",
    "    expected_metric = metric_mocked_fixed_train_no_exog_yes_remainder\n",
    "    expected_backtest_predictions = backtest_predictions_mocked_fixed_train_no_exog_yes_remainder\n",
    "    assert expected_metric == approx(metric)\n",
    "    pd.testing.assert_frame_equal(expected_backtest_predictions, backtest_predictions)\n",
    "\n",
    "\n",
    "def test_output_backtesting_forecaster_refit_fixed_train_size_yes_exog_no_remainder_with_mocked():\n",
    "    '''\n",
    "    Test output of _backtesting_forecaster_refit with backtesting mocked, interval no.\n",
    "    Regressor is LinearRegression with lags=3, Series y is mocked, exog is mocked,\n",
    "    12 observations to backtest, steps=4 (no remainder), metric='mean_squared_error',\n",
    "    fixed_train_size=True\n",
    "    '''\n",
    "    forecaster = ForecasterAutoreg(regressor=LinearRegression(), lags=3)\n",
    "\n",
    "    n_backtest = 12\n",
    "    y_train = y[:-n_backtest]\n",
    "\n",
    "    metric, backtest_predictions = _backtesting_forecaster_refit(\n",
    "                                        forecaster          = forecaster,\n",
    "                                        y                   = y,\n",
    "                                        exog                = exog,\n",
    "                                        initial_train_size  = len(y_train),\n",
    "                                        fixed_train_size    = True,\n",
    "                                        steps               = 4,\n",
    "                                        metric              = 'mean_squared_error',\n",
    "                                        interval            = None,\n",
    "                                        n_boot              = 500,\n",
    "                                        random_state        = 123,\n",
    "                                        in_sample_residuals = True,\n",
    "                                        verbose             = False\n",
    "                                   )\n",
    "    expected_metric = metric_mocked_fixed_train_yes_exog_no_remainder\n",
    "    expected_backtest_predictions = backtest_predictions_mocked_fixed_train_yes_exog_no_remainder\n",
    "    assert expected_metric == approx(metric)\n",
    "    pd.testing.assert_frame_equal(expected_backtest_predictions, backtest_predictions)\n",
    "\n",
    "\n",
    "def test_output_backtesting_forecaster_refit_fixed_train_size_yes_exog_yes_remainder_with_mocked():\n",
    "    '''\n",
    "    Test output of _backtesting_forecaster_refit with backtesting mocked, interval no.\n",
    "    Regressor is LinearRegression with lags=3, Series y is mocked, exog is mocked,\n",
    "    12 observations to backtest, steps=5 (2 remainder), metric='mean_squared_error',\n",
    "    fixed_train_size=True\n",
    "    '''\n",
    "    forecaster = ForecasterAutoreg(regressor=LinearRegression(), lags=3)\n",
    "\n",
    "    n_backtest = 12\n",
    "    y_train = y[:-n_backtest]\n",
    "\n",
    "    metric, backtest_predictions = _backtesting_forecaster_refit(\n",
    "                                        forecaster          = forecaster,\n",
    "                                        y                   = y,\n",
    "                                        exog                = exog,\n",
    "                                        initial_train_size  = len(y_train),\n",
    "                                        fixed_train_size    = True,\n",
    "                                        steps               = 5,\n",
    "                                        metric              = 'mean_squared_error',\n",
    "                                        interval            = None,\n",
    "                                        n_boot              = 500,\n",
    "                                        random_state        = 123,\n",
    "                                        in_sample_residuals = True,\n",
    "                                        verbose             = False\n",
    "                                   )\n",
    "    expected_metric = metric_mocked_fixed_train_yes_exog_yes_remainder\n",
    "    expected_backtest_predictions = backtest_predictions_mocked_fixed_train_yes_exog_yes_remainder\n",
    "    assert expected_metric == approx(metric)\n",
    "    pd.testing.assert_frame_equal(expected_backtest_predictions, backtest_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b4d3d7b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T10:36:30.579994Z",
     "start_time": "2022-02-25T10:36:30.487445Z"
    }
   },
   "outputs": [],
   "source": [
    "test_output_backtesting_forecaster_refit_fixed_train_size_no_exog_no_remainder_with_mocked()\n",
    "test_output_backtesting_forecaster_refit_fixed_train_size_no_exog_yes_remainder_with_mocked()\n",
    "test_output_backtesting_forecaster_refit_fixed_train_size_yes_exog_no_remainder_with_mocked()\n",
    "test_output_backtesting_forecaster_refit_fixed_train_size_yes_exog_yes_remainder_with_mocked()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0258d533",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6947e807",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451ba383",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2902db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c685e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170a56dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ecb1c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed23156",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skforecast",
   "language": "python",
   "name": "skforecast"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "358.633px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
